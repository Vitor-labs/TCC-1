{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "from collections.abc import Callable\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from json import dumps\n",
    "from time import time\n",
    "from typing import Final, Literal\n",
    "\n",
    "import numpy as np\n",
    "import structlog\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.event import Events\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.util import load_logs\n",
    "from numpy import ndarray, where\n",
    "from pandas import DataFrame, Series, concat, read_csv, set_option\n",
    "from scipy.stats import loguniform, wilcoxon\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "set_option(\"display.max_columns\", None)\n",
    "structlog.configure(\n",
    "    processors=[\n",
    "        structlog.stdlib.filter_by_level,\n",
    "        structlog.stdlib.add_logger_name,\n",
    "        structlog.stdlib.add_log_level,\n",
    "        structlog.stdlib.PositionalArgumentsFormatter(),\n",
    "        structlog.processors.TimeStamper(fmt=\"iso\"),\n",
    "        structlog.processors.StackInfoRenderer(),\n",
    "        structlog.processors.format_exc_info,\n",
    "        structlog.processors.UnicodeDecoder(),\n",
    "        structlog.processors.JSONRenderer(),\n",
    "    ],\n",
    "    context_class=dict,\n",
    "    logger_factory=structlog.stdlib.LoggerFactory(),\n",
    "    wrapper_class=structlog.stdlib.BoundLogger,\n",
    "    cache_logger_on_first_use=True,\n",
    ")\n",
    "\n",
    "type ParamGrid = dict[str, tuple[float | str, ...]]\n",
    "NUM_TRIALS: Final[int] = 10\n",
    "LOGS_PATH_BAYESIAN: Final[str] = \"../reports/logs_bayesian.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train = read_csv(\"../data/PAMAP2/x_train_data.csv\")\n",
    "X_test = read_csv(\"../data/PAMAP2/x_test_data.csv\")\n",
    "y_train = read_csv(\"../data/PAMAP2/y_train_data.csv\")\n",
    "y_test = read_csv(\"../data/PAMAP2/y_test_data.csv\")\n",
    "\n",
    "X_train[\"activity\"] = y_train\n",
    "X_test[\"activity\"] = y_test\n",
    "\n",
    "# Global variables\n",
    "testing_data: DataFrame\n",
    "test_targets: Series\n",
    "training_data: DataFrame\n",
    "train_targets: Series\n",
    "MIN_SAMPLES = X_train[\"activity\"].value_counts().sort_values().iloc[0]\n",
    "MAXIMAZED = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    method: str\n",
    "    best_params: dict\n",
    "    best_score: float\n",
    "    cv_scores: list[float]\n",
    "    fit_time: float\n",
    "    n_evaluations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_file_logger(filepath: str) -> structlog.BoundLogger:\n",
    "    \"\"\"Configure a file-specific logger using structlog.\"\"\"\n",
    "    file_handler = logging.FileHandler(filepath, mode=\"a\")\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "\n",
    "    structlog.configure(\n",
    "        processors=[\n",
    "            structlog.stdlib.filter_by_level,\n",
    "            structlog.stdlib.add_logger_name,\n",
    "            structlog.stdlib.add_log_level,\n",
    "            structlog.stdlib.PositionalArgumentsFormatter(),\n",
    "            structlog.processors.TimeStamper(fmt=\"iso\"),\n",
    "            structlog.processors.StackInfoRenderer(),\n",
    "            structlog.processors.format_exc_info,\n",
    "            structlog.processors.UnicodeDecoder(),\n",
    "            structlog.processors.JSONRenderer(),\n",
    "        ],\n",
    "        context_class=dict,\n",
    "        logger_factory=structlog.stdlib.LoggerFactory(),\n",
    "        wrapper_class=structlog.stdlib.BoundLogger,\n",
    "        cache_logger_on_first_use=False,\n",
    "    )\n",
    "    stdlib_logger = logging.getLogger(\"hyperparameter_search\")\n",
    "    stdlib_logger.handlers.clear()\n",
    "    stdlib_logger.addHandler(file_handler)\n",
    "    stdlib_logger.setLevel(logging.INFO)\n",
    "\n",
    "    return structlog.get_logger(\"hyperparameter_search\")\n",
    "\n",
    "\n",
    "def score_function(model: OneClassSVM, Train: DataFrame, test: Series) -> float:\n",
    "    \"\"\"\n",
    "    Objective function to maximize, calcs the F1 score on the test set.\n",
    "    follows the format needed by scikit-learn's API.\n",
    "    \"\"\"\n",
    "    f1 = f1_score(test_targets, where(model.predict(testing_data) == -1, True, False))\n",
    "    logger.info(\n",
    "        {\n",
    "            \"target\": f1,\n",
    "            \"params\": model.get_params(),\n",
    "            \"datetime\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        }\n",
    "    )\n",
    "    return float(f1)\n",
    "\n",
    "\n",
    "def objective_function_bayesian(nu: float, gamma: float, tol: float) -> float:\n",
    "    \"\"\"\n",
    "    Objective function to optimize F1-Score using Bayesian Optimization.\n",
    "    \"\"\"\n",
    "    global training_data, testing_data, train_targets, test_targets\n",
    "    oc_svm = OneClassSVM(kernel=\"rbf\", nu=nu, gamma=gamma, tol=tol).fit(training_data)\n",
    "    return float(\n",
    "        f1_score(test_targets, where(oc_svm.predict(testing_data) == 1, False, True))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedAnnealingSearch:\n",
    "    \"\"\"\n",
    "    Custom Simulated Annealing implementation for hyperparameter optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        param_space: dict,\n",
    "        n_iter: int = NUM_TRIALS,\n",
    "        initial_temp: float = 1.0,\n",
    "        cooling_rate: float = 0.95,\n",
    "        min_temp: float = 0.01,\n",
    "        random_state: int = 42,\n",
    "    ):\n",
    "        self.param_space = param_space\n",
    "        self.n_iter = n_iter\n",
    "        self.initial_temp = initial_temp\n",
    "        self.cooling_rate = cooling_rate\n",
    "        self.min_temp = min_temp\n",
    "        self.random_state = random_state\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = -np.inf\n",
    "        self.cv_results_ = {\"mean_test_score\": []}\n",
    "\n",
    "    def _sample_params(self) -> dict:\n",
    "        \"\"\"Sample random parameters from the parameter space.\"\"\"\n",
    "        return {\n",
    "            key: values.rvs(random_state=self.random_state)\n",
    "            if hasattr(values, \"rvs\")\n",
    "            else random.choice(values)\n",
    "            for key, values in self.param_space.items()\n",
    "        }\n",
    "\n",
    "    def _neighbor_params(self, current_params: dict) -> dict:\n",
    "        \"\"\"Generate neighboring parameters by slightly modifying current ones.\"\"\"\n",
    "        neighbor = deepcopy(current_params)\n",
    "        param_to_modify = random.choice(list(self.param_space.keys()))\n",
    "\n",
    "        if hasattr(self.param_space[param_to_modify], \"rvs\"):\n",
    "            if param_to_modify == \"nu\":\n",
    "                current_val = neighbor[param_to_modify]\n",
    "                neighbor[param_to_modify] = np.clip(\n",
    "                    current_val + np.random.normal(0, 0.05 * current_val), 0.001, 1.0\n",
    "                )\n",
    "            elif param_to_modify == \"gamma\":\n",
    "                neighbor[param_to_modify] = 10 ** np.clip(\n",
    "                    np.log10(neighbor[param_to_modify]) + np.random.normal(0, 0.1),\n",
    "                    -4,\n",
    "                    1,\n",
    "                )\n",
    "            elif param_to_modify == \"tol\":\n",
    "                neighbor[param_to_modify] = 10 ** np.clip(\n",
    "                    np.log10(neighbor[param_to_modify]) + np.random.normal(0, 0.1),\n",
    "                    -6,\n",
    "                    -1,\n",
    "                )\n",
    "        else:\n",
    "            neighbor[param_to_modify] = random.choice(self.param_space[param_to_modify])\n",
    "\n",
    "        return neighbor\n",
    "\n",
    "    def _evaluate_params(self, params: ParamGrid, X: DataFrame, y: Series) -> float:\n",
    "        \"\"\"Evaluate parameter configuration using cross-validation.\"\"\"\n",
    "        return np.mean(\n",
    "            cross_val_score(\n",
    "                OneClassSVM(**params, kernel=\"rbf\"), X, y, cv=4, scoring=score_function\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def fit(self, X: DataFrame, y: Series):\n",
    "        \"\"\"Fit the simulated annealing search.\"\"\"\n",
    "        random.seed(self.random_state)\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        current_params = self._sample_params()\n",
    "        current_score = self._evaluate_params(current_params, X, y)\n",
    "\n",
    "        self.best_params_ = deepcopy(current_params)\n",
    "        self.best_score_ = current_score\n",
    "        temperature = self.initial_temp\n",
    "\n",
    "        for iteration in range(self.n_iter):\n",
    "            neighbor_params = self._neighbor_params(current_params)\n",
    "            neighbor_score = self._evaluate_params(neighbor_params, X, y)\n",
    "            self.cv_results_[\"mean_test_score\"].append(neighbor_score)\n",
    "\n",
    "            if neighbor_score > current_score:\n",
    "                current_params = neighbor_params\n",
    "                current_score = neighbor_score\n",
    "            else:\n",
    "                if (\n",
    "                    random.random()\n",
    "                    < np.exp(neighbor_score - current_score / temperature)\n",
    "                    if temperature > 0\n",
    "                    else 0\n",
    "                ):\n",
    "                    current_params = neighbor_params\n",
    "                    current_score = neighbor_score\n",
    "\n",
    "            if current_score > self.best_score_:\n",
    "                self.best_params_ = deepcopy(current_params)\n",
    "                self.best_score_ = current_score\n",
    "\n",
    "            temperature = max(temperature * self.cooling_rate, self.min_temp)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "class GeneticAlgorithmSearch:\n",
    "    \"\"\"\n",
    "    Custom Genetic Algorithm implementation for hyperparameter optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        param_space: dict,\n",
    "        population_size: int = 20,\n",
    "        n_generations: int = 10,\n",
    "        mutation_rate: float = 0.1,\n",
    "        crossover_rate: float = 0.8,\n",
    "        elite_size: int = 2,\n",
    "        random_state: int = 42,\n",
    "    ):\n",
    "        self.param_space = param_space\n",
    "        self.population_size = population_size\n",
    "        self.n_generations = n_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.elite_size = elite_size\n",
    "        self.random_state = random_state\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = -np.inf\n",
    "        self.cv_results_ = {\"mean_test_score\": []}\n",
    "\n",
    "    def _create_individual(self) -> dict:\n",
    "        \"\"\"Create a random individual (parameter set).\"\"\"\n",
    "        return {\n",
    "            key: values.rvs(random_state=self.random_state)\n",
    "            if hasattr(values, \"rvs\")\n",
    "            else random.choice(values)\n",
    "            for key, values in self.param_space.items()\n",
    "        }\n",
    "\n",
    "    def _crossover(self, parent1: dict, parent2: dict) -> tuple[dict, dict]:\n",
    "        \"\"\"Create two offspring from two parents using uniform crossover.\"\"\"\n",
    "        child1, child2 = deepcopy(parent1), deepcopy(parent2)\n",
    "\n",
    "        for key in parent1.keys():\n",
    "            if random.random() < 0.5:\n",
    "                child1[key], child2[key] = child2[key], child1[key]\n",
    "\n",
    "        return child1, child2\n",
    "\n",
    "    def _mutate(self, individual: dict) -> dict:\n",
    "        \"\"\"Mutate an individual by randomly changing some parameters.\"\"\"\n",
    "        mutated = deepcopy(individual)\n",
    "\n",
    "        for key in individual.keys():\n",
    "            if random.random() < self.mutation_rate:\n",
    "                mutated[key] = (\n",
    "                    self.param_space[key].rvs(random_state=self.random_state)\n",
    "                    if hasattr(self.param_space[key], \"rvs\")\n",
    "                    else random.choice(self.param_space[key])\n",
    "                )\n",
    "        return mutated\n",
    "\n",
    "    def _tournament_selection(\n",
    "        self, population: list, fitness_scores: list, tournament_size: int = 3\n",
    "    ) -> dict:\n",
    "        \"\"\"Select an individual using tournament selection.\"\"\"\n",
    "        tournament_indices = random.sample(\n",
    "            range(len(population)), min(tournament_size, len(population))\n",
    "        )\n",
    "        return population[\n",
    "            tournament_indices[\n",
    "                np.argmax([fitness_scores[i] for i in tournament_indices])\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    def _evaluate_params(self, params: dict, X: DataFrame, y: Series) -> float:\n",
    "        \"\"\"Evaluate parameter configuration using cross-validation.\"\"\"\n",
    "        return np.mean(\n",
    "            cross_val_score(\n",
    "                OneClassSVM(**params, kernel=\"rbf\"), X, y, cv=4, scoring=score_function\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def fit(self, X: DataFrame, y: Series):\n",
    "        \"\"\"Fit the genetic algorithm search.\"\"\"\n",
    "        random.seed(self.random_state)\n",
    "        np.random.seed(self.random_state)\n",
    "        population = [self._create_individual() for _ in range(self.population_size)]\n",
    "\n",
    "        for generation in range(self.n_generations):\n",
    "            print(f\"Evaluating Generation {generation}\")\n",
    "            fitness_scores = []\n",
    "            for individual in population:\n",
    "                score = self._evaluate_params(individual, X, y)\n",
    "                fitness_scores.append(score)\n",
    "                self.cv_results_[\"mean_test_score\"].append(score)\n",
    "\n",
    "                if score > self.best_score_:\n",
    "                    self.best_params_ = deepcopy(individual)\n",
    "                    self.best_score_ = score\n",
    "\n",
    "            new_population = [\n",
    "                deepcopy(population[idx])\n",
    "                for idx in np.argsort(fitness_scores)[-self.elite_size :]\n",
    "            ]\n",
    "\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1 = self._tournament_selection(population, fitness_scores)\n",
    "                parent2 = self._tournament_selection(population, fitness_scores)\n",
    "\n",
    "                if random.random() < self.crossover_rate:\n",
    "                    child1, child2 = self._crossover(parent1, parent2)\n",
    "                else:\n",
    "                    child1, child2 = deepcopy(parent1), deepcopy(parent2)\n",
    "\n",
    "                new_population.extend([self._mutate(child1), self._mutate(child2)])\n",
    "\n",
    "            population = new_population[: self.population_size]\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "class BayesianOptimizationSearch:\n",
    "    \"\"\"Wrapper for Bayesian Optimization to match the interface of other search methods.\"\"\"\n",
    "\n",
    "    def __init__(self, param_space: dict, random_state: int = 42):\n",
    "        self.param_space = param_space\n",
    "        self.random_state = random_state\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = -np.inf\n",
    "        self.cv_results_ = {\"mean_test_score\": []}\n",
    "        self.optimizer = None\n",
    "\n",
    "    def fit(self, X: DataFrame, y: Series, n_iter: int = 100):\n",
    "        \"\"\"Fit the Bayesian optimization search.\"\"\"\n",
    "        global training_data, train_targets, testing_data, test_targets\n",
    "        training_data, train_targets = X, y\n",
    "\n",
    "        self.optimizer = BayesianOptimization(\n",
    "            objective_function_bayesian,\n",
    "            self.param_space,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "\n",
    "        if not os.path.exists(LOGS_PATH_BAYESIAN):\n",
    "            with open(LOGS_PATH_BAYESIAN, \"w\") as fp:\n",
    "                pass\n",
    "\n",
    "        self.optimizer.subscribe(\n",
    "            Events.OPTIMIZATION_STEP, JSONLogger(LOGS_PATH_BAYESIAN, False)\n",
    "        )\n",
    "\n",
    "        # Load existing logs if available\n",
    "        if os.path.exists(LOGS_PATH_BAYESIAN):\n",
    "            load_logs(self.optimizer, logs=[LOGS_PATH_BAYESIAN])\n",
    "\n",
    "        # Perform optimization\n",
    "        self.optimizer.maximize(init_points=25, n_iter=n_iter - 25)\n",
    "\n",
    "        # Extract results\n",
    "        self.best_params_ = self.optimizer.max[\"params\"]\n",
    "        self.best_score_ = self.optimizer.max[\"target\"]\n",
    "\n",
    "        # Extract all scores for cv_results_\n",
    "        self.cv_results_[\"mean_test_score\"] = [\n",
    "            res[\"target\"] for res in self.optimizer.res\n",
    "        ]\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_grid(\n",
    "    search_method: Literal[\n",
    "        \"Grid\", \"Random\", \"SimulatedAnnealing\", \"GeneticAlgorithm\", \"Bayesian\"\n",
    "    ],\n",
    "    use_log_dist: bool = False,\n",
    ") -> ParamGrid:\n",
    "    if search_method == \"Grid\":\n",
    "        return {\n",
    "            \"nu\": [0.01, 0.05, 0.1, 0.25],\n",
    "            \"gamma\": [\"scale\", \"auto\", 0.001, 0.01, 0.1],\n",
    "            \"tol\": [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "        }\n",
    "    elif search_method in [\"Random\", \"SimulatedAnnealing\", \"GeneticAlgorithm\"]:\n",
    "        if use_log_dist:\n",
    "            return {\n",
    "                \"nu\": loguniform(0.001, 0.3),\n",
    "                \"gamma\": loguniform(1e-4, 10),\n",
    "                \"tol\": loguniform(1e-6, 1e-1),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"nu\": [0.01, 0.025, 0.05, 0.75, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "                \"gamma\": [\"scale\", \"auto\", 0.001, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1],\n",
    "                \"tol\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "            }\n",
    "    elif search_method == \"Bayesian\":\n",
    "        return {\"nu\": (0.01, 0.5), \"gamma\": (1e-4, 1), \"tol\": (1e-5, 1e-1)}\n",
    "\n",
    "\n",
    "def update_train_vars(\n",
    "    i: int, activities: ndarray\n",
    ") -> tuple[DataFrame, Series, DataFrame, Series]:\n",
    "    training = (\n",
    "        X_train[X_train[\"activity\"].isin(activities[:i])]\n",
    "        .groupby(\"activity\")\n",
    "        .head(MIN_SAMPLES)\n",
    "    )\n",
    "    testing = X_test[X_test[\"activity\"] == activities[i]].head(MIN_SAMPLES)\n",
    "    training.loc[:, \"isNovelty\"], testing.loc[:, \"isNovelty\"] = False, True\n",
    "    novelty = concat(\n",
    "        [testing, training.sample(n=int(0.15 * len(training)), random_state=42)]\n",
    "    )\n",
    "    return (\n",
    "        training.drop(columns=[\"isNovelty\"]),\n",
    "        training[\"isNovelty\"],\n",
    "        novelty.drop(columns=[\"isNovelty\"]),\n",
    "        novelty[\"isNovelty\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def train_search_method(\n",
    "    training_data: DataFrame,\n",
    "    train_targets: Series,\n",
    "    search_type: Literal[\n",
    "        \"Grid\", \"Random\", \"SimulatedAnnealing\", \"GeneticAlgorithm\", \"Bayesian\"\n",
    "    ],\n",
    "    params: dict[str, list],\n",
    "    scoring: Callable,\n",
    "    n_iter: int | None = 100,\n",
    "    cv: int = 4,\n",
    "    verbose: int = 1,\n",
    "    random_state: int = 42,\n",
    ") -> (\n",
    "    RandomizedSearchCV\n",
    "    | GridSearchCV\n",
    "    | SimulatedAnnealingSearch\n",
    "    | GeneticAlgorithmSearch\n",
    "    | BayesianOptimizationSearch\n",
    "):\n",
    "    if search_type == \"SimulatedAnnealing\":\n",
    "        return SimulatedAnnealingSearch(\n",
    "            param_space=params,\n",
    "            n_iter=n_iter or 100,\n",
    "            initial_temp=1.0,\n",
    "            cooling_rate=0.95,\n",
    "            random_state=random_state,\n",
    "        ).fit(training_data, train_targets)\n",
    "\n",
    "    elif search_type == \"GeneticAlgorithm\":\n",
    "        population_size = min(20, n_iter // 5) if n_iter else 20\n",
    "        return GeneticAlgorithmSearch(\n",
    "            param_space=params,\n",
    "            population_size=population_size,\n",
    "            n_generations=(n_iter // population_size) if n_iter else 5,\n",
    "            mutation_rate=0.1,\n",
    "            crossover_rate=0.8,\n",
    "            random_state=random_state,\n",
    "        ).fit(training_data, train_targets)\n",
    "\n",
    "    elif search_type == \"Bayesian\":\n",
    "        return BayesianOptimizationSearch(\n",
    "            param_space=params,\n",
    "            random_state=random_state,\n",
    "        ).fit(training_data, train_targets, n_iter or 100)\n",
    "\n",
    "    else:\n",
    "        search_cls = RandomizedSearchCV if search_type == \"Random\" else GridSearchCV\n",
    "        search_kwargs = {\n",
    "            f\"param_{'distributions' if search_type == 'Random' else 'grid'}\": params,\n",
    "            \"estimator\": OneClassSVM(kernel=\"rbf\"),\n",
    "            \"scoring\": scoring,\n",
    "            \"cv\": cv,\n",
    "            \"verbose\": verbose,\n",
    "            \"error_score\": \"raise\",\n",
    "        }\n",
    "        if search_type == \"Random\" and n_iter:\n",
    "            search_kwargs.update({\"n_iter\": n_iter, \"random_state\": random_state})\n",
    "        return search_cls(**search_kwargs).fit(training_data, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_search_methods(\n",
    "    grid_scores: list[float], random_scores: list[float]\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"Statistical comparison of search methods using Wilcoxon signed-rank test.\"\"\"\n",
    "    if len(grid_scores) != len(random_scores):\n",
    "        raise ValueError(\"Score arrays must have equal length\")\n",
    "\n",
    "    statistic, p_value = wilcoxon(grid_scores, random_scores, alternative=\"two-sided\")\n",
    "\n",
    "    return {\n",
    "        \"wilcoxon_statistic\": statistic,\n",
    "        \"p_value\": p_value,\n",
    "        \"grid_mean\": np.mean(grid_scores),\n",
    "        \"random_mean\": np.mean(random_scores),\n",
    "        \"effect_size\": (np.mean(grid_scores) - np.mean(random_scores))\n",
    "        / np.std(grid_scores + random_scores),\n",
    "    }\n",
    "\n",
    "\n",
    "def update_params_grid(\n",
    "    cv_results: dict[str, tuple], og_param_grid: ParamGrid\n",
    ") -> ParamGrid:\n",
    "    params = [\"gamma\", \"nu\", \"tol\"]\n",
    "    top_entries = (\n",
    "        DataFrame(\n",
    "            zip(\n",
    "                cv_results[\"rank_test_score\"],\n",
    "                cv_results[\"param_gamma\"],\n",
    "                cv_results[\"param_nu\"],\n",
    "                cv_results[\"param_tol\"],\n",
    "            ),\n",
    "            columns=[\"rank_test_score\", \"gamma\", \"nu\", \"tol\"],\n",
    "        )\n",
    "        .sort_values(\"rank_test_score\")\n",
    "        .head(NUM_TRIALS)\n",
    "    )\n",
    "\n",
    "    if len(top_entries) == NUM_TRIALS:\n",
    "        print(\"Detected potential parameter space stagnation, diversifying...\")\n",
    "\n",
    "        current_params = {col: set(top_entries[col]) for col in params}\n",
    "        unused_params = {\n",
    "            param: list(set(og_param_grid[param]) - current_params[param])\n",
    "            for param in params\n",
    "        }\n",
    "\n",
    "        for param in params:\n",
    "            if unused_params[param]:\n",
    "                current_unique = list(dict.fromkeys(top_entries[param]))\n",
    "                if len(current_unique) > 1 and unused_params[param]:\n",
    "                    current_unique = current_unique[:-1] + [unused_params[param][0]]\n",
    "                elif unused_params[param]:\n",
    "                    current_unique.append(unused_params[param][0])\n",
    "\n",
    "                top_entries.loc[\n",
    "                    top_entries[param] == list(dict.fromkeys(top_entries[param]))[-1],\n",
    "                    param,\n",
    "                ] = unused_params[param][0]\n",
    "\n",
    "    exmp = {col: list(dict.fromkeys(top_entries[col])) for col in params}\n",
    "    cartesian_size = len(exmp[\"gamma\"]) * len(exmp[\"nu\"]) * len(exmp[\"tol\"])\n",
    "\n",
    "    if cartesian_size > NUM_TRIALS:\n",
    "        while cartesian_size > NUM_TRIALS:\n",
    "            best_reduction = None\n",
    "            best_param = None\n",
    "\n",
    "            for param in params:\n",
    "                if len(exmp[param]) > 1:\n",
    "                    temp_sizes = [\n",
    "                        len(exmp[p]) if p != param else len(exmp[p]) - 1 for p in params\n",
    "                    ]\n",
    "                    new_size = temp_sizes[0] * temp_sizes[1] * temp_sizes[2]\n",
    "                    if new_size >= NUM_TRIALS and (\n",
    "                        best_reduction is None or new_size < best_reduction\n",
    "                    ):\n",
    "                        best_reduction = new_size\n",
    "                        best_param = param\n",
    "\n",
    "            if best_param is None:\n",
    "                param_lengths = [(param, len(exmp[param])) for param in params]\n",
    "                param_lengths.sort(key=lambda x: x[1], reverse=True)\n",
    "                best_param = param_lengths[0][0]\n",
    "\n",
    "            if len(exmp[best_param]) > 1:\n",
    "                exmp[best_param] = exmp[best_param][:-1]\n",
    "\n",
    "            cartesian_size = len(exmp[\"gamma\"]) * len(exmp[\"nu\"]) * len(exmp[\"tol\"])\n",
    "            if all(len(exmp[param]) == 1 for param in params):\n",
    "                break\n",
    "\n",
    "    assert cartesian_size == NUM_TRIALS, \"reducing the params space failed\"\n",
    "    print(f\"dict of len {cartesian_size} :\", exmp)\n",
    "    return exmp\n",
    "\n",
    "\n",
    "def eval_search_method(\n",
    "    activities: ndarray,\n",
    "    search_name: Literal[\n",
    "        \"Grid\", \"Random\", \"SimulatedAnnealing\", \"GeneticAlgorithm\", \"Bayesian\"\n",
    "    ],\n",
    "    use_log_dist: bool = False,\n",
    ") -> SearchResult:\n",
    "    dist = get_param_grid(search_name, use_log_dist)\n",
    "    MAXIMAZED = False\n",
    "    BEST_SCORES = None\n",
    "\n",
    "    global testing_data, test_targets, logger\n",
    "    start_time = time()\n",
    "\n",
    "    for i in range(1, len(activities)):\n",
    "        training_data, train_targets, test_data, testing_targets = update_train_vars(\n",
    "            i, activities\n",
    "        )\n",
    "        testing_data = test_data\n",
    "        test_targets = testing_targets\n",
    "        print(f\"Training for activities {activities[:i]}\")\n",
    "\n",
    "        if not MAXIMAZED:\n",
    "            search_method = train_search_method(\n",
    "                training_data=training_data,\n",
    "                train_targets=train_targets,\n",
    "                search_type=search_name,\n",
    "                params=dist,\n",
    "                scoring=score_function,\n",
    "            )\n",
    "            BEST_SCORES = search_method\n",
    "            MAXIMAZED = True\n",
    "        else:\n",
    "            print(f\"Already maximized, suggesting new {NUM_TRIALS} points\")\n",
    "            if search_name in [\"SimulatedAnnealing\", \"GeneticAlgorithm\", \"Bayesian\"]:\n",
    "                search_method = train_search_method(\n",
    "                    training_data=training_data,\n",
    "                    train_targets=train_targets,\n",
    "                    search_type=search_name,\n",
    "                    params=dist,\n",
    "                    scoring=score_function,\n",
    "                    n_iter=NUM_TRIALS,\n",
    "                )\n",
    "            else:\n",
    "                search_method = train_search_method(\n",
    "                    training_data=training_data,\n",
    "                    train_targets=train_targets,\n",
    "                    search_type=search_name,\n",
    "                    params=update_params_grid(search_method.cv_results_, dist)\n",
    "                    if search_name == \"Grid\"\n",
    "                    else dist,\n",
    "                    scoring=score_function,\n",
    "                    n_iter=NUM_TRIALS if search_name == \"Random\" else None,\n",
    "                )\n",
    "\n",
    "            if search_method.best_score_ > BEST_SCORES.best_score_:\n",
    "                BEST_SCORES = search_method\n",
    "\n",
    "        print(f\"{search_name} Search Best Params:\", search_method.best_params_)\n",
    "\n",
    "    return SearchResult(\n",
    "        method=search_name + \"_search\",\n",
    "        best_params=BEST_SCORES.best_params_,\n",
    "        best_score=BEST_SCORES.best_score_,\n",
    "        cv_scores=BEST_SCORES.cv_results_[\"mean_test_score\"].tolist()\n",
    "        if hasattr(BEST_SCORES.cv_results_[\"mean_test_score\"], \"tolist\")\n",
    "        else BEST_SCORES.cv_results_[\"mean_test_score\"],\n",
    "        fit_time=time() - start_time,\n",
    "        n_evaluations=len(BEST_SCORES.cv_results_[\"mean_test_score\"]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for activities [1]\n",
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n",
      "Grid Search Best Params: {'gamma': 'scale', 'nu': 0.01, 'tol': 0.001}\n",
      "Training for activities [1 2]\n",
      "Already maximized, suggesting new 10 points\n",
      "Detected potential parameter space stagnation, diversifying...\n",
      "dict of len 10 : {'gamma': [0.1], 'nu': [0.01, 0.25], 'tol': [0.001, 0.0001, 0.01, 1e-05, 0.1]}\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Grid Search Best Params: {'gamma': 0.1, 'nu': 0.01, 'tol': 1e-05}\n",
      "Training for activities [1 2 3]\n",
      "Already maximized, suggesting new 10 points\n",
      "Detected potential parameter space stagnation, diversifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VDUART10\\AppData\\Local\\Temp\\ipykernel_33056\\3122073337.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'auto' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  top_entries.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict of len 10 : {'gamma': ['auto'], 'nu': [0.01, 0.05], 'tol': [1e-05, 0.0001, 0.001, 0.01, 0.1]}\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Grid Search Best Params: {'gamma': 'auto', 'nu': 0.01, 'tol': 1e-05}\n",
      "Training for activities [1 2 3 4]\n",
      "Already maximized, suggesting new 10 points\n",
      "Detected potential parameter space stagnation, diversifying...\n",
      "dict of len 10 : {'gamma': [0.1], 'nu': [0.01, 0.25], 'tol': [1e-05, 0.0001, 0.001, 0.01, 0.1]}\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Grid Search Best Params: {'gamma': 0.1, 'nu': 0.01, 'tol': 0.0001}\n",
      "Training for activities [1 2 3 4 5]\n",
      "Already maximized, suggesting new 10 points\n",
      "Detected potential parameter space stagnation, diversifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VDUART10\\AppData\\Local\\Temp\\ipykernel_33056\\3122073337.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'auto' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  top_entries.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict of len 10 : {'gamma': ['auto'], 'nu': [0.01, 0.05], 'tol': [0.0001, 1e-05, 0.01, 0.001, 0.1]}\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Grid Search Best Params: {'gamma': 'auto', 'nu': 0.05, 'tol': 1e-05}\n",
      "Training for activities [1 2 3 4 5 6]\n",
      "Already maximized, suggesting new 10 points\n",
      "Detected potential parameter space stagnation, diversifying...\n",
      "dict of len 10 : {'gamma': [0.1], 'nu': [0.05, 0.25], 'tol': [1e-05, 0.0001, 0.001, 0.01, 0.1]}\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Grid Search Best Params: {'gamma': 0.1, 'nu': 0.05, 'tol': 0.001}\n",
      "Training for activities [1 2 3 4 5 6 7]\n",
      "Already maximized, suggesting new 10 points\n",
      "Detected potential parameter space stagnation, diversifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VDUART10\\AppData\\Local\\Temp\\ipykernel_33056\\3122073337.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'auto' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  top_entries.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict of len 10 : {'gamma': ['auto'], 'nu': [0.05, 0.1], 'tol': [0.001, 1e-05, 0.0001, 0.01, 0.1]}\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Grid Search Best Params: {'gamma': 'auto', 'nu': 0.05, 'tol': 0.0001}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12]\n",
      "Already maximized, suggesting new 10 points\n",
      "Detected potential parameter space stagnation, diversifying...\n",
      "dict of len 10 : {'gamma': [0.1], 'nu': [0.05, 0.25], 'tol': [0.0001, 1e-05, 0.001, 0.01, 0.1]}\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Grid Search Best Params: {'gamma': 0.1, 'nu': 0.05, 'tol': 1e-05}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13]\n",
      "Already maximized, suggesting new 10 points\n",
      "Detected potential parameter space stagnation, diversifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VDUART10\\AppData\\Local\\Temp\\ipykernel_33056\\3122073337.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'auto' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  top_entries.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict of len 10 : {'gamma': ['auto'], 'nu': [0.05, 0.1], 'tol': [1e-05, 0.0001, 0.001, 0.01, 0.1]}\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Grid Search Best Params: {'gamma': 'auto', 'nu': 0.05, 'tol': 1e-05}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16]\n",
      "Already maximized, suggesting new 10 points\n",
      "Detected potential parameter space stagnation, diversifying...\n",
      "dict of len 10 : {'gamma': [0.1], 'nu': [0.05, 0.25], 'tol': [1e-05, 0.0001, 0.001, 0.01, 0.1]}\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Grid Search Best Params: {'gamma': 0.1, 'nu': 0.05, 'tol': 1e-05}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16 17]\n",
      "Already maximized, suggesting new 10 points\n",
      "Detected potential parameter space stagnation, diversifying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VDUART10\\AppData\\Local\\Temp\\ipykernel_33056\\3122073337.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'auto' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  top_entries.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict of len 10 : {'gamma': ['auto'], 'nu': [0.05, 0.1], 'tol': [1e-05, 0.0001, 0.001, 0.01, 0.1]}\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Grid Search Best Params: {'gamma': 'auto', 'nu': 0.1, 'tol': 0.0001}\n",
      "Training for activities [1]\n",
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n",
      "Random Search Best Params: {'tol': 1e-05, 'nu': 0.01, 'gamma': 'scale'}\n",
      "Training for activities [1 2]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'tol': 0.001, 'nu': 0.1, 'gamma': 0.01}\n",
      "Training for activities [1 2 3]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'tol': 1e-05, 'nu': 0.3, 'gamma': 'scale'}\n",
      "Training for activities [1 2 3 4]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'tol': 0.001, 'nu': 0.1, 'gamma': 0.01}\n",
      "Training for activities [1 2 3 4 5]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'tol': 0.001, 'nu': 0.2, 'gamma': 0.1}\n",
      "Training for activities [1 2 3 4 5 6]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'tol': 0.001, 'nu': 0.1, 'gamma': 0.01}\n",
      "Training for activities [1 2 3 4 5 6 7]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'tol': 0.001, 'nu': 0.1, 'gamma': 0.01}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'tol': 0.001, 'nu': 0.1, 'gamma': 0.01}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'tol': 0.001, 'nu': 0.1, 'gamma': 0.01}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'tol': 0.001, 'nu': 0.1, 'gamma': 0.01}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16 17]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'tol': 0.001, 'nu': 0.1, 'gamma': 0.01}\n",
      "Training for activities [1]\n",
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.00012104285107995026), 'nu': np.float64(0.018557377359658574), 'tol': np.float64(1.356684539787923e-05)}\n",
      "Training for activities [1 2]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.0004982752357076451), 'nu': np.float64(0.005292705365436975), 'tol': np.float64(6.789053271698483e-05)}\n",
      "Training for activities [1 2 3]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.0004982752357076451), 'nu': np.float64(0.005292705365436975), 'tol': np.float64(6.789053271698483e-05)}\n",
      "Training for activities [1 2 3 4]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.0004982752357076451), 'nu': np.float64(0.005292705365436975), 'tol': np.float64(6.789053271698483e-05)}\n",
      "Training for activities [1 2 3 4 5]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.019069966103000432), 'nu': np.float64(0.08810003129071789), 'tol': np.float64(9.962513222055122e-06)}\n",
      "Training for activities [1 2 3 4 5 6]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.019069966103000432), 'nu': np.float64(0.08810003129071789), 'tol': np.float64(9.962513222055122e-06)}\n",
      "Training for activities [1 2 3 4 5 6 7]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.0008260808399079611), 'nu': np.float64(0.005670807781371429), 'tol': np.float64(0.0004205156450913873)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.019069966103000432), 'nu': np.float64(0.08810003129071789), 'tol': np.float64(9.962513222055122e-06)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.0004982752357076451), 'nu': np.float64(0.005292705365436975), 'tol': np.float64(6.789053271698483e-05)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.0004982752357076451), 'nu': np.float64(0.005292705365436975), 'tol': np.float64(6.789053271698483e-05)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16 17]\n",
      "Already maximized, suggesting new 10 points\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Random Search Best Params: {'gamma': np.float64(0.0004982752357076451), 'nu': np.float64(0.005292705365436975), 'tol': np.float64(6.789053271698483e-05)}\n",
      "Training for activities [1]\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.008206791755834107), 'gamma': np.float64(0.008085151365991677), 'tol': np.float64(6.842347758855007e-05)}\n",
      "Training for activities [1 2]\n",
      "Already maximized, suggesting new 10 points\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.009971956114148275), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(8.366665612175694e-05)}\n",
      "Training for activities [1 2 3]\n",
      "Already maximized, suggesting new 10 points\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [1 2 3 4]\n",
      "Already maximized, suggesting new 10 points\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [1 2 3 4 5]\n",
      "Already maximized, suggesting new 10 points\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.009112860069469446), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(8.659034062360148e-05)}\n",
      "Training for activities [1 2 3 4 5 6]\n",
      "Already maximized, suggesting new 10 points\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.00841321432247402), 'gamma': np.float64(0.01153577054563649), 'tol': np.float64(6.857824013833442e-05)}\n",
      "Training for activities [1 2 3 4 5 6 7]\n",
      "Already maximized, suggesting new 10 points\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.00913664795844126), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(0.00012296242901626252)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12]\n",
      "Already maximized, suggesting new 10 points\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.008617181294313481), 'gamma': np.float64(0.010730547362627702), 'tol': np.float64(8.752811031287249e-05)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13]\n",
      "Already maximized, suggesting new 10 points\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(0.00012296242901626252)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16]\n",
      "Already maximized, suggesting new 10 points\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(8.659034062360148e-05)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16 17]\n",
      "Already maximized, suggesting new 10 points\n",
      "SimulatedAnnealing Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [1]\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [1 2]\n",
      "Already maximized, suggesting new 10 points\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [1 2 3]\n",
      "Already maximized, suggesting new 10 points\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [1 2 3 4]\n",
      "Already maximized, suggesting new 10 points\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [1 2 3 4 5]\n",
      "Already maximized, suggesting new 10 points\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [1 2 3 4 5 6]\n",
      "Already maximized, suggesting new 10 points\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [1 2 3 4 5 6 7]\n",
      "Already maximized, suggesting new 10 points\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12]\n",
      "Already maximized, suggesting new 10 points\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13]\n",
      "Already maximized, suggesting new 10 points\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16]\n",
      "Already maximized, suggesting new 10 points\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16 17]\n",
      "Already maximized, suggesting new 10 points\n",
      "Evaluating Generation 0\n",
      "Evaluating Generation 1\n",
      "Evaluating Generation 2\n",
      "Evaluating Generation 3\n",
      "Evaluating Generation 4\n",
      "GeneticAlgorithm Search Best Params: {'nu': np.float64(0.008468008575248327), 'gamma': np.float64(0.0074593432857265485), 'tol': np.float64(7.459343285726558e-05)}\n",
      "Training for activities [1]\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n",
      "Training for activities [1 2]\n",
      "Already maximized, suggesting new 10 points\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n",
      "Training for activities [1 2 3]\n",
      "Already maximized, suggesting new 10 points\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n",
      "Training for activities [1 2 3 4]\n",
      "Already maximized, suggesting new 10 points\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n",
      "Training for activities [1 2 3 4 5]\n",
      "Already maximized, suggesting new 10 points\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n",
      "Training for activities [1 2 3 4 5 6]\n",
      "Already maximized, suggesting new 10 points\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n",
      "Training for activities [1 2 3 4 5 6 7]\n",
      "Already maximized, suggesting new 10 points\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12]\n",
      "Already maximized, suggesting new 10 points\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13]\n",
      "Already maximized, suggesting new 10 points\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16]\n",
      "Already maximized, suggesting new 10 points\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16 17]\n",
      "Already maximized, suggesting new 10 points\n",
      "Bayesian Search Best Params: {'gamma': np.float64(0.002748232495731026), 'nu': np.float64(0.014533824703500385), 'tol': np.float64(0.006762806191316482)}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Score arrays must have equal length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Save comparison results\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m../conf/test_results.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     24\u001b[39m     file.write(\n\u001b[32m     25\u001b[39m         dumps(\n\u001b[32m     26\u001b[39m             [\n\u001b[32m     27\u001b[39m                 {\n\u001b[32m     28\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mGrid x Rand\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m                     **compare_search_methods(\n\u001b[32m     30\u001b[39m                         grid_result.cv_scores, rand_result.cv_scores\n\u001b[32m     31\u001b[39m                     ),\n\u001b[32m     32\u001b[39m                 },\n\u001b[32m     33\u001b[39m                 {\n\u001b[32m     34\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mGrid x SA\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     35\u001b[39m                     **compare_search_methods(\n\u001b[32m     36\u001b[39m                         grid_result.cv_scores, sa_result.cv_scores\n\u001b[32m     37\u001b[39m                     ),\n\u001b[32m     38\u001b[39m                 },\n\u001b[32m     39\u001b[39m                 {\n\u001b[32m     40\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mGrid x GA\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m                     **compare_search_methods(\n\u001b[32m     42\u001b[39m                         grid_result.cv_scores, ga_result.cv_scores\n\u001b[32m     43\u001b[39m                     ),\n\u001b[32m     44\u001b[39m                 },\n\u001b[32m     45\u001b[39m                 {\n\u001b[32m     46\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mGrid x Bayesian\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m                     **\u001b[43mcompare_search_methods\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgrid_result\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcv_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbayesian_result\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcv_scores\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     50\u001b[39m                 },\n\u001b[32m     51\u001b[39m                 {\n\u001b[32m     52\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRand x SA\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     53\u001b[39m                     **compare_search_methods(\n\u001b[32m     54\u001b[39m                         rand_result.cv_scores, sa_result.cv_scores\n\u001b[32m     55\u001b[39m                     ),\n\u001b[32m     56\u001b[39m                 },\n\u001b[32m     57\u001b[39m                 {\n\u001b[32m     58\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRand x GA\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m                     **compare_search_methods(\n\u001b[32m     60\u001b[39m                         rand_result.cv_scores, ga_result.cv_scores\n\u001b[32m     61\u001b[39m                     ),\n\u001b[32m     62\u001b[39m                 },\n\u001b[32m     63\u001b[39m                 {\n\u001b[32m     64\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRand x Bayesian\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     65\u001b[39m                     **compare_search_methods(\n\u001b[32m     66\u001b[39m                         rand_result.cv_scores, bayesian_result.cv_scores\n\u001b[32m     67\u001b[39m                     ),\n\u001b[32m     68\u001b[39m                 },\n\u001b[32m     69\u001b[39m                 {\n\u001b[32m     70\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSA x GA\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m                     **compare_search_methods(sa_result.cv_scores, ga_result.cv_scores),\n\u001b[32m     72\u001b[39m                 },\n\u001b[32m     73\u001b[39m                 {\n\u001b[32m     74\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSA x Bayesian\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     75\u001b[39m                     **compare_search_methods(\n\u001b[32m     76\u001b[39m                         sa_result.cv_scores, bayesian_result.cv_scores\n\u001b[32m     77\u001b[39m                     ),\n\u001b[32m     78\u001b[39m                 },\n\u001b[32m     79\u001b[39m                 {\n\u001b[32m     80\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mGA x Bayesian\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     81\u001b[39m                     **compare_search_methods(\n\u001b[32m     82\u001b[39m                         ga_result.cv_scores, bayesian_result.cv_scores\n\u001b[32m     83\u001b[39m                     ),\n\u001b[32m     84\u001b[39m                 },\n\u001b[32m     85\u001b[39m             ]\n\u001b[32m     86\u001b[39m         )\n\u001b[32m     87\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mcompare_search_methods\u001b[39m\u001b[34m(grid_scores, random_scores)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Statistical comparison of search methods using Wilcoxon signed-rank test.\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(grid_scores) != \u001b[38;5;28mlen\u001b[39m(random_scores):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mScore arrays must have equal length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m statistic, p_value = wilcoxon(grid_scores, random_scores, alternative=\u001b[33m\"\u001b[39m\u001b[33mtwo-sided\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwilcoxon_statistic\u001b[39m\u001b[33m\"\u001b[39m: statistic,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mp_value\u001b[39m\u001b[33m\"\u001b[39m: p_value,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     / np.std(grid_scores + random_scores),\n\u001b[32m     17\u001b[39m }\n",
      "\u001b[31mValueError\u001b[39m: Score arrays must have equal length"
     ]
    }
   ],
   "source": [
    "activities = X_train[\"activity\"].unique()\n",
    "\n",
    "# Run all search methods\n",
    "logger = configure_file_logger(\"../reports/logs_grid.log\")\n",
    "grid_result = eval_search_method(activities, \"Grid\")\n",
    "\n",
    "logger = configure_file_logger(\"../reports/logs_rand.log\")\n",
    "rand_result = eval_search_method(activities, \"Random\")\n",
    "\n",
    "logger = configure_file_logger(\"../reports/logs_rand_log.log\")\n",
    "rand_log_result = eval_search_method(activities, \"Random\", True)\n",
    "\n",
    "logger = configure_file_logger(\"../reports/logs_sian.log\")\n",
    "sa_result = eval_search_method(activities, \"SimulatedAnnealing\", True)\n",
    "\n",
    "logger = configure_file_logger(\"../reports/logs_geal.log\")\n",
    "ga_result = eval_search_method(activities, \"GeneticAlgorithm\", True)\n",
    "\n",
    "logger = configure_file_logger(\"../reports/logs_bayesian.log\")\n",
    "bayesian_result = eval_search_method(activities, \"Bayesian\", True)\n",
    "\n",
    "# Save comparison results\n",
    "with open(\"../conf/test_results.json\", \"w\") as file:\n",
    "    file.write(\n",
    "        dumps(\n",
    "            [\n",
    "                {\n",
    "                    \"test\": \"Grid x Rand\",\n",
    "                    **compare_search_methods(\n",
    "                        grid_result.cv_scores, rand_result.cv_scores\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"test\": \"Grid x SA\",\n",
    "                    **compare_search_methods(\n",
    "                        grid_result.cv_scores, sa_result.cv_scores\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"test\": \"Grid x GA\",\n",
    "                    **compare_search_methods(\n",
    "                        grid_result.cv_scores, ga_result.cv_scores\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"test\": \"Grid x Bayesian\",\n",
    "                    **compare_search_methods(\n",
    "                        grid_result.cv_scores, bayesian_result.cv_scores\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"test\": \"Rand x SA\",\n",
    "                    **compare_search_methods(\n",
    "                        rand_result.cv_scores, sa_result.cv_scores\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"test\": \"Rand x GA\",\n",
    "                    **compare_search_methods(\n",
    "                        rand_result.cv_scores, ga_result.cv_scores\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"test\": \"Rand x Bayesian\",\n",
    "                    **compare_search_methods(\n",
    "                        rand_result.cv_scores, bayesian_result.cv_scores\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"test\": \"SA x GA\",\n",
    "                    **compare_search_methods(sa_result.cv_scores, ga_result.cv_scores),\n",
    "                },\n",
    "                {\n",
    "                    \"test\": \"SA x Bayesian\",\n",
    "                    **compare_search_methods(\n",
    "                        sa_result.cv_scores, bayesian_result.cv_scores\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"test\": \"GA x Bayesian\",\n",
    "                    **compare_search_methods(\n",
    "                        ga_result.cv_scores, bayesian_result.cv_scores\n",
    "                    ),\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
