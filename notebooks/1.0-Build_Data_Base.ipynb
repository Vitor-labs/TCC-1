{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pandas import DataFrame, Series, read_csv, set_option, concat\n",
    "\n",
    "set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_w_log(path: str, filename: str) -> DataFrame:\n",
    "    print('reading', filename)\n",
    "    df: DataFrame = read_csv(\n",
    "            os.path.join(path, filename),\n",
    "            sep='\\s+',\n",
    "            header=None\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_data(path: str, test_size: float = 0.2) -> tuple[DataFrame, DataFrame, DataFrame, DataFrame]:\n",
    "    train_data, test_data, train_targets, test_targets = [], [], [], []\n",
    "    for df in [\n",
    "        read_w_log(path, filename)\n",
    "        for filename in os.listdir(path)\n",
    "        if filename.endswith('.dat')\n",
    "    ]:\n",
    "        df:DataFrame = df[df[1] != 0].dropna().sort_values(1) # type: ignore\n",
    "        # for every class drop the last 20% of the data\n",
    "        for label in df[1].unique():\n",
    "            data = df[df[1] == label]\n",
    "            SIZE = int((1 - test_size) * len(data))\n",
    "            X, y = data.drop(columns=[1,2]), data[1]\n",
    "            # as it's a time series, we split by slice the last 20% of the data\n",
    "            X_train, X_test = X[:SIZE], X[SIZE:]\n",
    "            y_train, y_test = y[:SIZE], y[SIZE:]\n",
    "\n",
    "            train_data.append(X_train)\n",
    "            test_data.append(X_test)\n",
    "            train_targets.append(y_train)\n",
    "            test_targets.append(y_test)\n",
    "\n",
    "    X_train = concat(train_data)\n",
    "    X_test = concat(test_data)\n",
    "    y_train = concat(train_targets)\n",
    "    y_test = concat(test_targets)\n",
    "\n",
    "    # Sanity check\n",
    "    print(\"Train Shape:\", X_train.shape)\n",
    "    print(\"Test Shape:\", X_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading subject102.dat\n",
      "reading subject104.dat\n",
      "reading subject103.dat\n",
      "reading subject101.dat\n",
      "reading subject105.dat\n",
      "reading subject109.dat\n",
      "reading subject107.dat\n",
      "reading subject108.dat\n",
      "reading subject106.dat\n",
      "Train Shape: (140360, 52)\n",
      "Test Shape: (35138, 52)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data('../data/PAMAP2_Dataset/Protocol/', .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading subject102.dat\n",
      "reading subject104.dat\n",
      "reading subject103.dat\n",
      "reading subject101.dat\n",
      "reading subject105.dat\n",
      "reading subject107.dat\n",
      "reading subject108.dat\n",
      "reading subject106.dat\n",
      "Train Shape: (139932, 52)\n",
      "Test Shape: (34983, 52)\n"
     ]
    }
   ],
   "source": [
    "def split_data() -> tuple[Series, Series, DataFrame, Series, Series, DataFrame]:\n",
    "    TEST_SIZE = 0.2\n",
    "    X_train, X_test, y_train, y_test = load_data('../data/PAMAP2_Dataset/Protocol/', TEST_SIZE)\n",
    "\n",
    "    VAL_SIZE = int(TEST_SIZE * len(X_train))\n",
    "    X_valid, X_train = X_train[:VAL_SIZE], X_train[VAL_SIZE:]\n",
    "    y_valid, y_train = y_train[:VAL_SIZE], y_train[VAL_SIZE:]\n",
    "\n",
    "    X_train.to_csv('../data/PAMAP2/x_train_data.csv', index=False)\n",
    "    X_valid.to_csv('../data/PAMAP2/x_val_data.csv', index=False)\n",
    "    X_test.to_csv('../data/PAMAP2/x_test_data.csv', index=False)\n",
    "    y_train.to_csv('../data/PAMAP2/y_train_data.csv', index=False)\n",
    "    y_valid.to_csv('../data/PAMAP2/y_val_data.csv', index=False)\n",
    "    y_test.to_csv('../data/PAMAP2/y_test_data.csv', index=False)\n",
    "\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC-1-pCv1QtoV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
