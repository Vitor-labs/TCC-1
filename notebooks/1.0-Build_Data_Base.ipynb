{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, concat, read_csv, set_option, to_datetime\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "set_option(\"display.max_columns\", None)\n",
    "\n",
    "COLUMNS: list[str] = [\n",
    "\t\"timestamp\",\n",
    "\t\"activity\",\n",
    "\t\"heart_rate\",\n",
    "\t*[\n",
    "\t\tf\"IMU_{body_part}_{suffix}\"\n",
    "\t\tfor body_part in [\"hand\", \"chest\", \"ankle\"]\n",
    "\t\tfor suffix in [\n",
    "\t\t\t\"temp_C\",\n",
    "\t\t\t*[\n",
    "\t\t\t\tf\"{scalar}_{axis}\"\n",
    "\t\t\t\tfor scalar in [\"acc16g_ms^-2\", \"acc6g_ms^-2\", \"gyro_rad/s\", \"mag_μT\"]\n",
    "\t\t\t\tfor axis in [\"x\", \"y\", \"z\"]\n",
    "\t\t\t],\n",
    "\t\t\t*[f\"orient_{x}\" for x in range(1, 5)],\n",
    "\t\t]\n",
    "\t],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_w_log(path: Path, filename: str) -> tuple[DataFrame, str]:\n",
    "\t\"\"\"\n",
    "\tThe IMU sensory data contains the following columns:\n",
    "\t- 1 temperature (°C)\n",
    "\t- 2...4 3D-acceleration data (ms^-2), scale: ±16g, resolution: 13-bit\n",
    "\t- 5...7 3D-acceleration data (ms^-2), scale: ±6g, resolution: 13-bit*\n",
    "\t- 8...10 3D-gyroscope data (rad/s)\n",
    "\t- 11...13 3D-magnetometer data (μT)\n",
    "\t- 14...17 orientation (invalid in this data collection)\n",
    "\n",
    "\t* This accelerometer is not precisely calibrated with the first one. Moreover, due\n",
    "\tto high impacts caused by certain movements (e.g. during running) with acceleration\n",
    "\tover 6g, it gets saturated sometimes. Therefore, the use of the data from the first\n",
    "\taccelerometer (with the scale of ±16g) is recommended.\n",
    "\t\"\"\"\n",
    "\tprint(f\"Reading: {filename}\", end=\"\\r\")\n",
    "\tdf = read_csv(os.path.join(path, filename), sep=r\"\\s+\", header=None)\n",
    "\tdf.columns = COLUMNS\n",
    "\treturn (\n",
    "\t\tdf.loc[\n",
    "\t\t\t:,\n",
    "\t\t\t~df.columns.str.contains(\"orient\") & ~df.columns.str.contains(\"acc6g\"),\n",
    "\t\t],\n",
    "\t\tfilename.split(\".\")[0][-2:],\n",
    "\t)\n",
    "\n",
    "\n",
    "def handle_nans(df: DataFrame) -> DataFrame:\n",
    "\t\"\"\"\n",
    "\tHandles NaN values in the sensor data with a time-series-aware strategy.\n",
    "\n",
    "\t- First, forward-fills to propagate the last valid observation.\n",
    "\t- Then, uses linear interpolation for short gaps.\n",
    "\t- Finally, drops any rows where sensor data is still missing.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdf: The input DataFrame with potential NaN values.\n",
    "\n",
    "\tReturns:\n",
    "\t\tDataFrame with NaNs handled.\n",
    "\t\"\"\"\n",
    "\t# For IMU data: linear interpolation for short gaps, drop for long gaps\n",
    "\tfor col in (imu_cols := [col for col in df.columns if col.startswith(\"IMU_\")]):\n",
    "\t\t# Forward fill first (sensor readings typically persist briefly)\n",
    "\t\tdf.loc[:, col] = df[col].ffill(limit=2)\n",
    "\t\t# Only interpolate if gap is ≤ 5 samples (0.05s at 100Hz)\n",
    "\t\t# IMU gaps can be interpolated without significant information loss.\n",
    "\t\tdf.loc[:, col] = df[col].interpolate(\"linear\", limit=5, limit_direction=\"both\")\n",
    "\t# Drop rows where ANY IMU sensor still has NaN (likely sensor disconnection)\n",
    "\treturn df.dropna(subset=imu_cols)\n",
    "\n",
    "\n",
    "def normalize_features(data: DataFrame) -> DataFrame:\n",
    "\t\"\"\"\n",
    "\tNormalize features using training set statistics\n",
    "\n",
    "\tArgs:\n",
    "\t\tX_train (Dataframe): training data\n",
    "\t\tX_test (Dataframe): testing data\n",
    "\n",
    "\tReturns:\n",
    "\t\ttuple[DataFrame, DataFrame]: scaled train and test data\n",
    "\t\"\"\"\n",
    "\t# Use RobustScaler for IMU data (less sensitive to outliers)\n",
    "\tif imu_columns := [col for col in data.columns if col.startswith(\"IMU_\")]:\n",
    "\t\tdata.loc[:, imu_columns] = RobustScaler().fit_transform(data[imu_columns])\n",
    "\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Mod proposal_: **Subject-Based Splitting**\n",
    "\n",
    "> In novelty detection, you want to detect unseen patterns. If the same subject appears in both train and test, the model learns subject-specific characteristics, which won't generalize to new users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: subject109.dat\r"
     ]
    }
   ],
   "source": [
    "def load_data(path: Path, norm_features: bool = True) -> tuple[DataFrame, DataFrame]:\n",
    "\tdata, labels = [], []\n",
    "\tfor df, subject in [  # all protocol files\n",
    "\t\tread_w_log(path, filename)\n",
    "\t\tfor filename in os.listdir(path)\n",
    "\t\tif filename.endswith(\".dat\")\n",
    "\t]:  # droping rope jumping (24) cause only subject 9 does this activity\n",
    "\t\tdf = handle_nans(df[~df[\"activity\"].isin([0, 24])])\n",
    "\t\tdf[\"subject\"] = str(subject)\n",
    "\t\tdf[\"timestamp\"] = to_datetime(df[\"timestamp\"], unit=\"s\").dt.time\n",
    "\n",
    "\t\tdata.append(df.drop(columns=[\"activity\", \"heart_rate\"]))\n",
    "\t\tlabels.append(df[[\"timestamp\", \"activity\"]])  # Index & Activity\n",
    "\n",
    "\tdata, labels = concat(data), concat(labels)\n",
    "\tdata[\"subject\"] = data[\"subject\"].astype(\"category\")\n",
    "\tlabels[\"activity\"] = labels[\"activity\"].astype(\"category\")\n",
    "\n",
    "\treturn (normalize_features(data), labels) if norm_features else (data, labels)\n",
    "\n",
    "\n",
    "data, labels = load_data(Path(\"../data/PAMAP2_Dataset/Protocol/\"))\n",
    "df = data.merge(labels, how=\"left\", on=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_date = datetime.today().date()\n",
    "df[\"datetime\"] = df[\"timestamp\"].apply(lambda t: datetime.combine(base_date, t))\n",
    "\n",
    "df = df.sort_values([\"subject\", \"datetime\"])\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "subjects = df[\"subject\"].unique()\n",
    "subject_positions = {subject: i for i, subject in enumerate(subjects)}\n",
    "\n",
    "activities = df[\"activity\"].unique()\n",
    "colors = plt.cm.tab10(range(len(activities)))\n",
    "activity_colors = {activity: colors[i] for i, activity in enumerate(activities)}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "\tax.barh(\n",
    "\t\tsubject_positions[row[\"subject\"]],\n",
    "\t\ttimedelta(minutes=30),\n",
    "\t\tleft=row[\"datetime\"],\n",
    "\t\theight=0.8,\n",
    "\t\tcolor=activity_colors[row[\"activity\"]],\n",
    "\t\tedgecolor=\"black\",\n",
    "\t\tlinewidth=0.5,\n",
    "\t\tlabel=row[\"activity\"]\n",
    "\t\tif row[\"activity\"] not in ax.get_legend_handles_labels()[1]\n",
    "\t\telse \"\",\n",
    "\t)\n",
    "ax.set_yticks(range(len(subjects)))\n",
    "ax.set_yticklabels(subjects)\n",
    "ax.set_xlabel(\"Time\", fontsize=12)\n",
    "ax.set_ylabel(\"Subject\", fontsize=12)\n",
    "ax.set_title(\"Activity Timeline by Subject\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "ax.legend(\n",
    "\tby_label.values(),\n",
    "\tby_label.keys(),\n",
    "\ttitle=\"Activities\",\n",
    "\tbbox_to_anchor=(1.05, 1),\n",
    "\tloc=\"upper left\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.grid(axis=\"x\", alpha=0.3, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(\n",
    "\ttest_activities: tuple[str, ...] = (\"08\", \"09\"),\n",
    ") -> tuple[DataFrame, DataFrame, DataFrame, DataFrame]:\n",
    "\tdata, labels = load_data(Path(\"../data/PAMAP2_Dataset/Protocol/\"))\n",
    "\n",
    "\tX_train.to_csv(\"../data/PAMAP2/x_train_data.csv\", index=False)\n",
    "\ty_train.to_csv(\"../data/PAMAP2/y_train_data.csv\", index=False)\n",
    "\tX_test.to_csv(\"../data/PAMAP2/x_test_data.csv\", index=False)\n",
    "\ty_test.to_csv(\"../data/PAMAP2/y_test_data.csv\", index=False)\n",
    "\n",
    "\treturn X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data()\n",
    "print(\"Train Shape:\", X_train.shape, \"\\nTest Shape:\", X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
