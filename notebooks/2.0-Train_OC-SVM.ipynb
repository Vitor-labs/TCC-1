{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from json import load\n",
    "from typing import Final\n",
    "\n",
    "from numpy import ndarray, where\n",
    "from pandas import DataFrame, Series, concat, read_csv, set_option\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "set_option(\"display.max_columns\", None)\n",
    "\n",
    "NUM_TRIALS: Final[int] = 5\n",
    "LOGS_PATH: Final[str] = \"../reports/logs_normal.log\"\n",
    "CONF_PATH: Final[str] = \"../conf/model_configs.json\"\n",
    "MODELS = {\n",
    "    \"SGDOneClassSVM\": SGDOneClassSVM(),\n",
    "    \"OneClassSVM\": OneClassSVM(kernel=\"rbf\"),\n",
    "    \"IsolationForest\": IsolationForest(),\n",
    "    \"LocalOutlierFactor\": LocalOutlierFactor(novelty=True),\n",
    "    # Set novelty=True for training/prediction workflow\n",
    "}\n",
    "logging.basicConfig(filename=LOGS_PATH, level=logging.INFO)\n",
    "\n",
    "with open(CONF_PATH, \"r\") as f:\n",
    "    for model in (MODEL_CONFIGS := load(f)):\n",
    "        MODEL_CONFIGS[model][\"model\"] = MODELS[model]\n",
    "\n",
    "    MODELS = MODEL_CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = read_csv(\"../data/PAMAP2/x_train_data.csv\")\n",
    "X_test = read_csv(\"../data/PAMAP2/x_test_data.csv\")\n",
    "y_train = read_csv(\"../data/PAMAP2/y_train_data.csv\")\n",
    "y_test = read_csv(\"../data/PAMAP2/y_test_data.csv\")\n",
    "\n",
    "X_train[\"activity\"] = y_train  # First 80% of the data\n",
    "X_test[\"activity\"] = y_test  # Last 20% of the data\n",
    "\n",
    "models: dict[int, dict] = {}\n",
    "training_data: DataFrame\n",
    "testing_data: DataFrame\n",
    "train_targets: Series\n",
    "test_targets: Series\n",
    "\n",
    "RESULTS: dict[int, dict[str, float | int]] = {}\n",
    "MIN_SAMPLES = X_train[\"activity\"].value_counts().sort_values().iloc[0]\n",
    "MAXIMAZED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(\n",
    "    model: OneClassSVM | SGDOneClassSVM | IsolationForest | LocalOutlierFactor,\n",
    "    Train: DataFrame,  # only for API compliance\n",
    "    test: Series,  # only for API compliance\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Objective function to maximize, calcs the F1 score on the test set.\n",
    "    follows the format needed by scikit-learn's API.\n",
    "\n",
    "    Args:\n",
    "        model (OneClassSVM): Model to eval\n",
    "        X_test (DataFrame): train data, only for API compliance\n",
    "        y_true (Series): true targets, only for API compliance\n",
    "\n",
    "    Returns:\n",
    "        float: F1 score\n",
    "    \"\"\"\n",
    "    f1 = f1_score(test_targets, where(model.predict(testing_data) == -1, True, False))\n",
    "    logging.info(\n",
    "        {\n",
    "            \"target\": f1,\n",
    "            \"params\": model.get_params(),\n",
    "            \"datetime\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%s\"),\n",
    "        }\n",
    "    )\n",
    "    return float(f1)\n",
    "\n",
    "\n",
    "def update_train_vars(\n",
    "    i: int, activities: ndarray\n",
    ") -> tuple[DataFrame, Series, DataFrame, Series]:\n",
    "    training = (  # picks the first n samples of each class\n",
    "        X_train[X_train[\"activity\"].isin(activities[:i])]\n",
    "        .groupby(\"activity\")\n",
    "        .head(MIN_SAMPLES)\n",
    "    )\n",
    "    testing = X_test[X_test[\"activity\"] == activities[i]].head(MIN_SAMPLES)\n",
    "    training.loc[:, \"isNovelty\"], testing.loc[:, \"isNovelty\"] = False, True\n",
    "    novelty = concat(\n",
    "        [testing, training.sample(n=int(0.15 * len(training)), random_state=42)]\n",
    "    )\n",
    "    return (\n",
    "        training.drop(columns=[\"isNovelty\"]),\n",
    "        training[\"isNovelty\"],\n",
    "        # only current activity (as novelty)\n",
    "        novelty.drop(columns=[\"isNovelty\"]),\n",
    "        novelty[\"isNovelty\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Description:\n",
    "\n",
    "- tol: Defines the tolerance for the optimization solver (SMO). The algorithm stops iterating when the improvement in the objective function is smaller than this value.\n",
    "- nu: Controls the fraction of the dataset that is considered anomalies/outliers. It must be in the range (0, 1].   \n",
    "  - A ggressive anomaly detectionfor for nu > 0.5, \n",
    "- gamma: Defines how much influence a single training example has. This is the parameter for the Gaussian kernel\n",
    "  - $ K(x_i,x_j​)=exp(−γ∣∣x_i​−x_j​∣∣²) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Running grid search for SGDOneClassSVM\n",
      "==================================================\n",
      "CONFIGS:  SGDOneClassSVM()\n",
      "PARAMS:  {'nu': [0.01, 0.05, 0.1, 0.2, 0.3, 0.5], 'learning_rate': ['optimal', 'constant', 'invscaling', 'adaptive'], 'alpha': [0.0001, 0.001, 0.01, 0.1]}\n",
      "\n",
      "==================================================\n",
      "Running grid search for OneClassSVM\n",
      "==================================================\n",
      "CONFIGS:  OneClassSVM()\n",
      "PARAMS:  {'nu': [0.01, 0.05, 0.1, 0.2, 0.3, 0.5], 'gamma': [0.001, 0.01, 0.1, 0.5, 1]}\n",
      "\n",
      "==================================================\n",
      "Running grid search for IsolationForest\n",
      "==================================================\n",
      "CONFIGS:  IsolationForest()\n",
      "PARAMS:  {'n_estimators': [50, 100, 200], 'contamination': [0.01, 0.05, 0.1, 0.2, 0.3], 'max_samples': ['auto', 100, 500, 1000]}\n",
      "\n",
      "==================================================\n",
      "Running grid search for LocalOutlierFactor\n",
      "==================================================\n",
      "CONFIGS:  LocalOutlierFactor(novelty=True)\n",
      "PARAMS:  {'n_neighbors': [5, 10, 20, 50], 'contamination': [0.01, 0.05, 0.1, 0.2, 0.3], 'metric': ['euclidean', 'manhattan']}\n"
     ]
    }
   ],
   "source": [
    "for model_name, config in MODEL_CONFIGS.items():\n",
    "    print(f\"\\n{'=' * 50}\\nRunning grid search for {model_name}\\n{'=' * 50}\")\n",
    "    print(\"CONFIGS: \", config[\"model\"])\n",
    "    print(\"PARAMS: \", config[\"grid_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params_grid(cv_results: dict[str, list]) -> dict[str, list]:\n",
    "    data = (\n",
    "        DataFrame(\n",
    "            zip(\n",
    "                cv_results[\"rank_test_score\"],\n",
    "                cv_results[\"param_gamma\"],\n",
    "                cv_results[\"param_nu\"],\n",
    "                cv_results[\"param_tol\"],\n",
    "            ),\n",
    "            columns=[\"rank_test_score\", \"gamma\", \"nu\", \"tol\"],\n",
    "        )\n",
    "        .sort_values(\"rank_test_score\")\n",
    "        .head(NUM_TRIALS)\n",
    "        .drop(\"rank_test_score\", axis=1)\n",
    "        .to_dict(orient=\"list\")\n",
    "    )\n",
    "    return {col: list(dict.fromkeys(data[col])) for col in [\"gamma\", \"nu\", \"tol\"]}\n",
    "\n",
    "\n",
    "def train_grid_optimizer(grid: dict[str, list]) -> GridSearchCV:\n",
    "    return GridSearchCV(\n",
    "        estimator=OneClassSVM(kernel=\"rbf\"),\n",
    "        param_grid=grid,\n",
    "        scoring=score_function,\n",
    "        # n_jobs=-1,\n",
    "        cv=4,\n",
    "        verbose=1,\n",
    "        error_score=\"raise\",\n",
    "    ).fit(training_data, train_targets)\n",
    "\n",
    "\n",
    "for i in range(1, len((activities := X_train[\"activity\"].unique()))):\n",
    "    training_data, train_targets, testing_data, test_targets = update_train_vars(\n",
    "        i, activities\n",
    "    )\n",
    "    print(f\"Training for activities {activities[:i]}\")\n",
    "    if not MAXIMAZED:\n",
    "        grid_search = train_grid_optimizer(\n",
    "            {\n",
    "                \"tol\": [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                # Tolerance for Stopping Criterion\n",
    "                \"nu\": [0.01, 0.05, 0.1, 0.25, 0.5],\n",
    "                # Upper Bound on Outliers & Lower Bound on Support Vectors\n",
    "                \"gamma\": [0.001, 0.01, 0.1, 0.5, 1],\n",
    "                # Kernel Coefficient for RBF Kernel\n",
    "            }\n",
    "        )\n",
    "        MAXIMAZED = True\n",
    "    else:\n",
    "        print(f\"Already maximized, sugesting new {NUM_TRIALS} points\")\n",
    "        grid_search = train_grid_optimizer(update_params_grid(grid_search.cv_results_))  # type: ignore\n",
    "    print(\"Grid Search Best Params:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_optimizer(iters: int) -> RandomizedSearchCV:\n",
    "    return RandomizedSearchCV(\n",
    "        estimator=OneClassSVM(kernel=\"rbf\"),\n",
    "        param_distributions={\n",
    "            \"nu\": [0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "            \"gamma\": [0.001, 0.01, 0.1, 0.5, 1],\n",
    "            \"tol\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        },\n",
    "        n_iter=iters,\n",
    "        scoring=score_function,\n",
    "        # n_jobs=-1,\n",
    "        cv=4,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        error_score=\"raise\",\n",
    "    ).fit(training_data, train_targets)\n",
    "\n",
    "\n",
    "for i in range(1, len((activities := X_train[\"activity\"].unique()))):\n",
    "    training_data, train_targets, testing_data, test_targets = update_train_vars(\n",
    "        i, activities\n",
    "    )\n",
    "    print(f\"Training for activities {activities[:i]}\")\n",
    "    if not MAXIMAZED:\n",
    "        random_search = train_optimizer(100)\n",
    "        MAXIMAZED = True\n",
    "    else:\n",
    "        print(f\"Already maximized, sugesting new {NUM_TRIALS} points\")\n",
    "        random_search = train_optimizer(NUM_TRIALS)\n",
    "    print(\n",
    "        f\"Random Search. Best Params: {random_search.best_params_} Best Score: {random_search.best_score_}\"\n",
    "    )\n",
    "\n",
    "MAXIMAZED = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
