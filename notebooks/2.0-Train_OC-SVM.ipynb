{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections.abc import Callable\n",
    "from datetime import datetime\n",
    "from json import load\n",
    "from typing import Final, Literal\n",
    "\n",
    "from numpy import ndarray, where\n",
    "from pandas import DataFrame, Series, concat, read_csv, set_option\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "set_option(\"display.max_columns\", None)\n",
    "\n",
    "NUM_TRIALS: Final[int] = 20\n",
    "LOGS_PATH: Final[str] = \"../reports/logs_grid.log\"\n",
    "CONF_PATH: Final[str] = \"../conf/model_configs.json\"\n",
    "MODELS = {\n",
    "    \"SGDOneClassSVM\": SGDOneClassSVM(),\n",
    "    \"OneClassSVM\": OneClassSVM(kernel=\"rbf\"),\n",
    "    \"IsolationForest\": IsolationForest(),\n",
    "    \"LocalOutlierFactor\": LocalOutlierFactor(novelty=True),\n",
    "    # Set novelty=True for training/prediction workflow\n",
    "}\n",
    "logging.basicConfig(filename=LOGS_PATH, level=logging.INFO)\n",
    "\n",
    "with open(CONF_PATH, \"r\") as f:\n",
    "    for model in (MODEL_CONFIGS := load(f)):\n",
    "        MODEL_CONFIGS[model][\"model\"] = MODELS[model]\n",
    "\n",
    "    MODELS = MODEL_CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = read_csv(\"../data/PAMAP2/x_train_data.csv\")\n",
    "X_test = read_csv(\"../data/PAMAP2/x_test_data.csv\")\n",
    "y_train = read_csv(\"../data/PAMAP2/y_train_data.csv\")\n",
    "y_test = read_csv(\"../data/PAMAP2/y_test_data.csv\")\n",
    "\n",
    "X_train[\"activity\"] = y_train  # First 80% of the data\n",
    "X_test[\"activity\"] = y_test  # Last 20% of the data\n",
    "\n",
    "models: dict[int, dict] = {}\n",
    "training_data: DataFrame\n",
    "testing_data: DataFrame\n",
    "train_targets: Series\n",
    "test_targets: Series\n",
    "\n",
    "RESULTS: dict[int, dict[str, float | int]] = {}\n",
    "MIN_SAMPLES = X_train[\"activity\"].value_counts().sort_values().iloc[0]\n",
    "MAXIMAZED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(\n",
    "    model: OneClassSVM | SGDOneClassSVM | IsolationForest | LocalOutlierFactor,\n",
    "    Train: DataFrame,  # only for API compliance\n",
    "    test: Series,  # only for API compliance\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Objective function to maximize, calcs the F1 score on the test set.\n",
    "    follows the format needed by scikit-learn's API.\n",
    "\n",
    "    Args:\n",
    "        model (OneClassSVM): Model to eval\n",
    "        X_test (DataFrame): train data, only for API compliance\n",
    "        y_true (Series): true targets, only for API compliance\n",
    "\n",
    "    Returns:\n",
    "        float: F1 score\n",
    "    \"\"\"\n",
    "    f1 = f1_score(test_targets, where(model.predict(testing_data) == -1, True, False))\n",
    "    logging.info(\n",
    "        {\n",
    "            \"target\": f1,\n",
    "            \"params\": model.get_params(),\n",
    "            \"datetime\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%s\"),\n",
    "        }\n",
    "    )\n",
    "    return float(f1)\n",
    "\n",
    "\n",
    "def update_train_vars(\n",
    "    i: int, activities: ndarray\n",
    ") -> tuple[DataFrame, Series, DataFrame, Series]:\n",
    "    training = (  # picks the first n samples of each class\n",
    "        X_train[X_train[\"activity\"].isin(activities[:i])]\n",
    "        .groupby(\"activity\")\n",
    "        .head(MIN_SAMPLES)\n",
    "    )\n",
    "    testing = X_test[X_test[\"activity\"] == activities[i]].head(MIN_SAMPLES)\n",
    "    training.loc[:, \"isNovelty\"], testing.loc[:, \"isNovelty\"] = False, True\n",
    "    novelty = concat(\n",
    "        [testing, training.sample(n=int(0.15 * len(training)), random_state=42)]\n",
    "    )\n",
    "    return (\n",
    "        training.drop(columns=[\"isNovelty\"]),\n",
    "        training[\"isNovelty\"],\n",
    "        # only current activity (as novelty)\n",
    "        novelty.drop(columns=[\"isNovelty\"]),\n",
    "        novelty[\"isNovelty\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def train_search_method(\n",
    "    seach_type: Literal[\"grid\", \"random\"],\n",
    "    params: dict[str, list],\n",
    "    scoring: Callable,\n",
    "    n_iter: int = 100,\n",
    "    cv: int = 4,\n",
    "    verbose: int = 1,\n",
    "    random_state: int = 42,  # used only if seach_type == \"random\"\n",
    ") -> RandomizedSearchCV | GridSearchCV:\n",
    "    search_cls = RandomizedSearchCV if seach_type == \"random\" else GridSearchCV\n",
    "    search_kwargs = {\n",
    "        f\"param_{'distributions' if seach_type == 'random' else 'grid'}\": params,\n",
    "        \"estimator\": OneClassSVM(kernel=\"rbf\"),\n",
    "        \"scoring\": scoring,\n",
    "        \"cv\": cv,\n",
    "        \"verbose\": verbose,\n",
    "        \"error_score\": \"raise\",\n",
    "    }\n",
    "    if seach_type == \"random\":\n",
    "        search_kwargs.update({\"n_iter\": n_iter, \"random_state\": random_state})\n",
    "    return search_cls(**search_kwargs).fit(training_data, train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Description:\n",
    "\n",
    "- tol: Defines the tolerance for the optimization solver (SMO). The algorithm stops iterating when the improvement in the objective function is smaller than this value.\n",
    "- nu: Controls the fraction of the dataset that is considered anomalies/outliers. It must be in the range (0, 1].   \n",
    "  - A ggressive anomaly detectionfor for nu > 0.5, \n",
    "- gamma: Defines how much influence a single training example has. This is the parameter for the Gaussian kernel\n",
    "  - $ K(x_i,x_j​)=exp(−γ∣∣x_i​−x_j​∣∣²) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for activities [1]\n",
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.01, 'tol': 1e-05}\n",
      "Training for activities [1 2]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.01, 'tol': 0.001}\n",
      "Training for activities [1 2 3]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.01, 'tol': 0.0001}\n",
      "Training for activities [1 2 3 4]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.01, 'tol': 0.001}\n",
      "Training for activities [1 2 3 4 5]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.05, 'tol': 1e-05}\n",
      "Training for activities [1 2 3 4 5 6]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.01, 'tol': 1e-05}\n",
      "Training for activities [1 2 3 4 5 6 7]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.01, 'tol': 1e-05}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.01, 'tol': 1e-05}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.05, 'tol': 0.0001}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.01, 'tol': 1e-05}\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16 17]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Grid Search Best Params: {'gamma': 0.001, 'nu': 0.01, 'tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "def update_params_grid(cv_results: dict[str, list]) -> dict[str, list]:\n",
    "    data = (\n",
    "        DataFrame(\n",
    "            zip(\n",
    "                cv_results[\"rank_test_score\"],\n",
    "                cv_results[\"param_gamma\"],\n",
    "                cv_results[\"param_nu\"],\n",
    "                cv_results[\"param_tol\"],\n",
    "            ),\n",
    "            columns=[\"rank_test_score\", \"gamma\", \"nu\", \"tol\"],\n",
    "        )\n",
    "        .sort_values(\"rank_test_score\")\n",
    "        .head(NUM_TRIALS)\n",
    "        .drop(\"rank_test_score\", axis=1)\n",
    "        .to_dict(orient=\"list\")\n",
    "    )\n",
    "    return {col: list(dict.fromkeys(data[col])) for col in [\"gamma\", \"nu\", \"tol\"]}\n",
    "\n",
    "\n",
    "for i in range(1, len((activities := X_train[\"activity\"].unique()))):\n",
    "    training_data, train_targets, testing_data, test_targets = update_train_vars(\n",
    "        i, activities\n",
    "    )\n",
    "    print(f\"Training for activities {activities[:i]}\")\n",
    "    if not MAXIMAZED:\n",
    "        grid_search = train_search_method(\n",
    "            \"grid\",\n",
    "            {\n",
    "                \"tol\": [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                # Tolerance for Stopping Criterion\n",
    "                \"nu\": [0.01, 0.05, 0.1, 0.25, 0.5],\n",
    "                # Upper Bound on Outliers & Lower Bound on Support Vectors\n",
    "                \"gamma\": [0.001, 0.01, 0.1, 1],\n",
    "                # Kernel Coefficient for RBF Kernel\n",
    "            },\n",
    "            score_function,\n",
    "        )\n",
    "        MAXIMAZED = True\n",
    "    else:\n",
    "        print(f\"Already maximized, sugesting new {NUM_TRIALS} points\")\n",
    "        grid_search = train_search_method(\n",
    "            \"grid\",\n",
    "            update_params_grid(grid_search.cv_results_),  # type: ignore\n",
    "            score_function,\n",
    "        )\n",
    "    print(\"Grid Search Best Params:\", grid_search.best_params_)\n",
    "\n",
    "MAXIMAZED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for activities [1]\n",
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n",
      "Random Search. Best Params: {'tol': 0.01, 'nu': 0.01, 'gamma': 0.001} Best Score: 0.9813838151877367\n",
      "Training for activities [1 2]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Random Search. Best Params: {'tol': 0.0001, 'nu': 0.05, 'gamma': 0.01} Best Score: 0.957762225276991\n",
      "Training for activities [1 2 3]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Random Search. Best Params: {'tol': 0.0001, 'nu': 0.05, 'gamma': 0.01} Best Score: 0.9387220334280943\n",
      "Training for activities [1 2 3 4]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Random Search. Best Params: {'tol': 0.001, 'nu': 0.05, 'gamma': 0.01} Best Score: 0.8220964658921611\n",
      "Training for activities [1 2 3 4 5]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Random Search. Best Params: {'tol': 0.001, 'nu': 0.05, 'gamma': 0.01} Best Score: 0.8461617078003891\n",
      "Training for activities [1 2 3 4 5 6]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Random Search. Best Params: {'tol': 0.001, 'nu': 0.05, 'gamma': 0.01} Best Score: 0.8304113078408505\n",
      "Training for activities [1 2 3 4 5 6 7]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Random Search. Best Params: {'tol': 0.001, 'nu': 0.05, 'gamma': 0.01} Best Score: 0.7240949420044088\n",
      "Training for activities [ 1  2  3  4  5  6  7 12]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Random Search. Best Params: {'tol': 0.1, 'nu': 0.5, 'gamma': 0.1} Best Score: 0.6492649273489919\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Random Search. Best Params: {'tol': 0.0001, 'nu': 0.05, 'gamma': 0.01} Best Score: 0.7369997940543581\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Random Search. Best Params: {'tol': 0.0001, 'nu': 0.05, 'gamma': 0.01} Best Score: 0.7224987730537058\n",
      "Training for activities [ 1  2  3  4  5  6  7 12 13 16 17]\n",
      "Already maximized, sugesting new 20 points\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Random Search. Best Params: {'tol': 0.001, 'nu': 0.4, 'gamma': 0.01} Best Score: 0.3771676886177842\n"
     ]
    }
   ],
   "source": [
    "params = [\n",
    "    \"random\",\n",
    "    {\n",
    "        \"nu\": [0.01, 0.025, 0.05, 0.75, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        \"gamma\": [0.001, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1],\n",
    "        \"tol\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    },\n",
    "    score_function,\n",
    "]\n",
    "for i in range(1, len((activities := X_train[\"activity\"].unique()))):\n",
    "    training_data, train_targets, testing_data, test_targets = update_train_vars(\n",
    "        i, activities\n",
    "    )\n",
    "    print(f\"Training for activities {activities[:i]}\")\n",
    "    if not MAXIMAZED:\n",
    "        random_search = train_search_method(*params)\n",
    "        MAXIMAZED = True\n",
    "    else:\n",
    "        print(f\"Already maximized, sugesting new {NUM_TRIALS} points\")\n",
    "        random_search = train_search_method(*params, n_iter=NUM_TRIALS)\n",
    "    print(\n",
    "        f\"Random Search. Best Params: {random_search.best_params_} Best Score: {random_search.best_score_}\"\n",
    "    )\n",
    "\n",
    "MAXIMAZED = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC-1-pCv1QtoV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
