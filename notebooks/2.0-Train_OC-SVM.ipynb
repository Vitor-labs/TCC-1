{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame, Series, read_csv\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = read_csv('../data/PAMAP2/x_train_data.csv')\n",
    "X_valid = read_csv('../data/PAMAP2/x_val_data.csv')\n",
    "y_train = read_csv('../data/PAMAP2/y_train_data.csv')\n",
    "y_valid = read_csv('../data/PAMAP2/y_val_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_160383/2737291297.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data[\n"
     ]
    }
   ],
   "source": [
    "def filter_major_classes(y_classes:list, data: DataFrame, classes: DataFrame) -> DataFrame:\n",
    "    data['target'] = classes\n",
    "    return (\n",
    "        data[\n",
    "            data['target'].isin(values=y_classes)\n",
    "        ]\n",
    "        .groupby(by='target')\n",
    "        .apply(func=lambda x: x.sample(n=10000, random_state=42))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "y_classes: list[int] = [1, 2, 3, 4] #, 16, 17] -> 0 \"noNovelty\"\n",
    "\n",
    "data = filter_major_classes(y_classes, X_train, y_train)\n",
    "X_train_balanced, y_train_balanced = data.drop(columns=['target']), 0 # everything is normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(model, X_train, y_true) -> float:\n",
    "    return float(\n",
    "        f1_score(\n",
    "            np.ones(len(y_true)),\n",
    "            model.predict(X_train),\n",
    "            pos_label=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "def svm_target_function(nu:float, gamma:float, tol:float) -> float:\n",
    "    model = OneClassSVM(kernel='rbf', gamma=gamma, tol=tol, nu=nu).fit(X=X_train_balanced)\n",
    "    # Calculate performance on the validation set and Convert the predictions:\n",
    "    # 1 for normal and -1 for novelty. Returns the f1 score\n",
    "    return score_function(model, X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   gamma   |    nu     |    tol    |\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=svm_target_function,\n",
    "    pbounds={\n",
    "        'nu': (0.01, 0.5),\n",
    "        'gamma': (0.001, 1),\n",
    "        'tol': (1e-3, 1e-5)\n",
    "    },\n",
    "    random_state=42\n",
    ")\n",
    "# optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)\n",
    "optimizer.maximize(init_points=5, n_iter=25)\n",
    "print(f\"Best result: {optimizer.max['params']}; f(x) = {optimizer.max['target']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grids\n",
    "param_grid: dict[str, list[float]] = {\n",
    "    'nu': [0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "    'gamma': [0.001, 0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search: GridSearchCV[OneClassSVM] = GridSearchCV(\n",
    "    estimator=OneClassSVM(kernel='rbf'),\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(score_func=score_function),\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    "    cv=5,\n",
    ").fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search\n",
    "random_search: RandomizedSearchCV = RandomizedSearchCV(\n",
    "    estimator=OneClassSVM(kernel='rbf'),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,\n",
    "    scoring=make_scorer(score_func=score_function),\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    ").fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best results\n",
    "bayesian_best_params: dict[str, float] = optimizer.max['params']\n",
    "grid_best_params: dict[str, float] = grid_search.best_params_\n",
    "random_best_params: dict[str, float] = random_search.best_params_\n",
    "\n",
    "print(\"Bayesian Optimization Best Params:\", bayesian_best_params)\n",
    "print(\"Grid Search Best Params:\", grid_best_params)\n",
    "print(\"Random Search Best Params:\", random_best_params)\n",
    "\n",
    "# You can further test these models on your test set and compare their performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC-1-pCv1QtoV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
