{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    \"\"\"A simple LSTM network for sequence prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        return self.fc(lstm_out[:, -1, :])  # Return the last time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pamap2_data():\n",
    "    df = pd.read_parquet('../data/PAMAP2/protocol.parquet')\n",
    "    # the labels are on the 2ยบ column\n",
    "    X = df.drop('activityID', axis=1)\n",
    "    y = df['activityID']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective_function(hidden_size, num_layers, learning_rate):\n",
    "    \"\"\"\n",
    "    Objective function for Bayesian Optimization.\n",
    "\n",
    "    This function initializes the LSTM network with the given hyperparameters,\n",
    "    trains it on the provided dataloader, and returns the average loss as\n",
    "    the evaluation metric.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    hidden_size : float\n",
    "        The number of hidden units in the LSTM layer. This value should be\n",
    "        between 10 and 100.\n",
    "\n",
    "    num_layers : float\n",
    "        The number of LSTM layers in the network. This value should be between\n",
    "        1 and 5.\n",
    "\n",
    "    learning_rate : float\n",
    "        The learning rate for the optimizer. This value should be between\n",
    "        0.0001 and 0.1.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        The average loss of the model after training.\n",
    "    \"\"\"\n",
    "    # Load PAMAP2 dataset\n",
    "    X, y = load_pamap2_data()\n",
    "    NUM_EPOCHS = 25\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Set up the LSTM network\n",
    "    input_size = X.shape[1]  # Number of features\n",
    "    output_size = 1          # Single output for binary classification\n",
    "\n",
    "    model = LSTMNetwork(input_size, int(hidden_size), int(num_layers), output_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    dataloader = load_pamap2_data()\n",
    "\n",
    "    for _ in range(NUM_EPOCHS):\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x.float())\n",
    "            loss = criterion(output, y.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            output = model(x.float())\n",
    "            all_preds.append(output.softmax(dim=1).cpu().numpy())  # Convert to probabilities\n",
    "            all_labels.append(y.cpu().numpy())\n",
    "\n",
    "    # Concatenate results for AUC-ROC calculation\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    # Compute AUC-ROC score\n",
    "    auc_score = roc_auc_score(all_labels, all_preds, multi_class='ovr')\n",
    "\n",
    "    return auc_score  # Return the AUC-ROC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | hidden... | learni... | num_la... |\n",
      "-------------------------------------------------------------\n",
      "0 of 25\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization\u001b[39;00m\n\u001b[1;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[1;32m      9\u001b[0m     f\u001b[38;5;241m=\u001b[39mobjective_function,\n\u001b[1;32m     10\u001b[0m     pbounds\u001b[38;5;241m=\u001b[39mpbounds,\n\u001b[1;32m     11\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(optimizer\u001b[38;5;241m.\u001b[39mmax)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/TCC-1-pCv1QtoV/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:374\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    372\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[1;32m    373\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 374\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/TCC-1-pCv1QtoV/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:245\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/TCC-1-pCv1QtoV/lib/python3.10/site-packages/bayes_opt/target_space.py:373\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[_hashable(x\u001b[38;5;241m.\u001b[39mravel())]\n\u001b[1;32m    372\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[0;32m--> 373\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[0;32mIn[5], line 49\u001b[0m, in \u001b[0;36mobjective_function\u001b[0;34m(hidden_size, num_layers, learning_rate)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train)):\n\u001b[1;32m     48\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 49\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Shape (1, seq_length, input_size)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, torch\u001b[38;5;241m.\u001b[39mtensor(y_train[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     51\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "pbounds = {\n",
    "    'hidden_size': (10, 100),  # Example bounds for hidden layer size\n",
    "    'num_layers': (1, 5),      # Example bounds for number of layers\n",
    "    'learning_rate': (0.0001, 0.1)  # Example bounds for learning rate\n",
    "}\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=5,\n",
    "    n_iter=25,\n",
    ")\n",
    "\n",
    "print(optimizer.max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC-1-pCv1QtoV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
