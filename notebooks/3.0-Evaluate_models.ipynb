{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dump, load\n",
    "from random import sample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed, dump\n",
    "from numpy import ndarray, where\n",
    "from pandas import DataFrame, concat, read_csv\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "TECHNIQUES = [\"Grid Search\", \"Random Search\", \"Bayesian Opt\"]\n",
    "POLLUTIONS = [0.2, 0.4, 0.75, 0.9]\n",
    "RESULTS: dict[str, dict[float, dict[str, float]]] = {\n",
    "    technique: {} for technique in TECHNIQUES\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = read_csv(\"../data/PAMAP2/x_train_data.csv\")\n",
    "X_test = read_csv(\"../data/PAMAP2/x_test_data.csv\")\n",
    "y_train = read_csv(\"../data/PAMAP2/y_train_data.csv\")\n",
    "y_test = read_csv(\"../data/PAMAP2/y_test_data.csv\")\n",
    "\n",
    "X_train[\"activity\"] = y_train  # First 80% of the data\n",
    "X_test[\"activity\"] = y_test  # Last 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_train_test(data: DataFrame) -> tuple[list, DataFrame, DataFrame]:\n",
    "    classes: list[int] = [\n",
    "        num for num in sample(X_train[\"activity\"].value_counts().index.to_list(), 6)\n",
    "    ]\n",
    "    classes.sort()\n",
    "    return (\n",
    "        classes,\n",
    "        data[data[\"activity\"].isin(classes)],\n",
    "        data[~data[\"activity\"].isin(classes)],\n",
    "    )\n",
    "\n",
    "\n",
    "def test_ocsvm_with_pollution(\n",
    "    train: DataFrame, test: DataFrame, model: OneClassSVM, percent: float\n",
    ") -> dict[str, float]:\n",
    "    novelty = concat([test, train.sample(n=int(percent * len(train)), random_state=42)])\n",
    "    preds = where(model.predict(novelty.drop(columns=[\"isNovelty\"])) == -1, True, False)\n",
    "    precision, recall, _ = precision_recall_curve(novelty[\"isNovelty\"], preds)\n",
    "\n",
    "    return {\n",
    "        \"f1\": float(f1_score(novelty[\"isNovelty\"], preds)),\n",
    "        \"mcc\": float(matthews_corrcoef(novelty[\"isNovelty\"], preds)),\n",
    "        \"acc\": float(accuracy_score(novelty[\"isNovelty\"], preds)),\n",
    "        \"pr_auc\": float(auc(recall, precision)),\n",
    "        \"roc_auc\": float(roc_auc_score(novelty[\"isNovelty\"], preds)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, training, testing = filter_train_test(concat([X_train, X_test]))\n",
    "training.loc[:, \"isNovelty\"], testing.loc[:, \"isNovelty\"] = False, True\n",
    "\n",
    "print(f\"Training with: {classes}\")\n",
    "with open(\"../conf/top_results.json\", \"r\") as f:\n",
    "    top_results = load(f)\n",
    "\n",
    "# Extract training data once as numpy array (lighter to share)\n",
    "X_training = training.drop(columns=[\"isNovelty\"]).values\n",
    "\n",
    "\n",
    "def create_ocsvm(params: dict, technique: str, train_data: ndarray = X_training):\n",
    "    print(f\"fitting model for {technique}\")\n",
    "    return OneClassSVM(\n",
    "        kernel=\"rbf\", gamma=params[\"gamma\"][0], tol=params[\"tol\"][0], nu=params[\"nu\"][0]\n",
    "    ).fit(train_data)\n",
    "\n",
    "\n",
    "models = {\n",
    "    technique: result\n",
    "    for technique, result in zip(\n",
    "        TECHNIQUES,\n",
    "        Parallel(n_jobs=-1)(\n",
    "            delayed(create_ocsvm)(top_results[technique], technique, X_training)\n",
    "            for technique in TECHNIQUES\n",
    "        ),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/Grid_Search.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m technique, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../models/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtechnique\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/TCC-1-pCv1QtoV/lib/python3.10/site-packages/joblib/numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[0;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/Grid_Search.joblib'"
     ]
    }
   ],
   "source": [
    "for technique, model in models.items():\n",
    "    with open(f\"../models/{technique.replace(' ', '_')}.joblib\", \"wb\") as f:\n",
    "        dump(model, f)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 20.0% pollution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorduarte/.local/share/virtualenvs/TCC-1-pCv1QtoV/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but OneClassSVM was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for pollution in POLLUTIONS:\n",
    "    print(f\"Testing with {pollution * 100}% pollution\")\n",
    "    for name, model in models.items():\n",
    "        result = {\n",
    "            pollution: test_ocsvm_with_pollution(training, testing, model, pollution)\n",
    "        }\n",
    "        RESULTS[name].update(result)\n",
    "        print(f\"Results for {name}:\\n{result[pollution]}\")\n",
    "\n",
    "with open(\"../conf/result_polution.json\", \"w\") as fp:\n",
    "    dump(RESULTS, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8), sharey=True)\n",
    "\n",
    "for i, (technique_name, df) in enumerate(\n",
    "    (\n",
    "        (name, DataFrame(RESULTS[name]).transpose())\n",
    "        for name in [\"Grid Search\", \"Random Search\", \"Bayesian Opt\"]\n",
    "    )\n",
    "):\n",
    "    for metric in df.columns.tolist():\n",
    "        axes[i].plot(df.index.tolist(), df[metric], marker=\"o\", label=metric)\n",
    "\n",
    "    axes[i].set_ylabel(\"Resultados\" if i == 0 else \"\")\n",
    "    axes[i].set_xlabel(\"% de novidade\")\n",
    "    axes[i].set_title(technique_name)\n",
    "    axes[i].tick_params(axis=\"x\", rotation=0)\n",
    "    axes[i].legend(loc=\"best\", fontsize=18)\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC-1-pCv1QtoV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
