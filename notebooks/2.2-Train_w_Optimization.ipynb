{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.event import Events\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.util import load_logs\n",
    "from numpy import where\n",
    "from pandas import DataFrame, concat\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hyperparams(nu, gamma):\n",
    "    # Train the model using the given hyperparameters\n",
    "    X_train = current_data.drop(columns=[\"isNovelty\"])\n",
    "    y_train = current_data[\"isNovelty\"]\n",
    "\n",
    "    oc_svm = OneClassSVM(nu=nu, kernel=\"rbf\", gamma=gamma).fit(X_train)\n",
    "\n",
    "    # Sample and add to novelty data\n",
    "    sampled_data = current_data.sample(n=int(0.2 * len(current_data)), random_state=42)\n",
    "    sampled_data[\"isNovelty\"] = 0\n",
    "    combined_novelty = concat([novelty, sampled_data])\n",
    "\n",
    "    X_test = combined_novelty.drop(columns=[\"isNovelty\"])\n",
    "    y_test = combined_novelty[\"isNovelty\"]\n",
    "\n",
    "    # Predict and calculate F1 scores\n",
    "    y_pred_train = where(oc_svm.predict(X_train) == 1, False, True)\n",
    "    y_pred_test = where(oc_svm.predict(X_test) == 1, False, True)\n",
    "\n",
    "    f1_train = f1_score(y_train, y_pred_train, pos_label=True)\n",
    "    f1_test = f1_score(y_test, y_pred_test, pos_label=True)\n",
    "\n",
    "    # Return the F1 score for test as the objective to maximize\n",
    "    return f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_for_activity(\n",
    "    current_data: DataFrame, novelty: DataFrame, activity: int, log_file: str\n",
    ") -> OneClassSVM:\n",
    "    # Load previous logs if available\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=evaluate_hyperparams,\n",
    "        pbounds={\"nu\": (0.01, 0.5), \"gamma\": (0.001, 1)},\n",
    "        random_state=42,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    if log_file:\n",
    "        try:\n",
    "            load_logs(optimizer, logs=[log_file])\n",
    "            print(f\"Loaded logs from {log_file}. Continuing optimization...\")\n",
    "        except FileNotFoundError:\n",
    "            print(\n",
    "                f\"No previous log found. Starting fresh optimization for activity {activity}.\"\n",
    "            )\n",
    "\n",
    "    # Add a logger to save results\n",
    "    logger = JSONLogger(path=log_file)\n",
    "    optimizer.subscribe(Events.OPTMIZATION_STEP, logger)  # type: ignore\n",
    "\n",
    "    # Run optimization\n",
    "    optimizer.maximize(init_points=5, n_iter=10)\n",
    "\n",
    "    # Check if we found new best hyperparameters\n",
    "    best_hyperparams = optimizer.max[\"params\"]  # type: ignore\n",
    "    print(f\"Best hyperparameters for Activity {activity}: {best_hyperparams}\")\n",
    "\n",
    "    # If no improvement after iterations, fall back to previous best\n",
    "    if not optimizer.res or optimizer.res[-1][\"target\"] < optimizer.max[\"target\"]:  # type: ignore\n",
    "        print(\"No improvement found. Using the best hyperparameters so far.\")\n",
    "\n",
    "    # Train final model using the best hyperparameters\n",
    "    best_nu = best_hyperparams[\"nu\"]\n",
    "    best_gamma = best_hyperparams[\"gamma\"]\n",
    "    final_model = OneClassSVM(nu=best_nu, kernel=\"rbf\", gamma=best_gamma).fit(\n",
    "        current_data.drop(columns=[\"isNovelty\"])\n",
    "    )\n",
    "\n",
    "    # Evaluate and print final results\n",
    "    sampled_data = current_data.sample(n=int(0.2 * len(current_data)), random_state=42)\n",
    "    sampled_data[\"isNovelty\"] = 0\n",
    "    novelty = concat([novelty, sampled_data])\n",
    "\n",
    "    X_test = novelty.drop(columns=[\"isNovelty\"])\n",
    "    y_test = novelty[\"isNovelty\"]\n",
    "\n",
    "    y_pred_train = where(final_model.predict(X_train) == 1, False, True)\n",
    "    y_pred_test = where(final_model.predict(X_test) == 1, False, True)\n",
    "\n",
    "    print(\n",
    "        f\"Final Model for Activity: {activity}\"\n",
    "        f\"\\nF1 Score (Train): {f1_score(y_train, y_pred_train, pos_label=True)}\"\n",
    "        f\"\\nF1 Score (Test): {f1_score(y_test, y_pred_test, pos_label=True)}\"\n",
    "    )\n",
    "\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_svm_for_activity(\n",
    "    current_data, novelty, activity=1, log_file=\"activity_1_logs.json\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC-1-pCv1QtoV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
