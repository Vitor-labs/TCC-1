{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, read_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = read_csv(\"../data/PAMAP2/x_train_data.csv\")\n",
    "X_test = read_csv(\"../data/PAMAP2/x_test_data.csv\")\n",
    "y_train = read_csv(\"../data/PAMAP2/y_train_data.csv\")\n",
    "y_test = read_csv(\"../data/PAMAP2/y_test_data.csv\")\n",
    "\n",
    "x_label = [f\"{num[0]}\" for num in y_test.value_counts().index.sort_values().to_list()][\n",
    "    1:\n",
    "]\n",
    "\n",
    "X_train[\"activity\"] = y_train  # First 80% of the data\n",
    "X_test[\"activity\"] = y_test  # Last 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_log_files(reports_dir: str = \"../reports\"):\n",
    "    \"\"\"\n",
    "    Find all .log files in the reports directory\n",
    "    \"\"\"\n",
    "    if not os.path.exists(reports_dir):\n",
    "        raise FileNotFoundError(f\"Reports directory not found: {reports_dir}\")\n",
    "\n",
    "    log_files = glob.glob(os.path.join(reports_dir, \"*.log\"))\n",
    "    if not log_files:\n",
    "        raise FileNotFoundError(f\"No .log files found in {reports_dir}\")\n",
    "\n",
    "    return sorted(log_files)\n",
    "\n",
    "\n",
    "def process_file_records(log_file_path: str):\n",
    "    print(f\"üìÅ Reading log file: {log_file_path}...\")\n",
    "    with open(log_file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    lines = [lines[i].strip() for i in range(1, len(lines))]\n",
    "    print(f\"‚úÖ Extracted {len(lines)} even lines\\nüîß Parsing JSON lines...\")\n",
    "    records = []\n",
    "    for i, line in enumerate(lines):\n",
    "        try:\n",
    "            data = json.loads(line.replace(\"'\", '\"').lower())\n",
    "            records.append(data[\"event\"] if line.startswith('{\"event') else data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ö†Ô∏è  JSON decode error on line {i}: {e}\")\n",
    "            raise e\n",
    "\n",
    "    if not records:\n",
    "        raise ValueError(\"No valid JSON records found!\")\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "def group_data(records: list):\n",
    "    df = DataFrame(records)\n",
    "    print(f\"‚úÖ Created dataframe with {len(df)} records\\nüìä Grouping every 4 rows...\")\n",
    "    grouped_df = DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"target\": group[\"target\"].mean(),\n",
    "                \"datetime\": group[\"datetime\"].iloc[-1],\n",
    "                \"group_size\": len(group),\n",
    "            }\n",
    "            for i in range(0, len(df), 4)\n",
    "            if len(group := df.iloc[i : i + 4]) > 0\n",
    "        ]\n",
    "    ).reset_index(drop=True)\n",
    "    print(f\"‚úÖ Created {len(grouped_df)} groups and Sorted by target\")\n",
    "    return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperparams_log(grouped_df: DataFrame):\n",
    "    \"\"\"\n",
    "    Process hyperparameter tuning log file according to specified rules\n",
    "    \"\"\"\n",
    "    print(\"üì¶ Creating batches...\")\n",
    "    activities = X_train[\"activity\"].unique()\n",
    "\n",
    "    batches = []\n",
    "\n",
    "    # First batch: first 100 lines\n",
    "    batch_1 = grouped_df.iloc[:100]\n",
    "    batches.append(\n",
    "        {\n",
    "            \"batch_num\": activities[0],\n",
    "            \"size\": len(batch_1),\n",
    "            \"max_target\": batch_1[\"target\"].max(),\n",
    "            \"mean_target\": batch_1[\"target\"].mean(),\n",
    "            \"min_target\": batch_1[\"target\"].min(),\n",
    "        }\n",
    "    )\n",
    "    remaining_df = grouped_df.iloc[100:]\n",
    "\n",
    "    # Remaining batches: 20 lines each\n",
    "    batch_num = 0\n",
    "    for i in range(0, len(remaining_df), 20):\n",
    "        batch = remaining_df.iloc[i : i + 20]\n",
    "        if len(batch) > 0:\n",
    "            batches.append(\n",
    "                {\n",
    "                    \"batch_num\": activities[batch_num],\n",
    "                    \"size\": len(batch),\n",
    "                    \"max_target\": batch[\"target\"].max(),\n",
    "                    \"mean_target\": batch[\"target\"].mean(),\n",
    "                    \"min_target\": batch[\"target\"].min(),\n",
    "                }\n",
    "            )\n",
    "            batch_num += 1\n",
    "            if batch_num > 11:\n",
    "                print(f\"‚ö†Ô∏è  Warning: More than 12 batches created: {len(batches)}\")\n",
    "                break\n",
    "\n",
    "    batches_df = DataFrame(batches)\n",
    "    print(f\"‚úÖ Created {len(batches_df)} batches\")\n",
    "    print(\"\\nüìã Batch Summary:\\n\", batches_df.to_string(index=False))\n",
    "\n",
    "    return grouped_df, batches_df\n",
    "\n",
    "\n",
    "def plot_all_batch_results(all_results: dict):\n",
    "    \"\"\"\n",
    "    Plot the results for all log files using subplots\n",
    "    \"\"\"\n",
    "    print(\"\\nüìà Creating visualizations for all log files...\")\n",
    "\n",
    "    n_files = len(all_results)\n",
    "    if n_files == 0:\n",
    "        print(\"‚ùå No log files to plot\")\n",
    "        return\n",
    "\n",
    "    # Calculate subplot layout\n",
    "    n_cols = min(2, n_files)  # Max 2 columns\n",
    "    n_rows = (n_files + n_cols - 1) // n_cols\n",
    "\n",
    "    # Create figure with subplots for max target plots\n",
    "    fig1, axes1 = plt.subplots(n_rows, n_cols, figsize=(12 * n_cols, 8 * n_rows))\n",
    "    if n_files == 1:\n",
    "        axes1 = [axes1]\n",
    "    elif n_rows == 1:\n",
    "        axes1 = [axes1]\n",
    "    else:\n",
    "        axes1 = axes1.flatten()\n",
    "\n",
    "    # Create figure with subplots for distribution plots\n",
    "    fig2, axes2 = plt.subplots(n_rows, n_cols, figsize=(12 * n_cols, 6 * n_rows))\n",
    "    if n_files == 1:\n",
    "        axes2 = [axes2]\n",
    "    elif n_rows == 1:\n",
    "        axes2 = [axes2]\n",
    "    else:\n",
    "        axes2 = axes2.flatten()\n",
    "\n",
    "    for idx, (log_file, (grouped_df, batches_df)) in enumerate(all_results.items()):\n",
    "        filename = os.path.basename(log_file).replace(\".log\", \"\")\n",
    "\n",
    "        # Plot 1: Max target bar chart\n",
    "        ax1 = axes1[idx]\n",
    "        bars = ax1.bar(\n",
    "            batches_df[\"batch_num\"],\n",
    "            batches_df[\"max_target\"],\n",
    "            color=\"steelblue\",\n",
    "            alpha=0.7,\n",
    "            edgecolor=\"navy\",\n",
    "            linewidth=1,\n",
    "        )\n",
    "        ax1.set_title(\n",
    "            f\"F1 M√°ximo por Atividade - {filename}\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            pad=10,\n",
    "        )\n",
    "        ax1.set_xlabel(\"Atividade de Teste\", fontsize=10, fontweight=\"bold\")\n",
    "        ax1.set_ylabel(\"F1 M√°ximo\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "        # Add value labels on top of bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(\n",
    "                bar.get_x() + bar.get_width() / 2.0,\n",
    "                height + 0.0001,\n",
    "                f\"{height:.4f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "        ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "        ax1.set_xticks(batches_df[\"batch_num\"])\n",
    "\n",
    "        # Add batch size information\n",
    "        for i, (batch_num, size) in enumerate(\n",
    "            zip(batches_df[\"batch_num\"], batches_df[\"size\"])\n",
    "        ):\n",
    "            y_min, y_max = ax1.get_ylim()\n",
    "            ax1.text(\n",
    "                batch_num,\n",
    "                y_min + (y_max - y_min) * 0.02,\n",
    "                f\"n={size}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=7,\n",
    "                alpha=0.7,\n",
    "            )\n",
    "\n",
    "        # Plot 2: Target distribution\n",
    "        ax2 = axes2[idx]\n",
    "        x = batches_df[\"batch_num\"]\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            batches_df[\"max_target\"],\n",
    "            \"o-\",\n",
    "            label=\"Max Target\",\n",
    "            linewidth=2,\n",
    "            markersize=4,\n",
    "        )\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            batches_df[\"mean_target\"],\n",
    "            \"s-\",\n",
    "            label=\"Mean Target\",\n",
    "            linewidth=2,\n",
    "            markersize=4,\n",
    "        )\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            batches_df[\"min_target\"],\n",
    "            \"^-\",\n",
    "            label=\"Min Target\",\n",
    "            linewidth=2,\n",
    "            markersize=4,\n",
    "        )\n",
    "        ax2.set_title(\n",
    "            f\"Distribui√ß√£o Target Score - {filename}\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            pad=10,\n",
    "        )\n",
    "        ax2.set_xlabel(\"Batch Number\", fontsize=10, fontweight=\"bold\")\n",
    "        ax2.set_ylabel(\"Target Score\", fontsize=10, fontweight=\"bold\")\n",
    "        ax2.legend(fontsize=8)\n",
    "        ax2.grid(alpha=0.3, linestyle=\"--\")\n",
    "        ax2.set_xticks(batches_df[\"batch_num\"])\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_files, len(axes1)):\n",
    "        axes1[idx].set_visible(False)\n",
    "        axes2[idx].set_visible(False)\n",
    "\n",
    "    fig1.suptitle(\n",
    "        \"F1 M√°ximo por Atividade - Todos os Arquivos de Log\",\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    fig2.suptitle(\n",
    "        \"Distribui√ß√£o Target Score - Todos os Arquivos de Log\",\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    fig1.tight_layout()\n",
    "    fig2.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"üîç Finding log files in reports directory...\")\n",
    "    log_files = find_log_files(\"../reports\")\n",
    "    print(\n",
    "        f\"üìã Found {len(log_files)} log files: {[os.path.basename(f) for f in log_files]}\"\n",
    "    )\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for log_file in log_files:\n",
    "        try:\n",
    "            print(f\"\\n{'=' * 50}\")\n",
    "            print(f\"Processing: {os.path.basename(log_file)}\")\n",
    "            print(f\"{'=' * 50}\")\n",
    "\n",
    "            grouped_df, batches_df = process_hyperparams_log(\n",
    "                group_data(process_file_records(log_file))\n",
    "            )\n",
    "            all_results[log_file] = (grouped_df, batches_df)\n",
    "\n",
    "            print(f\"\\nüìä Summary Statistics for {os.path.basename(log_file)}:\")\n",
    "            print(f\"Best target score: {grouped_df['target'].max():.6f}\")\n",
    "            print(f\"Worst target score: {grouped_df['target'].min():.6f}\")\n",
    "            print(f\"Average target score: {grouped_df['target'].mean():.6f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {log_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if all_results:\n",
    "        plot_all_batch_results(all_results)\n",
    "\n",
    "        print(f\"\\n{'=' * 50}\")\n",
    "        print(\"üìä OVERALL SUMMARY\")\n",
    "        print(f\"{'=' * 50}\")\n",
    "        for log_file, (grouped_df, _) in all_results.items():\n",
    "            filename = os.path.basename(log_file)\n",
    "            print(\n",
    "                f\"{filename}: Best={grouped_df['target'].max():.6f}, \"\n",
    "                f\"Avg={grouped_df['target'].mean():.6f}, \"\n",
    "                f\"Worst={grouped_df['target'].min():.6f}\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"‚ùå No log files were successfully processed\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
