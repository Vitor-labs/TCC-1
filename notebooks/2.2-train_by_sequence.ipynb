{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Final\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.event import Events\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.util import load_logs\n",
    "from numpy import where\n",
    "from pandas import DataFrame, Series, concat, read_csv\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "NUM_TRIALS: Final[int] = 5\n",
    "LOGS_PATH: Final[str] = \"../reports/logs_sequence.log\"\n",
    "logger = JSONLogger(path=LOGS_PATH, reset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = read_csv(\"../data/PAMAP2/x_train_data.csv\")\n",
    "X_test = read_csv(\"../data/PAMAP2/x_test_data.csv\")\n",
    "y_train = read_csv(\"../data/PAMAP2/y_train_data.csv\")\n",
    "y_test = read_csv(\"../data/PAMAP2/y_test_data.csv\")\n",
    "\n",
    "X_train[\"activity\"] = y_train  # First 80% of the data\n",
    "X_test[\"activity\"] = y_test  # Last 20% of the data\n",
    "\n",
    "# MIN_SAMPLES = X_train[\"activity\"].value_counts().min()\n",
    "MIN_SAMPLES = X_train[\"activity\"].value_counts().sort_values().iloc[3]\n",
    "MAXIMAZED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(nu: float, gamma: float) -> float:\n",
    "    \"\"\"\n",
    "    Objective function to optimize F1-Score on the train and test set.\n",
    "\n",
    "    Args:\n",
    "        nu (float): nu param to evaluate.\n",
    "        gamma (float): gamma param to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        float: F1-Score on the test set of this iteration.\n",
    "    \"\"\"\n",
    "    oc_svm = OneClassSVM(kernel=\"rbf\", nu=nu, gamma=gamma).fit(training_data)\n",
    "\n",
    "    f1_train = f1_score(\n",
    "        train_targets,\n",
    "        where(oc_svm.predict(training_data) == 1, False, True),\n",
    "        average=\"macro\",\n",
    "    )\n",
    "    f1_test = f1_score(\n",
    "        test_targets,\n",
    "        where(oc_svm.predict(testing_data) == 1, False, True),\n",
    "        average=\"macro\",\n",
    "    )\n",
    "    print(f\"\\nF1 Score (Train): {f1_train}\\nF1 Score (Test): {f1_test}\")\n",
    "    return float(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "models: dict[int, dict] = {}\n",
    "training_data: DataFrame\n",
    "testing_data: DataFrame\n",
    "train_targets: Series\n",
    "test_targets: Series\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    objective_function, {\"nu\": (0.01, 0.5), \"gamma\": (1e-4, 1e-1)}, random_state=42\n",
    ")\n",
    "if not os.path.exists(LOGS_PATH):\n",
    "    with open(LOGS_PATH, \"w\") as fp:\n",
    "        pass\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New optimizer is now aware of 55 points.\n",
      "\n",
      "F1 Score (Train): 0.48314606741573035\n",
      "F1 Score (Test): 0.971047526089349\n",
      "\n",
      "F1 Score (Train): 0.4121607694950189\n",
      "F1 Score (Test): 0.87254290636244\n",
      "\n",
      "F1 Score (Train): 0.4752851711026616\n",
      "F1 Score (Test): 0.961128649128649\n",
      "\n",
      "F1 Score (Train): 0.4880631843475139\n",
      "F1 Score (Test): 0.9815047645139792\n",
      "\n",
      "F1 Score (Train): 0.4628664699604495\n",
      "F1 Score (Test): 0.945615908300795\n",
      "\n",
      "F1 Score (Train): 0.4549276931897815\n",
      "F1 Score (Test): 0.9297271541041512\n",
      "\n",
      "F1 Score (Train): 0.4674136321195145\n",
      "F1 Score (Test): 0.951770158713132\n",
      "\n",
      "F1 Score (Train): 0.41074380165289254\n",
      "F1 Score (Test): 0.8687794901065449\n",
      "\n",
      "F1 Score (Train): 0.48044692737430167\n",
      "F1 Score (Test): 0.9694424977412062\n",
      "\n",
      "F1 Score (Train): 0.46909903201787045\n",
      "F1 Score (Test): 0.9520057214717721\n",
      "\n",
      "F1 Score (Train): 0.4674136321195145\n",
      "F1 Score (Test): 0.9508270716238427\n",
      "\n",
      "F1 Score (Train): 0.46900018618506795\n",
      "F1 Score (Test): 0.9548259997553341\n",
      "\n",
      "F1 Score (Train): 0.4734769230769231\n",
      "F1 Score (Test): 0.9585680017510976\n",
      "\n",
      "F1 Score (Train): 0.48305238354177993\n",
      "F1 Score (Test): 0.9733340447659274\n",
      "\n",
      "F1 Score (Train): 0.48566275924256086\n",
      "F1 Score (Test): 0.9753855660502111\n",
      "\n",
      "F1 Score (Train): 0.4859408795962509\n",
      "F1 Score (Test): 0.9765227291127077\n",
      "\n",
      "F1 Score (Train): 0.49192399049881236\n",
      "F1 Score (Test): 0.988019779263365\n",
      "\n",
      "F1 Score (Train): 0.38824538824538823\n",
      "F1 Score (Test): 0.8394528413895396\n",
      "\n",
      "F1 Score (Train): 0.4898336414048059\n",
      "F1 Score (Test): 0.982632229877849\n",
      "\n",
      "F1 Score (Train): 0.4742211024396239\n",
      "F1 Score (Test): 0.96043124896747\n",
      "\n",
      "F1 Score (Train): 0.4851365988686966\n",
      "F1 Score (Test): 0.9758406506060229\n",
      "\n",
      "F1 Score (Train): 0.4769851457913075\n",
      "F1 Score (Test): 0.9643737808888737\n",
      "\n",
      "F1 Score (Train): 0.47886466073821415\n",
      "F1 Score (Test): 0.9643737808888737\n",
      "\n",
      "F1 Score (Train): 0.47806990788751297\n",
      "F1 Score (Test): 0.9699014549115799\n",
      "\n",
      "F1 Score (Train): 0.47806990788751297\n",
      "F1 Score (Test): 0.9671431471837034\n",
      "New optimizer is now aware of 80 points.\n",
      "Already maximized, sugesting new 5 points\n",
      "\n",
      "F1 Score (Train): 0.46550054661877244\n",
      "F1 Score (Test): 0.9329124006013466\n",
      "Next point to probe is: {'gamma': np.float64(0.054373116769580586), 'nu': np.float64(0.02319952360498994)} Found the target value to be: 0.9329124006013466\n",
      "\n",
      "F1 Score (Train): 0.4732175840413742\n",
      "F1 Score (Test): 0.9473333057122431\n",
      "Next point to probe is: {'gamma': np.float64(0.029789055643158258), 'nu': np.float64(0.07195285768881325)} Found the target value to be: 0.9473333057122431\n",
      "\n",
      "F1 Score (Train): 0.4841277019082934\n",
      "F1 Score (Test): 0.9673821036574779\n",
      "Next point to probe is: {'gamma': np.float64(0.0006055810684430016), 'nu': np.float64(0.06111791391586465)} Found the target value to be: 0.9673821036574779\n",
      "\n",
      "F1 Score (Train): 0.46459747817652763\n",
      "F1 Score (Test): 0.9332075093401533\n",
      "Next point to probe is: {'gamma': np.float64(0.06297356315316989), 'nu': np.float64(0.05668958954921619)} Found the target value to be: 0.9332075093401533\n",
      "\n",
      "F1 Score (Train): 0.4736550705914921\n",
      "F1 Score (Test): 0.9520264424272167\n",
      "Next point to probe is: {'gamma': np.float64(0.032976357413183596), 'nu': np.float64(0.010527433352893146)} Found the target value to be: 0.9520264424272167\n",
      "New optimizer is now aware of 85 points.\n",
      "Already maximized, sugesting new 5 points\n",
      "\n",
      "F1 Score (Train): 0.4725897920604915\n",
      "F1 Score (Test): 0.9436666232150639\n",
      "Next point to probe is: {'gamma': np.float64(0.0006094931050846874), 'nu': np.float64(0.10396018337483476)} Found the target value to be: 0.9436666232150639\n",
      "\n",
      "F1 Score (Train): 0.4481186841539454\n",
      "F1 Score (Test): 0.899003735665775\n",
      "Next point to probe is: {'gamma': np.float64(0.07540658130389831), 'nu': np.float64(0.03630625002995378)} Found the target value to be: 0.899003735665775\n",
      "\n",
      "F1 Score (Train): 0.4697461110996344\n",
      "F1 Score (Test): 0.9384351543459275\n",
      "Next point to probe is: {'gamma': np.float64(0.030760865980568576), 'nu': np.float64(0.08764394143583017)} Found the target value to be: 0.9384351543459275\n",
      "\n",
      "F1 Score (Train): 0.44703677373489303\n",
      "F1 Score (Test): 0.8962174376877259\n",
      "Next point to probe is: {'gamma': np.float64(0.09232890749823436), 'nu': np.float64(0.058738111327784046)} Found the target value to be: 0.8962174376877259\n",
      "\n",
      "F1 Score (Train): 0.46503824430503743\n",
      "F1 Score (Test): 0.925731710756247\n",
      "Next point to probe is: {'gamma': np.float64(0.0385346521159782), 'nu': np.float64(0.05654217281243206)} Found the target value to be: 0.925731710756247\n",
      "New optimizer is now aware of 90 points.\n",
      "Already maximized, sugesting new 5 points\n",
      "\n",
      "F1 Score (Train): 0.4382878151260504\n",
      "F1 Score (Test): 0.780908284833456\n",
      "Next point to probe is: {'gamma': np.float64(0.01922154598225298), 'nu': np.float64(0.06381353063097717)} Found the target value to be: 0.780908284833456\n",
      "\n",
      "F1 Score (Train): 0.4520916382498439\n",
      "F1 Score (Test): 0.8220501381439727\n",
      "Next point to probe is: {'gamma': np.float64(0.007429250580966345), 'nu': np.float64(0.0754152464499042)} Found the target value to be: 0.8220501381439727\n",
      "\n",
      "F1 Score (Train): 0.4575282537367845\n",
      "F1 Score (Test): 0.841466072346966\n",
      "Next point to probe is: {'gamma': np.float64(0.006061236617374515), 'nu': np.float64(0.033412156448147635)} Found the target value to be: 0.841466072346966\n",
      "\n",
      "F1 Score (Train): 0.4675876230923601\n",
      "F1 Score (Test): 0.8727470455513756\n",
      "Next point to probe is: {'gamma': np.float64(0.003978228547526672), 'nu': np.float64(0.02389328329934487)} Found the target value to be: 0.8727470455513756\n",
      "\n",
      "F1 Score (Train): 0.45713243341846044\n",
      "F1 Score (Test): 0.835379295157237\n",
      "Next point to probe is: {'gamma': np.float64(0.006906151211172), 'nu': np.float64(0.013728651773598912)} Found the target value to be: 0.835379295157237\n",
      "New optimizer is now aware of 95 points.\n",
      "Already maximized, sugesting new 5 points\n",
      "\n",
      "F1 Score (Train): 0.42541397894501687\n",
      "F1 Score (Test): 0.7940189243115288\n",
      "Next point to probe is: {'gamma': np.float64(0.01710943714218037), 'nu': np.float64(0.010766210970167353)} Found the target value to be: 0.7940189243115288\n",
      "\n",
      "F1 Score (Train): 0.4361598640853851\n",
      "F1 Score (Test): 0.817417189126356\n",
      "Next point to probe is: {'gamma': np.float64(0.012679878458994447), 'nu': np.float64(0.02253701907133309)} Found the target value to be: 0.817417189126356\n",
      "\n",
      "F1 Score (Train): 0.48985992314367177\n",
      "F1 Score (Test): 0.9467981061085272\n",
      "Next point to probe is: {'gamma': np.float64(0.0004904039209322319), 'nu': np.float64(0.029338286615133054)} Found the target value to be: 0.9467981061085272\n",
      "\n",
      "F1 Score (Train): 0.48438870373618664\n",
      "F1 Score (Test): 0.9444242775474505\n",
      "Next point to probe is: {'gamma': np.float64(0.0007673458335907821), 'nu': np.float64(0.041652310852197345)} Found the target value to be: 0.9444242775474505\n",
      "\n",
      "F1 Score (Train): 0.4372085390369651\n",
      "F1 Score (Test): 0.8206497309656673\n",
      "Next point to probe is: {'gamma': np.float64(0.013490788771019568), 'nu': np.float64(0.044426098100711214)} Found the target value to be: 0.8206497309656673\n",
      "New optimizer is now aware of 100 points.\n",
      "Already maximized, sugesting new 5 points\n",
      "\n",
      "F1 Score (Train): 0.42124810804517404\n",
      "F1 Score (Test): 0.7766547723040713\n",
      "Next point to probe is: {'gamma': np.float64(0.025025379759580232), 'nu': np.float64(0.011889803297844403)} Found the target value to be: 0.7766547723040713\n",
      "\n",
      "F1 Score (Train): 0.44283040227759285\n",
      "F1 Score (Test): 0.8268126619230638\n",
      "Next point to probe is: {'gamma': np.float64(0.00445081237308266), 'nu': np.float64(0.039501066497102166)} Found the target value to be: 0.8268126619230638\n",
      "\n",
      "F1 Score (Train): 0.4613534160481118\n",
      "F1 Score (Test): 0.8746765074811247\n",
      "Next point to probe is: {'gamma': np.float64(0.0020272626954053767), 'nu': np.float64(0.014780018381070643)} Found the target value to be: 0.8746765074811247\n",
      "\n",
      "F1 Score (Train): 0.4237439428717164\n",
      "F1 Score (Test): 0.7869752079635928\n",
      "Next point to probe is: {'gamma': np.float64(0.007665257378430753), 'nu': np.float64(0.019511450833895667)} Found the target value to be: 0.7869752079635928\n",
      "\n",
      "F1 Score (Train): 0.43186467798159894\n",
      "F1 Score (Test): 0.8035827285374412\n",
      "Next point to probe is: {'gamma': np.float64(0.01098136872409469), 'nu': np.float64(0.01832053159574316)} Found the target value to be: 0.8035827285374412\n",
      "New optimizer is now aware of 105 points.\n",
      "Already maximized, sugesting new 5 points\n",
      "\n",
      "F1 Score (Train): 0.43805215848154005\n",
      "F1 Score (Test): 0.7509670024385032\n",
      "Next point to probe is: {'gamma': np.float64(0.0033679479153810527), 'nu': np.float64(0.027698126613267073)} Found the target value to be: 0.7509670024385032\n",
      "\n",
      "F1 Score (Train): 0.46034436448173977\n",
      "F1 Score (Test): 0.8177296875650915\n",
      "Next point to probe is: {'gamma': np.float64(0.001866810453935574), 'nu': np.float64(0.02919075388168845)} Found the target value to be: 0.8177296875650915\n",
      "\n",
      "F1 Score (Train): 0.42358679092222157\n",
      "F1 Score (Test): 0.7126880295783141\n",
      "Next point to probe is: {'gamma': np.float64(0.012942680395946258), 'nu': np.float64(0.04889045369712628)} Found the target value to be: 0.7126880295783141\n",
      "\n",
      "F1 Score (Train): 0.45029388733218234\n",
      "F1 Score (Test): 0.7828582766618695\n",
      "Next point to probe is: {'gamma': np.float64(0.0026990259896597143), 'nu': np.float64(0.03934756370653738)} Found the target value to be: 0.7828582766618695\n",
      "\n",
      "F1 Score (Train): 0.48675598777340273\n",
      "F1 Score (Test): 0.926287782733423\n",
      "Next point to probe is: {'gamma': np.float64(0.0006768464728808737), 'nu': np.float64(0.010813365984927896)} Found the target value to be: 0.926287782733423\n",
      "New optimizer is now aware of 110 points.\n",
      "Already maximized, sugesting new 5 points\n",
      "\n",
      "F1 Score (Train): 0.4136194111710763\n",
      "F1 Score (Test): 0.6621942749945325\n",
      "Next point to probe is: {'gamma': np.float64(0.012145417720261079), 'nu': np.float64(0.03991335076155033)} Found the target value to be: 0.6621942749945325\n",
      "\n",
      "F1 Score (Train): 0.421928663500385\n",
      "F1 Score (Test): 0.6796526192221606\n",
      "Next point to probe is: {'gamma': np.float64(0.01207438823711644), 'nu': np.float64(0.011747669951252914)} Found the target value to be: 0.6796526192221606\n",
      "\n",
      "F1 Score (Train): 0.415614286713776\n",
      "F1 Score (Test): 0.6631173544193932\n",
      "Next point to probe is: {'gamma': np.float64(0.012887590697400694), 'nu': np.float64(0.04079269095644786)} Found the target value to be: 0.6631173544193932\n",
      "\n",
      "F1 Score (Train): 0.4343626728968798\n",
      "F1 Score (Test): 0.711180330195794\n",
      "Next point to probe is: {'gamma': np.float64(0.0028062325339035664), 'nu': np.float64(0.02922568764683648)} Found the target value to be: 0.711180330195794\n",
      "\n",
      "F1 Score (Train): 0.4388138169663478\n",
      "F1 Score (Test): 0.7228343669345363\n",
      "Next point to probe is: {'gamma': np.float64(0.03464193325886896), 'nu': np.float64(0.033156666641187646)} Found the target value to be: 0.7228343669345363\n",
      "New optimizer is now aware of 115 points.\n",
      "Already maximized, sugesting new 5 points\n",
      "\n",
      "F1 Score (Train): 0.43914339929520196\n",
      "F1 Score (Test): 0.7713202184893996\n",
      "Next point to probe is: {'gamma': np.float64(0.0021131904920799554), 'nu': np.float64(0.010214391284892444)} Found the target value to be: 0.7713202184893996\n",
      "\n",
      "F1 Score (Train): 0.41514663735228297\n",
      "F1 Score (Test): 0.7131610753852315\n",
      "Next point to probe is: {'gamma': np.float64(0.013516496584812474), 'nu': np.float64(0.049906927812766656)} Found the target value to be: 0.7131610753852315\n",
      "\n",
      "F1 Score (Train): 0.3522679838597468\n",
      "F1 Score (Test): 0.5957809089368715\n",
      "Next point to probe is: {'gamma': np.float64(0.03634251897241341), 'nu': np.float64(0.02066335790097209)} Found the target value to be: 0.5957809089368715\n",
      "\n",
      "F1 Score (Train): 0.44421561604584525\n",
      "F1 Score (Test): 0.7797776618001844\n",
      "Next point to probe is: {'gamma': np.float64(0.002207998349808568), 'nu': np.float64(0.03893378575498259)} Found the target value to be: 0.7797776618001844\n",
      "\n",
      "F1 Score (Train): 0.38781951179419744\n",
      "F1 Score (Test): 0.6574934460856849\n",
      "Next point to probe is: {'gamma': np.float64(0.0251604150162574), 'nu': np.float64(0.028876562264106523)} Found the target value to be: 0.6574934460856849\n",
      "New optimizer is now aware of 120 points.\n",
      "Already maximized, sugesting new 5 points\n",
      "\n",
      "F1 Score (Train): 0.43777166921691557\n",
      "F1 Score (Test): 0.7887657579137347\n",
      "Next point to probe is: {'gamma': np.float64(0.0020552843033697305), 'nu': np.float64(0.010053552644809376)} Found the target value to be: 0.7887657579137347\n",
      "\n",
      "F1 Score (Train): 0.4752871892732121\n",
      "F1 Score (Test): 0.8991169807008221\n",
      "Next point to probe is: {'gamma': np.float64(0.00045469174234818814), 'nu': np.float64(0.09352311776293797)} Found the target value to be: 0.8991169807008221\n",
      "\n",
      "F1 Score (Train): 0.3642968145942263\n",
      "F1 Score (Test): 0.6388927576675136\n",
      "Next point to probe is: {'gamma': np.float64(0.050040086269436374), 'nu': np.float64(0.49305148337822596)} Found the target value to be: 0.6388927576675136\n",
      "\n",
      "F1 Score (Train): 0.3721125418705058\n",
      "F1 Score (Test): 0.6519046269062332\n",
      "Next point to probe is: {'gamma': np.float64(0.01326788359480912), 'nu': np.float64(0.04978699591389514)} Found the target value to be: 0.6519046269062332\n",
      "\n",
      "F1 Score (Train): 0.3905768383971819\n",
      "F1 Score (Test): 0.6873681706200406\n",
      "Next point to probe is: {'gamma': np.float64(0.0997968057775284), 'nu': np.float64(0.13840105788853266)} Found the target value to be: 0.6873681706200406\n",
      "New optimizer is now aware of 125 points.\n",
      "Already maximized, sugesting new 5 points\n",
      "\n",
      "F1 Score (Train): 0.3850677730559304\n",
      "F1 Score (Test): 0.4860604941884066\n",
      "Next point to probe is: {'gamma': np.float64(0.00986651296763613), 'nu': np.float64(0.05977056778096048)} Found the target value to be: 0.4860604941884066\n",
      "\n",
      "F1 Score (Train): 0.3374898738571925\n",
      "F1 Score (Test): 0.4203752296020772\n",
      "Next point to probe is: {'gamma': np.float64(0.0924219069889192), 'nu': np.float64(0.05881905780171488)} Found the target value to be: 0.4203752296020772\n",
      "\n",
      "F1 Score (Train): 0.4084245062453983\n",
      "F1 Score (Test): 0.526977579083874\n",
      "Next point to probe is: {'gamma': np.float64(0.012595652935364828), 'nu': np.float64(0.11232176047951854)} Found the target value to be: 0.526977579083874\n",
      "\n",
      "F1 Score (Train): 0.396549111583996\n",
      "F1 Score (Test): 0.502704518958673\n",
      "Next point to probe is: {'gamma': np.float64(0.05141577506179256), 'nu': np.float64(0.16637580843832403)} Found the target value to be: 0.502704518958673\n",
      "\n",
      "F1 Score (Train): 0.3228153186455715\n",
      "F1 Score (Test): 0.3999885046958474\n",
      "Next point to probe is: {'gamma': np.float64(0.09999421123351959), 'nu': np.float64(0.07635978026859762)} Found the target value to be: 0.3999885046958474\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len((activities := X_train[\"activity\"].unique()))):\n",
    "    training = (  # picks the first n samples of each class\n",
    "        X_train[X_train[\"activity\"].isin(activities[:i])]\n",
    "        .groupby(\"activity\")\n",
    "        .head(MIN_SAMPLES)\n",
    "        .copy()\n",
    "    )\n",
    "    testing = X_test[X_test[\"activity\"] == activities[i]].head(MIN_SAMPLES)\n",
    "    training.loc[:, \"isNovelty\"], testing.loc[:, \"isNovelty\"] = False, True\n",
    "    novelty = concat(\n",
    "        [testing, training.sample(n=int(0.2 * len(training)), random_state=42)]\n",
    "    )\n",
    "    training_data = training.drop(columns=[\"isNovelty\"])\n",
    "    train_targets = training[\"isNovelty\"]\n",
    "    # only current activity (as novelty)\n",
    "    testing_data = novelty.drop(columns=[\"isNovelty\"])\n",
    "    test_targets = novelty[\"isNovelty\"]\n",
    "\n",
    "    load_logs(optimizer, logs=[LOGS_PATH])\n",
    "    print(\"New optimizer is now aware of {} points.\".format(len(optimizer.space)))\n",
    "\n",
    "    if not MAXIMAZED:\n",
    "        optimizer.maximize(init_points=5, n_iter=25)\n",
    "        MAXIMAZED = True\n",
    "\n",
    "    else:\n",
    "        load_logs(optimizer, logs=[LOGS_PATH])\n",
    "        print(f\"Already maximized, sugesting new {NUM_TRIALS} points\")\n",
    "        for i in range(NUM_TRIALS):\n",
    "            MAX = optimizer.max[\"target\"]\n",
    "            print(\n",
    "                \"Next point:\",\n",
    "                next_point_to_probe := optimizer.suggest(),\n",
    "                \"Found the target:\",\n",
    "                target := objective_function(**next_point_to_probe),\n",
    "            )\n",
    "            optimizer.register(params=next_point_to_probe, target=target)\n",
    "            if target > MAX:\n",
    "                print(\"New best points found, continuing optimization\")\n",
    "                i = 0\n",
    "\n",
    "    models[i] = optimizer.max  # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC-1-pCv1QtoV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
