{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "from collections.abc import Callable\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from json import dumps\n",
    "from time import time\n",
    "from typing import Dict, Final, Literal\n",
    "\n",
    "import numpy as np\n",
    "import structlog\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from numpy import ndarray, where\n",
    "from pandas import DataFrame, Series, concat, read_csv, set_option\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import (\n",
    "\tauc,\n",
    "\taverage_precision_score,\n",
    "\tf1_score,\n",
    "\tprecision_recall_curve,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "set_option(\"display.max_columns\", None)\n",
    "structlog.configure(\n",
    "\tprocessors=[\n",
    "\t\tstructlog.stdlib.filter_by_level,\n",
    "\t\tstructlog.stdlib.add_logger_name,\n",
    "\t\tstructlog.stdlib.add_log_level,\n",
    "\t\tstructlog.stdlib.PositionalArgumentsFormatter(),\n",
    "\t\tstructlog.processors.TimeStamper(fmt=\"iso\"),\n",
    "\t\tstructlog.processors.StackInfoRenderer(),\n",
    "\t\tstructlog.processors.format_exc_info,\n",
    "\t\tstructlog.processors.UnicodeDecoder(),\n",
    "\t\tstructlog.processors.JSONRenderer(),\n",
    "\t],\n",
    "\tcontext_class=dict,\n",
    "\tlogger_factory=structlog.stdlib.LoggerFactory(),\n",
    "\twrapper_class=structlog.stdlib.BoundLogger,\n",
    "\tcache_logger_on_first_use=True,\n",
    ")\n",
    "\n",
    "type ParamGrid = dict[str, tuple[float | str, ...]]\n",
    "NUM_TRIALS: Final[int] = 20\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "\t\"\"\"Results from a hyperparameter search method.\"\"\"\n",
    "\n",
    "\tmethod: str\n",
    "\tbest_params: dict\n",
    "\tbest_score: float\n",
    "\tcv_scores: list[float]\n",
    "\tfit_time: float\n",
    "\tn_evaluations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedAnnealingSearch:\n",
    "\t\"\"\"\n",
    "\tCustom Simulated Annealing implementation for hyperparameter optimization.\n",
    "\n",
    "\tSimulated Annealing Search:\n",
    "\t- Temperature-based acceptance: Accepts worse solutions with decreasing probability\n",
    "\t- Adaptive parameter perturbation: Different strategies for continuous vs discrete parameters\n",
    "\t- Cooling schedule: Exponential cooling with configurable rate\n",
    "\t- Neighbor generation: Smart parameter space exploration\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tparam_space: dict,\n",
    "\t\tn_iter: int = 100,\n",
    "\t\tinitial_temp: float = 1.0,\n",
    "\t\tcooling_rate: float = 0.95,\n",
    "\t\tmin_temp: float = 0.01,\n",
    "\t\trandom_state: int = 42,\n",
    "\t) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize Simulated Annealing search.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tparam_space: Dictionary of parameter distributions\n",
    "\t\t\tn_iter: Number of iterations\n",
    "\t\t\tinitial_temp: Initial temperature\n",
    "\t\t\tcooling_rate: Rate of temperature decrease\n",
    "\t\t\tmin_temp: Minimum temperature\n",
    "\t\t\trandom_state: Random seed\n",
    "\t\t\"\"\"\n",
    "\t\tself.param_space = param_space\n",
    "\t\tself.n_iter = n_iter\n",
    "\t\tself.initial_temp = initial_temp\n",
    "\t\tself.cooling_rate = cooling_rate\n",
    "\t\tself.min_temp = min_temp\n",
    "\t\tself.random_state = random_state\n",
    "\t\tself.best_params_ = None\n",
    "\t\tself.best_score_ = -np.inf\n",
    "\t\tself.cv_results_ = {\"mean_test_score\": []}\n",
    "\n",
    "\tdef _sample_params(self) -> dict:\n",
    "\t\t\"\"\"Sample random parameters from the parameter space.\"\"\"\n",
    "\t\treturn {\n",
    "\t\t\tkey: values.rvs(random_state=self.random_state)\n",
    "\t\t\tif hasattr(values, \"rvs\")  # scipy distribution\n",
    "\t\t\telse random.choice(values)\n",
    "\t\t\tfor key, values in self.param_space.items()\n",
    "\t\t}\n",
    "\n",
    "\tdef _neighbor_params(self, current_params: dict) -> dict:\n",
    "\t\t\"\"\"Generate neighboring parameters by slightly modifying current ones.\"\"\"\n",
    "\t\tneighbor = deepcopy(current_params)\n",
    "\n",
    "\t\t# Choose a random parameter to modify\n",
    "\t\tparam_to_modify = random.choice(list(self.param_space.keys()))\n",
    "\n",
    "\t\tif hasattr(self.param_space[param_to_modify], \"rvs\"):  # continuous parameter\n",
    "\t\t\tif param_to_modify in [\"nu\", \"ocsvm_nu\"]:\n",
    "\t\t\t\t# For nu, stay within bounds [0.001, 1.0]\n",
    "\t\t\t\tcurrent_val = neighbor[param_to_modify]\n",
    "\t\t\t\tneighbor[param_to_modify] = np.clip(\n",
    "\t\t\t\t\tcurrent_val + np.random.normal(0, 0.05 * current_val), 0.001, 1.0\n",
    "\t\t\t\t)\n",
    "\t\t\telif \"gamma\" in param_to_modify:\n",
    "\t\t\t\t# For gamma, use log-space perturbation\n",
    "\t\t\t\tcurrent_val = neighbor[param_to_modify]\n",
    "\t\t\t\tif isinstance(current_val, (int, float)):\n",
    "\t\t\t\t\tneighbor[param_to_modify] = 10 ** np.clip(\n",
    "\t\t\t\t\t\tnp.log10(current_val) + np.random.normal(0, 0.1), -4, 1\n",
    "\t\t\t\t\t)\n",
    "\t\t\telif \"tol\" in param_to_modify:\n",
    "\t\t\t\t# For tolerance, use log-space perturbation\n",
    "\t\t\t\tcurrent_val = neighbor[param_to_modify]\n",
    "\t\t\t\tneighbor[param_to_modify] = 10 ** np.clip(\n",
    "\t\t\t\t\tnp.log10(current_val) + np.random.normal(0, 0.1), -6, -1\n",
    "\t\t\t\t)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Generic continuous parameter perturbation\n",
    "\t\t\t\tneighbor[param_to_modify] = self.param_space[param_to_modify].rvs(\n",
    "\t\t\t\t\trandom_state=self.random_state\n",
    "\t\t\t\t)\n",
    "\t\telse:  # discrete parameter\n",
    "\t\t\tneighbor[param_to_modify] = random.choice(self.param_space[param_to_modify])\n",
    "\n",
    "\t\treturn neighbor\n",
    "\n",
    "\tdef _evaluate_params(self, params: ParamGrid, X: DataFrame, y: Series) -> float:\n",
    "\t\t\"\"\"Evaluate parameter configuration using cross-validation.\"\"\"\n",
    "\t\treturn np.mean(\n",
    "\t\t\tcross_val_score(\n",
    "\t\t\t\tOneClassSVM(**params, kernel=\"rbf\"), X, y, cv=4, scoring=score_function\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\n",
    "\tdef fit(self, X: DataFrame, y: Series) -> \"SimulatedAnnealingSearch\":\n",
    "\t\t\"\"\"Fit the simulated annealing search.\"\"\"\n",
    "\t\trandom.seed(self.random_state)\n",
    "\t\tnp.random.seed(self.random_state)\n",
    "\n",
    "\t\t# Initialize with random parameters\n",
    "\t\tcurrent_params = self._sample_params()\n",
    "\t\tcurrent_score = self._evaluate_params(current_params, X, y)\n",
    "\n",
    "\t\tself.best_params_ = deepcopy(current_params)\n",
    "\t\tself.best_score_ = current_score\n",
    "\n",
    "\t\ttemperature = self.initial_temp\n",
    "\n",
    "\t\tfor iteration in range(self.n_iter):\n",
    "\t\t\t# Generate neighbor, store the score for cv_results and Accept or reject neighbor\n",
    "\t\t\tneighbor_params = self._neighbor_params(current_params)\n",
    "\t\t\tneighbor_score = self._evaluate_params(neighbor_params, X, y)\n",
    "\t\t\tself.cv_results_[\"mean_test_score\"].append(neighbor_score)\n",
    "\n",
    "\t\t\tif neighbor_score > current_score:  # Better solution - always accept\n",
    "\t\t\t\tcurrent_params = neighbor_params\n",
    "\t\t\t\tcurrent_score = neighbor_score\n",
    "\t\t\telse:  # Worse solution - accept with probability\n",
    "\t\t\t\tif (\n",
    "\t\t\t\t\trandom.random()\n",
    "\t\t\t\t\t< np.exp(neighbor_score - current_score / temperature)\n",
    "\t\t\t\t\tif temperature > 0\n",
    "\t\t\t\t\telse 0\n",
    "\t\t\t\t):\n",
    "\t\t\t\t\tcurrent_params = neighbor_params\n",
    "\t\t\t\t\tcurrent_score = neighbor_score\n",
    "\n",
    "\t\t\tif current_score > self.best_score_:  # Update best solution\n",
    "\t\t\t\tself.best_params_ = deepcopy(current_params)\n",
    "\t\t\t\tself.best_score_ = current_score\n",
    "\n",
    "\t\t\t# Cool down\n",
    "\t\t\ttemperature = max(temperature * self.cooling_rate, self.min_temp)\n",
    "\n",
    "\t\treturn self\n",
    "\n",
    "\n",
    "class GeneticAlgorithmSearch:\n",
    "\t\"\"\"\n",
    "\tCustom Genetic Algorithm implementation for hyperparameter optimization.\n",
    "\n",
    "\tGenetic Algorithm Search:\n",
    "\t- Population-based optimization: Maintains diverse parameter sets\n",
    "\t- Tournament selection: Robust parent selection mechanism\n",
    "\t- Uniform crossover: Parameter exchange between parents\n",
    "\t- Adaptive mutation: Random parameter changes with configurable rate\n",
    "\t- Elite preservation: Keeps best solutions across generations\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tparam_space: dict,\n",
    "\t\tpopulation_size: int = 20,\n",
    "\t\tn_generations: int = 10,\n",
    "\t\tmutation_rate: float = 0.1,\n",
    "\t\tcrossover_rate: float = 0.8,\n",
    "\t\telite_size: int = 2,\n",
    "\t\trandom_state: int = 42,\n",
    "\t) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize Genetic Algorithm search.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tparam_space: Dictionary of parameter distributions\n",
    "\t\t\tpopulation_size: Size of population\n",
    "\t\t\tn_generations: Number of generations\n",
    "\t\t\tmutation_rate: Probability of mutation\n",
    "\t\t\tcrossover_rate: Probability of crossover\n",
    "\t\t\telite_size: Number of elite individuals to preserve\n",
    "\t\t\trandom_state: Random seed\n",
    "\t\t\"\"\"\n",
    "\t\tself.param_space = param_space\n",
    "\t\tself.population_size = population_size\n",
    "\t\tself.n_generations = n_generations\n",
    "\t\tself.mutation_rate = mutation_rate\n",
    "\t\tself.crossover_rate = crossover_rate\n",
    "\t\tself.elite_size = elite_size\n",
    "\t\tself.random_state = random_state\n",
    "\t\tself.best_params_ = None\n",
    "\t\tself.best_score_ = -np.inf\n",
    "\t\tself.cv_results_ = {\"mean_test_score\": []}\n",
    "\n",
    "\tdef _create_individual(self) -> dict:\n",
    "\t\t\"\"\"Create a random individual (parameter set).\"\"\"\n",
    "\t\treturn {\n",
    "\t\t\tkey: values.rvs(random_state=self.random_state)\n",
    "\t\t\tif hasattr(values, \"rvs\")  # scipy distribution\n",
    "\t\t\telse random.choice(values)\n",
    "\t\t\tfor key, values in self.param_space.items()\n",
    "\t\t}\n",
    "\n",
    "\tdef _crossover(self, parent1: dict, parent2: dict) -> Tuple[dict, dict]:\n",
    "\t\t\"\"\"Create two offspring from two parents using uniform crossover.\"\"\"\n",
    "\t\tchild1, child2 = deepcopy(parent1), deepcopy(parent2)\n",
    "\n",
    "\t\tfor key in parent1.keys():\n",
    "\t\t\tif random.random() < 0.5:  # Swap parameter values\n",
    "\t\t\t\tchild1[key], child2[key] = child2[key], child1[key]\n",
    "\n",
    "\t\treturn child1, child2\n",
    "\n",
    "\tdef _mutate(self, individual: dict) -> dict:\n",
    "\t\t\"\"\"Mutate an individual by randomly changing some parameters.\"\"\"\n",
    "\t\tmutated = deepcopy(individual)\n",
    "\n",
    "\t\tfor key in individual.keys():\n",
    "\t\t\tif random.random() < self.mutation_rate:\n",
    "\t\t\t\tmutated[key] = (\n",
    "\t\t\t\t\tself.param_space[key].rvs(random_state=self.random_state)\n",
    "\t\t\t\t\tif hasattr(self.param_space[key], \"rvs\")  # continuous parameter\n",
    "\t\t\t\t\telse random.choice(self.param_space[key])  # discrete parameter\n",
    "\t\t\t\t)\n",
    "\t\treturn mutated\n",
    "\n",
    "\tdef _tournament_selection(\n",
    "\t\tself, population: list, fitness_scores: list, tournament_size: int = 3\n",
    "\t) -> dict:\n",
    "\t\t\"\"\"Select an individual using tournament selection.\"\"\"\n",
    "\t\ttournament_indices = random.sample(\n",
    "\t\t\trange(len(population)), min(tournament_size, len(population))\n",
    "\t\t)\n",
    "\t\treturn population[\n",
    "\t\t\ttournament_indices[\n",
    "\t\t\t\tnp.argmax([fitness_scores[i] for i in tournament_indices])\n",
    "\t\t\t]\n",
    "\t\t]\n",
    "\n",
    "\tdef _evaluate_params(self, params: dict, X: DataFrame, y: Series) -> float:\n",
    "\t\t\"\"\"Evaluate parameter configuration using cross-validation.\"\"\"\n",
    "\t\treturn np.mean(\n",
    "\t\t\tcross_val_score(\n",
    "\t\t\t\tOneClassSVM(**params, kernel=\"rbf\"), X, y, cv=4, scoring=score_function\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\n",
    "\tdef fit(self, X: DataFrame, y: Series) -> \"GeneticAlgorithmSearch\":\n",
    "\t\t\"\"\"Fit the genetic algorithm search.\"\"\"\n",
    "\t\trandom.seed(self.random_state)\n",
    "\t\tnp.random.seed(self.random_state)\n",
    "\t\tpopulation = [self._create_individual() for _ in range(self.population_size)]\n",
    "\n",
    "\t\tfor generation in range(self.n_generations):  # Evaluate fitness\n",
    "\t\t\tprint(f\"Evaluating Generation {generation}\")\n",
    "\t\t\tfitness_scores = []\n",
    "\t\t\tfor individual in population:\n",
    "\t\t\t\tscore = self._evaluate_params(individual, X, y)\n",
    "\t\t\t\tfitness_scores.append(score)\n",
    "\t\t\t\tself.cv_results_[\"mean_test_score\"].append(score)\n",
    "\n",
    "\t\t\t\tif score > self.best_score_:\n",
    "\t\t\t\t\tself.best_params_ = deepcopy(individual)\n",
    "\t\t\t\t\tself.best_score_ = score\n",
    "\n",
    "\t\t\t# Create next generation | Elite selection - keep best individuals\n",
    "\t\t\tnew_population = [\n",
    "\t\t\t\tdeepcopy(population[idx])\n",
    "\t\t\t\tfor idx in np.argsort(fitness_scores)[-self.elite_size :]\n",
    "\t\t\t]\n",
    "\t\t\t# Generate offspring\n",
    "\t\t\twhile len(new_population) < self.population_size:\n",
    "\t\t\t\t# Selection\n",
    "\t\t\t\tparent1 = self._tournament_selection(population, fitness_scores)\n",
    "\t\t\t\tparent2 = self._tournament_selection(population, fitness_scores)\n",
    "\t\t\t\t# Crossover\n",
    "\t\t\t\tif random.random() < self.crossover_rate:\n",
    "\t\t\t\t\tchild1, child2 = self._crossover(parent1, parent2)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tchild1, child2 = deepcopy(parent1), deepcopy(parent2)\n",
    "\t\t\t\t# Mutation\n",
    "\t\t\t\tnew_population.extend([self._mutate(child1), self._mutate(child2)])\n",
    "\t\t\t# Trim to exact population size\n",
    "\t\t\tpopulation = new_population[: self.population_size]\n",
    "\n",
    "\t\treturn self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAutoencoder(nn.Module):\n",
    "\t\"\"\"\n",
    "\tLSTM-based Autoencoder for time-series reconstruction.\n",
    "\n",
    "\tThis model learns to reconstruct normal activity patterns. Anomalies/novelties\n",
    "\twill have higher reconstruction errors.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tinput_dim: int,\n",
    "\t\thidden_dim: int = 64,\n",
    "\t\tnum_layers: int = 2,\n",
    "\t\tdropout: float = 0.2,\n",
    "\t\tbidirectional: bool = False,\n",
    "\t) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize LSTM Autoencoder.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tinput_dim: Number of input features (sensor channels)\n",
    "\t\t\thidden_dim: Hidden state dimension\n",
    "\t\t\tnum_layers: Number of LSTM layers\n",
    "\t\t\tdropout: Dropout rate between LSTM layers\n",
    "\t\t\tbidirectional: Whether to use bidirectional LSTM\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(LSTMAutoencoder, self).__init__()\n",
    "\n",
    "\t\tself.input_dim = input_dim\n",
    "\t\tself.hidden_dim = hidden_dim\n",
    "\t\tself.num_layers = num_layers\n",
    "\t\tself.bidirectional = bidirectional\n",
    "\t\tself.encoder = nn.LSTM(\n",
    "\t\t\tinput_size=input_dim,\n",
    "\t\t\thidden_size=hidden_dim,\n",
    "\t\t\tnum_layers=num_layers,\n",
    "\t\t\tbatch_first=True,\n",
    "\t\t\tdropout=dropout if num_layers > 1 else 0,\n",
    "\t\t\tbidirectional=bidirectional,\n",
    "\t\t)\n",
    "\t\t# Bottleneck dimension\n",
    "\t\tencoder_output_dim = hidden_dim * (2 if bidirectional else 1)\n",
    "\t\tself.decoder = nn.LSTM(\n",
    "\t\t\tinput_size=encoder_output_dim,\n",
    "\t\t\thidden_size=hidden_dim,\n",
    "\t\t\tnum_layers=num_layers,\n",
    "\t\t\tbatch_first=True,\n",
    "\t\t\tdropout=dropout if num_layers > 1 else 0,\n",
    "\t\t)\n",
    "\t\tself.output_layer = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\t\"\"\"\n",
    "\t\tForward pass through the autoencoder.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tx: Input tensor of shape (batch, seq_len, input_dim)\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tReconstructed tensor of shape (batch, seq_len, input_dim)\n",
    "\t\t\"\"\"\n",
    "\t\tbatch_size, seq_len, _ = x.shape\n",
    "\t\tencoded, (hidden, cell) = self.encoder(x)\n",
    "\t\t# Use only forward direction hidden states if bidirectional\n",
    "\t\tif self.bidirectional:\n",
    "\t\t\thidden = hidden[: self.num_layers]\n",
    "\t\t\tcell = cell[: self.num_layers]\n",
    "\n",
    "\t\t# Prepare decoder input (repeat last encoded state)\n",
    "\t\tdecoded, _ = self.decoder(\n",
    "\t\t\tencoded[:, -1:, :].repeat(1, seq_len, 1), (hidden, cell)\n",
    "\t\t)\n",
    "\t\t# Project to original dimension\n",
    "\t\treturn self.output_layer(decoded)\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "\t\"\"\"PyTorch Dataset for windowed time-series data.\"\"\"\n",
    "\n",
    "\tdef __init__(self, data: np.ndarray) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize dataset.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tdata: numpy array of shape (n_windows, window_size, n_features)\n",
    "\t\t\"\"\"\n",
    "\t\tself.data = torch.FloatTensor(data)\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\t\"\"\"Return number of windows.\"\"\"\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, idx: int) -> torch.Tensor:\n",
    "\t\t\"\"\"Get a window by index.\"\"\"\n",
    "\t\treturn self.data[idx]\n",
    "\n",
    "\n",
    "class LSTMAutoencoderWrapper:\n",
    "\t\"\"\"\n",
    "\tWrapper to make LSTM Autoencoder compatible with sklearn API.\n",
    "\n",
    "\tThis wrapper handles training, prediction, and decision function\n",
    "\tcomputation for the LSTM autoencoder.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tinput_dim: int,\n",
    "\t\thidden_dim: int = 64,\n",
    "\t\tnum_layers: int = 2,\n",
    "\t\tdropout: float = 0.2,\n",
    "\t\tbidirectional: bool = False,\n",
    "\t\tlearning_rate: float = 0.001,\n",
    "\t\tepochs: int = 50,\n",
    "\t\tbatch_size: int = 64,\n",
    "\t\tdevice: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "\t\tthreshold_percentile: float = 95.0,\n",
    "\t) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize LSTM Autoencoder wrapper.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tinput_dim: Number of input features\n",
    "\t\t\thidden_dim: Hidden dimension size\n",
    "\t\t\tnum_layers: Number of LSTM layers\n",
    "\t\t\tdropout: Dropout rate\n",
    "\t\t\tbidirectional: Use bidirectional LSTM\n",
    "\t\t\tlearning_rate: Learning rate for Adam optimizer\n",
    "\t\t\tepochs: Number of training epochs\n",
    "\t\t\tbatch_size: Batch size for training\n",
    "\t\t\tdevice: Device to train on ('cuda' or 'cpu')\n",
    "\t\t\tthreshold_percentile: Percentile for anomaly threshold\n",
    "\t\t\"\"\"\n",
    "\t\tself.input_dim = input_dim\n",
    "\t\tself.hidden_dim = hidden_dim\n",
    "\t\tself.num_layers = num_layers\n",
    "\t\tself.dropout = dropout\n",
    "\t\tself.bidirectional = bidirectional\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\t\tself.epochs = epochs\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.device = device\n",
    "\t\tself.threshold_percentile = threshold_percentile\n",
    "\n",
    "\t\tself.model: LSTMAutoencoder | None = None\n",
    "\t\tself.threshold: float | None = None\n",
    "\n",
    "\tdef fit(self, X: np.ndarray, y: Series | None = None) -> \"LSTMAutoencoderWrapper\":\n",
    "\t\t\"\"\"\n",
    "\t\tTrain the autoencoder on normal data.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tX: numpy array of shape (n_windows, window_size, n_features)\n",
    "\t\t\ty: Ignored, for sklearn compatibility\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tSelf\n",
    "\t\t\"\"\"\n",
    "\t\tself.model = LSTMAutoencoder(\n",
    "\t\t\tinput_dim=self.input_dim,\n",
    "\t\t\thidden_dim=self.hidden_dim,\n",
    "\t\t\tnum_layers=self.num_layers,\n",
    "\t\t\tdropout=self.dropout,\n",
    "\t\t\tbidirectional=self.bidirectional,\n",
    "\t\t).to(self.device)\n",
    "\t\tdataloader = DataLoader(\n",
    "\t\t\tTimeSeriesDataset(X),\n",
    "\t\t\tbatch_size=self.batch_size,\n",
    "\t\t\tshuffle=True,\n",
    "\t\t\tdrop_last=False,\n",
    "\t\t)\n",
    "\t\tcriterion = nn.MSELoss()  # setup\n",
    "\t\toptimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "\t\tself.model.train()\n",
    "\t\tfor epoch in range(self.epochs):\n",
    "\t\t\tprint(f\"Epoch {epoch + 1}/{self.epochs}\")\n",
    "\t\t\tepoch_loss = 0.0\n",
    "\t\t\tfor batch in dataloader:\n",
    "\t\t\t\tbatch = batch.to(self.device)\n",
    "\t\t\t\t# Forward pass\n",
    "\t\t\t\tloss = criterion(self.model(batch), batch)\n",
    "\t\t\t\t# Backward pass\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t\tepoch_loss += loss.item()\n",
    "\n",
    "\t\t# Calculate threshold on training data\n",
    "\t\ttrain_scores = self.decision_function(X)\n",
    "\t\tself.threshold = np.percentile(train_scores, self.threshold_percentile)  # type: ignore\n",
    "\n",
    "\t\treturn self\n",
    "\n",
    "\tdef decision_function(self, X: np.ndarray) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tCalculate reconstruction error (anomaly score).\n",
    "\n",
    "\t\tHigher values indicate more anomalous samples.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tX: numpy array of shape (n_windows, window_size, n_features)\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tAnomaly scores for each window\n",
    "\t\t\"\"\"\n",
    "\t\tif self.model:\n",
    "\t\t\tself.model.eval()\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Model has not been trained yet. Call fit() first.\")\n",
    "\n",
    "\t\tscores = []\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor batch in DataLoader(\n",
    "\t\t\t\tTimeSeriesDataset(X), batch_size=self.batch_size, shuffle=False\n",
    "\t\t\t):\n",
    "\t\t\t\tbatch = batch.to(self.device)\n",
    "\t\t\t\tscores.append(  # Calculate reconstruction error per sample\n",
    "\t\t\t\t\ttorch.mean((batch - self.model(batch)) ** 2, dim=(1, 2))\n",
    "\t\t\t\t\t.cpu()\n",
    "\t\t\t\t\t.numpy()\n",
    "\t\t\t\t)\n",
    "\t\treturn np.concatenate(scores)\n",
    "\n",
    "\tdef predict(self, X: np.ndarray) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tPredict novelty: -1 for anomalies, 1 for normal.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tX: numpy array of shape (n_windows, window_size, n_features)\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tPredictions: -1 (anomaly) or 1 (normal)\n",
    "\t\t\"\"\"\n",
    "\t\treturn np.where(self.decision_function(X) > self.threshold, -1, 1)\n",
    "\n",
    "\tdef get_params(self, deep: bool = True) -> Dict:\n",
    "\t\t\"\"\"Get parameters for sklearn compatibility.\"\"\"\n",
    "\t\treturn {\n",
    "\t\t\t\"input_dim\": self.input_dim,\n",
    "\t\t\t\"hidden_dim\": self.hidden_dim,\n",
    "\t\t\t\"num_layers\": self.num_layers,\n",
    "\t\t\t\"dropout\": self.dropout,\n",
    "\t\t\t\"bidirectional\": self.bidirectional,\n",
    "\t\t\t\"learning_rate\": self.learning_rate,\n",
    "\t\t\t\"epochs\": self.epochs,\n",
    "\t\t\t\"batch_size\": self.batch_size,\n",
    "\t\t\t\"threshold_percentile\": self.threshold_percentile,\n",
    "\t\t}\n",
    "\n",
    "\tdef set_params(self, **params) -> \"LSTMAutoencoderWrapper\":\n",
    "\t\t\"\"\"Set parameters for sklearn compatibility.\"\"\"\n",
    "\t\tfor key, value in params.items():\n",
    "\t\t\tsetattr(self, key, value)\n",
    "\t\treturn self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoveltyDetectionEnsemble:\n",
    "\t\"\"\"\n",
    "\tEnsemble of LSTM Autoencoder, Isolation Forest, and One-Class SVM.\n",
    "\n",
    "\tThis ensemble combines three different novelty detection approaches:\n",
    "\t1. LSTM Autoencoder: Captures temporal patterns\n",
    "\t2. Isolation Forest: Fast tree-based anomaly detection\n",
    "\t3. One-Class SVM: Kernel-based boundary learning\n",
    "\n",
    "\tPredictions are combined using weighted voting or averaging of decision scores.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\t# Data processing params\n",
    "\t\twindow_size: int = 100,\n",
    "\t\tstride: int = 50,\n",
    "\t\t# LSTM params\n",
    "\t\tlstm_hidden_dim: int = 64,\n",
    "\t\tlstm_num_layers: int = 2,\n",
    "\t\tlstm_dropout: float = 0.2,\n",
    "\t\tlstm_learning_rate: float = 0.001,\n",
    "\t\tlstm_epochs: int = 30,\n",
    "\t\tlstm_batch_size: int = 64,\n",
    "\t\tlstm_threshold_percentile: float = 95.0,\n",
    "\t\t# Isolation Forest params\n",
    "\t\tif_n_estimators: int = 100,\n",
    "\t\tif_contamination: float = 0.1,\n",
    "\t\tif_max_samples: str | int = \"auto\",\n",
    "\t\t# One-Class SVM params\n",
    "\t\tocsvm_kernel: str = \"rbf\",\n",
    "\t\tocsvm_nu: float = 0.1,\n",
    "\t\tocsvm_gamma: str | float = \"scale\",\n",
    "\t\tocsvm_tol: float = 1e-3,\n",
    "\t\t# Ensemble params\n",
    "\t\tweights: Dict[str, float] | None = None,\n",
    "\t\tvoting: str = \"soft\",  # 'soft' (decision scores) or 'hard' (predictions)\n",
    "\t\tuse_lstm: bool = True,\n",
    "\t\tuse_if: bool = True,\n",
    "\t\tuse_ocsvm: bool = True,\n",
    "\t) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize the ensemble model.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\twindow_size: Size of sliding window for time-series\n",
    "\t\t\tstride: Stride for sliding window\n",
    "\t\t\tlstm_hidden_dim: LSTM hidden dimension\n",
    "\t\t\tlstm_num_layers: Number of LSTM layers\n",
    "\t\t\tlstm_dropout: LSTM dropout rate\n",
    "\t\t\tlstm_learning_rate: LSTM learning rate\n",
    "\t\t\tlstm_epochs: Number of LSTM training epochs\n",
    "\t\t\tlstm_batch_size: LSTM batch size\n",
    "\t\t\tlstm_threshold_percentile: Percentile for LSTM anomaly threshold\n",
    "\t\t\tif_n_estimators: Number of trees in Isolation Forest\n",
    "\t\t\tif_contamination: Expected proportion of outliers\n",
    "\t\t\tif_max_samples: Number of samples to draw for each tree\n",
    "\t\t\tocsvm_kernel: Kernel type for SVM\n",
    "\t\t\tocsvm_nu: Nu parameter for SVM\n",
    "\t\t\tocsvm_gamma: Gamma parameter for SVM\n",
    "\t\t\tocsvm_tol: Tolerance for SVM\n",
    "\t\t\tweights: Dictionary of weights for each model\n",
    "\t\t\tvoting: Voting strategy ('soft' or 'hard')\n",
    "\t\t\tuse_lstm: Whether to use LSTM in ensemble\n",
    "\t\t\tuse_if: Whether to use Isolation Forest in ensemble\n",
    "\t\t\tuse_ocsvm: Whether to use One-Class SVM in ensemble\n",
    "\t\t\"\"\"\n",
    "\t\tself.window_size = window_size\n",
    "\t\tself.stride = stride\n",
    "\t\tself.lstm_params = {\n",
    "\t\t\t\"hidden_dim\": lstm_hidden_dim,\n",
    "\t\t\t\"num_layers\": lstm_num_layers,\n",
    "\t\t\t\"dropout\": lstm_dropout,\n",
    "\t\t\t\"learning_rate\": lstm_learning_rate,\n",
    "\t\t\t\"epochs\": lstm_epochs,\n",
    "\t\t\t\"batch_size\": lstm_batch_size,\n",
    "\t\t\t\"threshold_percentile\": lstm_threshold_percentile,\n",
    "\t\t}\n",
    "\t\tself.if_params = {\n",
    "\t\t\t\"n_estimators\": if_n_estimators,\n",
    "\t\t\t\"contamination\": if_contamination,\n",
    "\t\t\t\"max_samples\": if_max_samples,\n",
    "\t\t\t\"random_state\": 42,\n",
    "\t\t}\n",
    "\t\tself.ocsvm_params = {\n",
    "\t\t\t\"kernel\": ocsvm_kernel,\n",
    "\t\t\t\"nu\": ocsvm_nu,\n",
    "\t\t\t\"gamma\": ocsvm_gamma,\n",
    "\t\t\t\"tol\": ocsvm_tol,\n",
    "\t\t}\n",
    "\t\tself.use_lstm = use_lstm\n",
    "\t\tself.use_if = use_if\n",
    "\t\tself.use_ocsvm = use_ocsvm\n",
    "\n",
    "\t\tdefault_weights = {}\n",
    "\t\tif use_lstm:\n",
    "\t\t\tdefault_weights[\"lstm\"] = 1.0\n",
    "\t\tif use_if:\n",
    "\t\t\tdefault_weights[\"if\"] = 1.0\n",
    "\t\tif use_ocsvm:\n",
    "\t\t\tdefault_weights[\"ocsvm\"] = 1.0\n",
    "\n",
    "\t\tself.weights = weights or default_weights\n",
    "\t\tself.voting = voting\n",
    "\n",
    "\t\tself.lstm_model: LSTMAutoencoderWrapper] = None\n",
    "\t\tself.if_model: IsolationForest] = None\n",
    "\t\tself.ocsvm_model: OneClassSVM] = None\n",
    "\t\tself.scaler = StandardScaler()\n",
    "\t\tself.input_dim: int] = None\n",
    "\n",
    "\tdef _create_sliding_windows(\n",
    "\t\tself, data: DataFrame, activity_col: str = \"activity\"\n",
    "\t) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tCreate sliding windows from DataFrame.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tdata: Input DataFrame with sensor data\n",
    "\t\t\tactivity_col: Name of activity column to exclude\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tWindowed array of shape (n_windows, window_size, n_features)\n",
    "\t\t\"\"\"\n",
    "\t\t# Get sensor columns (exclude activity if present)\n",
    "\t\tsensor_cols = [col for col in data.columns if col != activity_col]\n",
    "\t\tvalues = data[sensor_cols].values\n",
    "\t\twindows = [\n",
    "\t\t\tvalues[i : i + self.window_size]\n",
    "\t\t\tfor i in range(0, len(values) - self.window_size + 1, self.stride)\n",
    "\t\t]\n",
    "\t\treturn (\n",
    "\t\t\tnp.array(windows)\n",
    "\t\t\tif windows\n",
    "\t\t\telse np.array([]).reshape(0, self.window_size, len(sensor_cols))\n",
    "\t\t)\n",
    "\n",
    "\tdef fit(\n",
    "\t\tself, X: DataFrame, y: Series | None = None\n",
    "\t) -> \"NoveltyDetectionEnsemble\":\n",
    "\t\t\"\"\"\n",
    "\t\tTrain all models in the ensemble.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tX: Training DataFrame with sensor data\n",
    "\t\t\ty: Ignored, for sklearn compatibility\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tSelf\n",
    "\t\t\"\"\"\n",
    "\t\t# Create windowed data\n",
    "\t\tif len(X_windowed := self._create_sliding_windows(X)) == 0:\n",
    "\t\t\traise ValueError(\n",
    "\t\t\t\tf\"No windows created. Data length: {len(X)}, window_size: {self.window_size}\"\n",
    "\t\t\t)\n",
    "\n",
    "\t\tn_windows, window_size, n_features = X_windowed.shape\n",
    "\t\tself.input_dim = n_features\n",
    "\n",
    "\t\tif self.use_lstm:# 1. Train LSTM Autoencoder on windowed data\n",
    "\t\t\tself.lstm_model = LSTMAutoencoderWrapper(\n",
    "\t\t\t\tinput_dim=n_features, **self.lstm_params\n",
    "\t\t\t)\n",
    "\t\t\tself.lstm_model.fit(X_windowed)\n",
    "\n",
    "\t\t# 2. Flatten windows for classical models and normalize\n",
    "\t\tX_scaled = self.scaler.fit_transform(X_windowed.reshape(n_windows, -1))\n",
    "\n",
    "\t\tif self.use_if:# 3. Train Isolation Forest\n",
    "\t\t\tself.if_model = IsolationForest(**self.if_params)\n",
    "\t\t\tself.if_model.fit(X_scaled)\n",
    "\n",
    "\t\tif self.use_ocsvm:# 4. Train One-Class SVM\n",
    "\t\t\tself.ocsvm_model = OneClassSVM(**self.ocsvm_params)\n",
    "\t\t\tself.ocsvm_model.fit(X_scaled)\n",
    "\n",
    "\t\treturn self\n",
    "\n",
    "\tdef decision_function(self, X: DataFrame) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tCalculate weighted ensemble anomaly scores.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tX: Test DataFrame with sensor data\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tAnomaly scores (higher = more anomalous)\n",
    "\t\t\"\"\"\n",
    "\t\t# Create windowed data\n",
    "\t\tif len(X_windowed := self._create_sliding_windows(X)) == 0:\n",
    "\t\t\treturn np.array([])\n",
    "\n",
    "\t\tn_windows = X_windowed.shape[0]\n",
    "\n",
    "\t\tscores_list = []\n",
    "\t\tweights_list = []\n",
    "\n",
    "\t\t# LSTM scores (already positive for anomalies)\n",
    "\t\tif self.use_lstm and self.lstm_model is not None:\n",
    "\t\t\tscores_list.append(self._normalize_scores( self.lstm_model.decision_function(X_windowed)))\n",
    "\t\t\tweights_list.append(self.weights.get(\"lstm\", 1.0))\n",
    "\n",
    "\t\t# Flatten and scale for classical models\n",
    "\t\tX_scaled = self.scaler.transform(X_windowed.reshape(n_windows, -1))\n",
    "\n",
    "\t\t# Isolation Forest scores (negate to make higher = more anomalous)\n",
    "\t\tif self.use_if and self.if_model is not None:\n",
    "\t\t\tscores_list.append(self._normalize_scores(-self.if_model.score_samples(X_scaled)))\n",
    "\t\t\tweights_list.append(self.weights.get(\"if\", 1.0))\n",
    "\n",
    "\t\t# One-Class SVM scores (negate to make higher = more anomalous)\n",
    "\t\tif self.use_ocsvm and self.ocsvm_model is not None:\n",
    "\t\t\tscores_list.append(self._normalize_scores(-self.ocsvm_model.decision_function(X_scaled)))\n",
    "\t\t\tweights_list.append(self.weights.get(\"ocsvm\", 1.0))\n",
    "\n",
    "\t\tif not scores_list:# Weighted combination\n",
    "\t\t\traise ValueError(\"No models enabled in ensemble\")\n",
    "\n",
    "\t\treturn sum(w * s for w, s in zip(weights_list, scores_list)) / sum(\n",
    "\t\t\tweights_list\n",
    "\t\t) # type: ignore\n",
    "\n",
    "\tdef predict(self, X: DataFrame) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tPredict novelty using ensemble voting.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tX: Test DataFrame with sensor data\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tPredictions: -1 (anomaly) or 1 (normal)\n",
    "\t\t\"\"\"\n",
    "\t\tif len(X_windowed:= self._create_sliding_windows(X)) == 0:\n",
    "\t\t\treturn np.array([])\n",
    "\n",
    "\t\tif self.voting == \"soft\":\n",
    "\t\t\t# Use decision scores with a threshold\n",
    "\t\t\tscores = self.decision_function(X)\n",
    "\t\t\t# percentile Can be tuned\n",
    "\t\t\treturn np.where(scores > np.percentile(scores, 90), -1, 1)\n",
    "\t\telse:\n",
    "\t\t\t# Hard voting\n",
    "\t\t\tX_scaled = self.scaler.transform(X_windowed.reshape( X_windowed.shape[0], -1))\n",
    "\t\t\tpredictions = []\n",
    "\n",
    "\t\t\tif self.use_lstm and self.lstm_model is not None:\n",
    "\t\t\t\tpredictions.append(self.lstm_model.predict(X_windowed))\n",
    "\t\t\tif self.use_if and self.if_model is not None:\n",
    "\t\t\t\tpredictions.append(self.if_model.predict(X_scaled))\n",
    "\t\t\tif self.use_ocsvm and self.ocsvm_model is not None:\n",
    "\t\t\t\tpredictions.append(self.ocsvm_model.predict(X_scaled))\n",
    "\n",
    "\t\t\tif not predictions:\n",
    "\t\t\t\traise ValueError(\"No models enabled in ensemble\")\n",
    "\n",
    "\t\t\t# Majority voting\n",
    "\t\t\treturn np.sign(np.sum(np.stack(predictions), axis=0))\n",
    "\n",
    "\tdef _normalize_scores(self, scores: np.ndarray) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tNormalize scores to [0, 1] range.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tscores: Raw anomaly scores\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tNormalized scores\n",
    "\t\t\"\"\"\n",
    "\t\tif (max_score :=np.max(scores)) - (min_score:=np.min(scores)) == 0:\n",
    "\t\t\treturn np.zeros_like(scores)\n",
    "\t\treturn (scores - min_score) / (max_score - min_score)\n",
    "\n",
    "\tdef get_params(self, deep: bool = True) -> dict[str, int | float | None]:\n",
    "\t\t\"\"\"Get parameters for sklearn compatibility.\"\"\"\n",
    "\t\treturn {\n",
    "\t\t\t\"window_size\": self.window_size,\n",
    "\t\t\t\"stride\": self.stride,\n",
    "\t\t\t\"lstm_hidden_dim\": self.lstm_params[\"hidden_dim\"],\n",
    "\t\t\t\"lstm_num_layers\": self.lstm_params[\"num_layers\"],\n",
    "\t\t\t\"lstm_dropout\": self.lstm_params[\"dropout\"],\n",
    "\t\t\t\"lstm_learning_rate\": self.lstm_params[\"learning_rate\"],\n",
    "\t\t\t\"lstm_epochs\": self.lstm_params[\"epochs\"],\n",
    "\t\t\t\"lstm_batch_size\": self.lstm_params[\"batch_size\"],\n",
    "\t\t\t\"lstm_threshold_percentile\": self.lstm_params[\"threshold_percentile\"],\n",
    "\t\t\t\"if_n_estimators\": self.if_params[\"n_estimators\"],\n",
    "\t\t\t\"if_contamination\": self.if_params[\"contamination\"],\n",
    "\t\t\t\"if_max_samples\": self.if_params[\"max_samples\"],\n",
    "\t\t\t\"ocsvm_kernel\": self.ocsvm_params[\"kernel\"],\n",
    "\t\t\t\"ocsvm_nu\": self.ocsvm_params[\"nu\"],\n",
    "\t\t\t\"ocsvm_gamma\": self.ocsvm_params[\"gamma\"],\n",
    "\t\t\t\"ocsvm_tol\": self.ocsvm_params[\"tol\"],\n",
    "\t\t\t\"weights\": self.weights,\n",
    "\t\t\t\"voting\": self.voting,\n",
    "\t\t\t\"use_lstm\": self.use_lstm,\n",
    "\t\t\t\"use_if\": self.use_if,\n",
    "\t\t\t\"use_ocsvm\": self.use_ocsvm,\n",
    "\t\t}\n",
    "\n",
    "\tdef set_params(self, **params) -> \"NoveltyDetectionEnsemble\":\n",
    "\t\t\"\"\"Set parameters for sklearn compatibility.\"\"\"\n",
    "\t\tfor key, value in params.items():\n",
    "\t\t\tif key.startswith(\"lstm_\"):\n",
    "\t\t\t\tparam_name = key.replace(\"lstm_\", \"\")\n",
    "\t\t\t\tif param_name in self.lstm_params:\n",
    "\t\t\t\t\tself.lstm_params[param_name] = value\n",
    "\t\t\telif key.startswith(\"if_\"):\n",
    "\t\t\t\tparam_name = key.replace(\"if_\", \"\")\n",
    "\t\t\t\tif param_name in self.if_params:\n",
    "\t\t\t\t\tself.if_params[param_name] = value\n",
    "\t\t\telif key.startswith(\"ocsvm_\"):\n",
    "\t\t\t\tparam_name = key.replace(\"ocsvm_\", \"\")\n",
    "\t\t\t\tif param_name in self.ocsvm_params:\n",
    "\t\t\t\t\tself.ocsvm_params[param_name] = value\n",
    "\t\t\telif key in [\n",
    "\t\t\t\t\"weights\",\n",
    "\t\t\t\t\"voting\",\n",
    "\t\t\t\t\"window_size\",\n",
    "\t\t\t\t\"stride\",\n",
    "\t\t\t\t\"use_lstm\",\n",
    "\t\t\t\t\"use_if\",\n",
    "\t\t\t\t\"use_ocsvm\",\n",
    "\t\t\t]:\n",
    "\t\t\t\tsetattr(self, key, value)\n",
    "\t\treturn self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_file_logger(filepath: str) -> structlog.BoundLogger:\n",
    "\t\"\"\"\n",
    "\tConfigure a file-specific logger using structlog.\n",
    "\n",
    "\tArgs:\n",
    "\t\tfilepath: Path to log file\n",
    "\n",
    "\tReturns:\n",
    "\t\tConfigured structlog logger\n",
    "\t\"\"\"\n",
    "\t# Create a specific handler for this file\n",
    "\tfile_handler = logging.FileHandler(filepath, mode=\"a\")\n",
    "\tfile_handler.setLevel(logging.INFO)\n",
    "\n",
    "\t# Configure structlog with file output\n",
    "\tstructlog.configure(\n",
    "\t\tprocessors=[\n",
    "\t\t\tstructlog.stdlib.filter_by_level,\n",
    "\t\t\tstructlog.stdlib.add_logger_name,\n",
    "\t\t\tstructlog.stdlib.add_log_level,\n",
    "\t\t\tstructlog.stdlib.PositionalArgumentsFormatter(),\n",
    "\t\t\tstructlog.processors.TimeStamper(fmt=\"iso\"),\n",
    "\t\t\tstructlog.processors.StackInfoRenderer(),\n",
    "\t\t\tstructlog.processors.format_exc_info,\n",
    "\t\t\tstructlog.processors.UnicodeDecoder(),\n",
    "\t\t\tstructlog.processors.JSONRenderer(),\n",
    "\t\t],\n",
    "\t\tcontext_class=dict,\n",
    "\t\tlogger_factory=structlog.stdlib.LoggerFactory(),\n",
    "\t\twrapper_class=structlog.stdlib.BoundLogger,\n",
    "\t\tcache_logger_on_first_use=False,\n",
    "\t)\n",
    "\t# Get the underlying stdlib logger and add the handler\n",
    "\tstdlib_logger = logging.getLogger(\"hyperparameter_search\")\n",
    "\tstdlib_logger.handlers.clear()  # Clear existing handlers\n",
    "\tstdlib_logger.addHandler(file_handler)\n",
    "\tstdlib_logger.setLevel(logging.INFO)\n",
    "\n",
    "\treturn structlog.get_logger(\"hyperparameter_search\")\n",
    "\n",
    "\n",
    "def score_ensemble_function(\n",
    "\tmodel: NoveltyDetectionEnsemble, Train: DataFrame, test: Series\n",
    ") -> float:\n",
    "\t\"\"\"\n",
    "\tObjective function to maximize, calculates the F1 score on the test set.\n",
    "\tFollows the format needed by scikit-learn's API.\n",
    "\n",
    "\tArgs:\n",
    "\t\tmodel: NoveltyDetectionEnsemble to evaluate\n",
    "\t\tTrain: Train data, only for API compliance\n",
    "\t\ttest: True targets, only for API compliance\n",
    "\n",
    "\tReturns:\n",
    "\t\tF1 score\n",
    "\t\"\"\"\n",
    "\tglobal testing_data, test_targets, logger\n",
    "\n",
    "\t# If no predictions (empty data), return 0\n",
    "\tif len(predictions := model.predict(testing_data)) == 0:\n",
    "\t\tlogger.warning(\"No predictions generated - empty windowed data\")\n",
    "\t\treturn 0.0\n",
    "\n",
    "\t# Align predictions with targets (use first N targets that match windows)\n",
    "\taligned_targets = test_targets.iloc[: len(predictions)].values\n",
    "\n",
    "\tf1 = f1_score(aligned_targets, predictions == -1)\n",
    "\n",
    "\t# Get decision scores\n",
    "\tif len(anomaly_scores := model.decision_function(testing_data)) > 0:\n",
    "\t\tprecision, recall, _ = precision_recall_curve(aligned_targets, anomaly_scores)\n",
    "\t\tavg_precision = average_precision_score(aligned_targets, anomaly_scores)\n",
    "\t\tauc_pr = auc(recall, precision)\n",
    "\telse:\n",
    "\t\tavg_precision = 0.0\n",
    "\t\tauc_pr = 0.0\n",
    "\n",
    "\tlogger.info(\n",
    "\t\t{\n",
    "\t\t\t\"target\": f1,\n",
    "\t\t\t\"avg_precision\": avg_precision,\n",
    "\t\t\t\"auc_pr\": auc_pr,\n",
    "\t\t\t\"params\": model.get_params(),\n",
    "\t\t\t\"n_windows\": len(predictions),\n",
    "\t\t\t\"datetime\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "\t\t}\n",
    "\t)\n",
    "\treturn float(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_grid(\n",
    "\tsearch_method: Literal[\n",
    "\t\t\"Grid\",\n",
    "\t\t\"Random\",\n",
    "\t\t\"SimulatedAnnealing\",\n",
    "\t\t\"GeneticAlgorithm\",\n",
    "\t\t\"Bayesian\",\n",
    "\t\t\"Ensemble\",\n",
    "\t],\n",
    "\tuse_log_dist: bool = False,\n",
    ") -> ParamGrid:\n",
    "\t\"\"\"\n",
    "\tGet parameter grid for different search methods.\n",
    "\n",
    "\tArgs:\n",
    "\t\tsearch_method: Name of search method\n",
    "\t\tuse_log_dist: Whether to use log-uniform distributions\n",
    "\n",
    "\tReturns:\n",
    "\t\tParameter grid dictionary\n",
    "\t\"\"\"\n",
    "\tif search_method == \"Ensemble\":\n",
    "\t\tif use_log_dist:\n",
    "\t\t\treturn {\n",
    "\t\t\t\t# Window params\n",
    "\t\t\t\t\"window_size\": [50, 100, 150, 200],\n",
    "\t\t\t\t\"stride\": [25, 50, 75],\n",
    "\t\t\t\t# LSTM params\n",
    "\t\t\t\t\"lstm_hidden_dim\": [32, 64, 128],\n",
    "\t\t\t\t\"lstm_num_layers\": [1, 2, 3],\n",
    "\t\t\t\t\"lstm_dropout\": uniform(0.0, 0.5),\n",
    "\t\t\t\t\"lstm_learning_rate\": loguniform(1e-4, 1e-2),\n",
    "\t\t\t\t\"lstm_epochs\": [20, 30, 50],\n",
    "\t\t\t\t# IF params\n",
    "\t\t\t\t\"if_n_estimators\": [100, 200, 500],\n",
    "\t\t\t\t\"if_contamination\": uniform(0.01, 0.19),\n",
    "\t\t\t\t# OCSVM params\n",
    "\t\t\t\t\"ocsvm_nu\": loguniform(0.001, 0.3),\n",
    "\t\t\t\t\"ocsvm_gamma\": loguniform(1e-4, 10),\n",
    "\t\t\t\t\"ocsvm_tol\": loguniform(1e-6, 1e-1),\n",
    "\t\t\t}\n",
    "\t\telse:\n",
    "\t\t\treturn {\n",
    "\t\t\t\t\"window_size\": [100, 150],\n",
    "\t\t\t\t\"stride\": [50],\n",
    "\t\t\t\t\"lstm_hidden_dim\": [64, 128],\n",
    "\t\t\t\t\"lstm_num_layers\": [2],\n",
    "\t\t\t\t\"lstm_dropout\": [0.2],\n",
    "\t\t\t\t\"lstm_learning_rate\": [0.001],\n",
    "\t\t\t\t\"lstm_epochs\": [30],\n",
    "\t\t\t\t\"if_n_estimators\": [100],\n",
    "\t\t\t\t\"if_contamination\": [0.1],\n",
    "\t\t\t\t\"ocsvm_nu\": [0.01, 0.05, 0.1],\n",
    "\t\t\t\t\"ocsvm_gamma\": [\"scale\", \"auto\"],\n",
    "\t\t\t\t\"ocsvm_tol\": [1e-3],\n",
    "\t\t\t}\n",
    "\telif search_method == \"Grid\":\n",
    "\t\treturn {\n",
    "\t\t\t\"nu\": [0.01, 0.05, 0.1, 0.25],\n",
    "\t\t\t\"gamma\": [\"scale\", \"auto\", 0.001, 0.01, 0.1],\n",
    "\t\t\t\"tol\": [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "\t\t}\n",
    "\telif search_method in [\"Random\", \"SimulatedAnnealing\", \"GeneticAlgorithm\"]:\n",
    "\t\tif use_log_dist:  # Log-uniform for better coverage\n",
    "\t\t\treturn {\n",
    "\t\t\t\t\"nu\": loguniform(0.001, 0.3),\n",
    "\t\t\t\t\"gamma\": loguniform(1e-4, 10),\n",
    "\t\t\t\t\"tol\": loguniform(1e-6, 1e-1),\n",
    "\t\t\t}\n",
    "\t\telse:\n",
    "\t\t\treturn {\n",
    "\t\t\t\t\"nu\": [0.01, 0.025, 0.05, 0.75, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t\t\t\"gamma\": [\"scale\", \"auto\", 0.001, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1],\n",
    "\t\t\t\t\"tol\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "\t\t\t}\n",
    "\telif search_method == \"Bayesian\":\n",
    "\t\treturn {\"nu\": (0.01, 0.5), \"gamma\": (1e-4, 1), \"tol\": (1e-5, 1e-1)}\n",
    "\n",
    "\treturn {}\n",
    "\n",
    "\n",
    "def score_function(model: OneClassSVM, Train: DataFrame, test: Series) -> float:\n",
    "\t\"\"\"\n",
    "\tObjective function to maximize, calculates the F1 score on the test set.\n",
    "\tFollows the format needed by scikit-learn's API.\n",
    "\n",
    "\tArgs:\n",
    "\t\tmodel: OneClassSVM to evaluate\n",
    "\t\tX_test: Train data, only for API compliance\n",
    "\t\ty_true: True targets, only for API compliance\n",
    "\n",
    "\tReturns:\n",
    "\t\tF1 score\n",
    "\t\"\"\"\n",
    "\tglobal testing_data, test_targets, logger\n",
    "\n",
    "\tf1 = f1_score(test_targets, where(model.predict(testing_data) == -1, True, False))\n",
    "\n",
    "\t# Get decision scores (higher values = more normal, lower = more anomalous)\n",
    "\t# convert to anomaly scores (higher values = more anomalous) and Negate\n",
    "\t# decision scores since OneClassSVM gives higher scores for inliers\n",
    "\tanomaly_scores = -model.decision_function(testing_data)\n",
    "\tprecision, recall, _ = precision_recall_curve(test_targets, anomaly_scores)\n",
    "\tlogger.info(\n",
    "\t\t{\n",
    "\t\t\t\"target\": f1,\n",
    "\t\t\t\"avg_precision\": average_precision_score(test_targets, anomaly_scores),\n",
    "\t\t\t\"auc_pr\": auc(recall, precision),\n",
    "\t\t\t\"params\": model.get_params(),\n",
    "\t\t\t\"datetime\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "\t\t}\n",
    "\t)\n",
    "\treturn float(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train_vars(\n",
    "\ti: int, activities: ndarray\n",
    ") -> tuple[DataFrame, Series, DataFrame, Series]:\n",
    "\t\"\"\"\n",
    "\tUpdate training and testing variables for current activity.\n",
    "\n",
    "\tArgs:\n",
    "\t\ti: Current activity index\n",
    "\t\tactivities: Array of all activities\n",
    "\n",
    "\tReturns:\n",
    "\t\tTuple of (training_data, train_targets, testing_data, test_targets)\n",
    "\t\"\"\"\n",
    "\tglobal X_train, X_test, MIN_SAMPLES\n",
    "\n",
    "\ttraining = (  # picks the first n samples of each class\n",
    "\t\tX_train[X_train[\"activity\"].isin(activities[:i])]\n",
    "\t\t.groupby(\"activity\")\n",
    "\t\t.head(MIN_SAMPLES)\n",
    "\t)\n",
    "\ttesting = X_test[X_test[\"activity\"] == activities[i]].head(MIN_SAMPLES)\n",
    "\ttraining.loc[:, \"isNovelty\"], testing.loc[:, \"isNovelty\"] = False, True\n",
    "\tnovelty = concat(\n",
    "\t\t[testing, training.sample(n=int(0.15 * len(training)), random_state=42)]\n",
    "\t)\n",
    "\treturn (\n",
    "\t\ttraining.drop(columns=[\"isNovelty\"]),\n",
    "\t\ttraining[\"isNovelty\"],\n",
    "\t\t# only current activity (as novelty)\n",
    "\t\tnovelty.drop(columns=[\"isNovelty\"]),\n",
    "\t\tnovelty[\"isNovelty\"],\n",
    "\t)\n",
    "\n",
    "\n",
    "def train_search_method(\n",
    "\ttraining_data: DataFrame,\n",
    "\ttrain_targets: Series,\n",
    "\tsearch_type: Literal[\n",
    "\t\t\"Grid\", \"Random\", \"SimulatedAnnealing\", \"GeneticAlgorithm\", \"Ensemble\"\n",
    "\t],\n",
    "\tparams: dict[str, list],\n",
    "\tscoring: Callable,\n",
    "\tn_iter: int | None = 100,\n",
    "\tcv: int = 4,\n",
    "\tverbose: int = 1,\n",
    "\trandom_state: int = 42,\n",
    ") -> (\n",
    "\tRandomizedSearchCV\n",
    "\t| GridSearchCV\n",
    "\t| SimulatedAnnealingSearch\n",
    "\t| GeneticAlgorithmSearch\n",
    "):\n",
    "\t\"\"\"\n",
    "\tTrain a model using the specified search method.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttraining_data: Training DataFrame\n",
    "\t\ttrain_targets: Training targets\n",
    "\t\tsearch_type: Type of search method\n",
    "\t\tparams: Parameter grid/distributions\n",
    "\t\tscoring: Scoring function\n",
    "\t\tn_iter: Number of iterations (for RandomSearch and metaheuristics)\n",
    "\t\tcv: Number of CV folds\n",
    "\t\tverbose: Verbosity level\n",
    "\t\trandom_state: Random seed\n",
    "\n",
    "\tReturns:\n",
    "\t\tFitted search object\n",
    "\t\"\"\"\n",
    "\tif search_type == \"SimulatedAnnealing\":\n",
    "\t\treturn SimulatedAnnealingSearch(\n",
    "\t\t\tparam_space=params,\n",
    "\t\t\tn_iter=n_iter or 100,\n",
    "\t\t\tinitial_temp=1.0,\n",
    "\t\t\tcooling_rate=0.95,\n",
    "\t\t\trandom_state=random_state,\n",
    "\t\t).fit(training_data, train_targets)\n",
    "\n",
    "\telif search_type == \"GeneticAlgorithm\":\n",
    "\t\t# For GA, use n_iter as total evaluations = population_size * n_generations\n",
    "\t\tpopulation_size = min(20, n_iter // 5) if n_iter else 20\n",
    "\t\treturn GeneticAlgorithmSearch(\n",
    "\t\t\tparam_space=params,\n",
    "\t\t\tpopulation_size=population_size,\n",
    "\t\t\tn_generations=(n_iter // population_size) if n_iter else 5,\n",
    "\t\t\tmutation_rate=0.1,\n",
    "\t\t\tcrossover_rate=0.8,\n",
    "\t\t\trandom_state=random_state,\n",
    "\t\t).fit(training_data, train_targets)\n",
    "\n",
    "\telse:\n",
    "\t\t# Original implementation for Grid and Random search\n",
    "\t\tsearch_cls = RandomizedSearchCV if search_type == \"Random\" else GridSearchCV\n",
    "\n",
    "\t\t# Determine which model to use\n",
    "\t\tif search_type == \"Ensemble\":\n",
    "\t\t\tbase_model = NoveltyDetectionEnsemble()\n",
    "\t\telse:\n",
    "\t\t\tbase_model = OneClassSVM(kernel=\"rbf\")\n",
    "\n",
    "\t\tsearch_kwargs = {\n",
    "\t\t\tf\"param_{'distributions' if search_type == 'Random' else 'grid'}\": params,\n",
    "\t\t\t\"estimator\": base_model,\n",
    "\t\t\t\"scoring\": scoring,\n",
    "\t\t\t\"cv\": cv,\n",
    "\t\t\t\"verbose\": verbose,\n",
    "\t\t\t\"error_score\": \"raise\",\n",
    "\t\t}\n",
    "\t\tif search_type == \"Random\" and n_iter:\n",
    "\t\t\tsearch_kwargs.update({\"n_iter\": n_iter, \"random_state\": random_state})\n",
    "\t\treturn search_cls(**search_kwargs).fit(training_data, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_search_methods(\n",
    "\tgrid_scores: list[float], random_scores: list[float]\n",
    ") -> Dict[str, float]:\n",
    "\t\"\"\"\n",
    "\tStatistical comparison of search methods using Wilcoxon signed-rank test.\n",
    "\n",
    "\tArgs:\n",
    "\t\tgrid_scores: Scores from first method\n",
    "\t\trandom_scores: Scores from second method\n",
    "\n",
    "\tReturns:\n",
    "\t\tDictionary with comparison statistics\n",
    "\t\"\"\"\n",
    "\tif len(grid_scores) != len(random_scores):\n",
    "\t\traise ValueError(\"Score arrays must have equal length\")\n",
    "\n",
    "\tstatistic, p_value = wilcoxon(grid_scores, random_scores, alternative=\"two-sided\")\n",
    "\n",
    "\treturn {\n",
    "\t\t\"wilcoxon_statistic\": statistic,\n",
    "\t\t\"p_value\": p_value,\n",
    "\t\t\"grid_mean\": np.mean(grid_scores),\n",
    "\t\t\"random_mean\": np.mean(random_scores),\n",
    "\t\t\"effect_size\": (np.mean(grid_scores) - np.mean(random_scores))\n",
    "\t\t/ np.std(grid_scores + random_scores),\n",
    "\t}\n",
    "\n",
    "\n",
    "def update_params_grid(\n",
    "\tcv_results: dict[str, tuple], og_param_grid: ParamGrid\n",
    ") -> ParamGrid:\n",
    "\t\"\"\"\n",
    "\tUpdate parameter grid based on cross-validation results.\n",
    "\n",
    "\tArgs:\n",
    "\t\tcv_results: Cross-validation results\n",
    "\t\tog_param_grid: Original parameter grid\n",
    "\n",
    "\tReturns:\n",
    "\t\tUpdated parameter grid\n",
    "\t\"\"\"\n",
    "\tparams = [\"gamma\", \"nu\", \"tol\"]\n",
    "\ttop_entries = (\n",
    "\t\tDataFrame(\n",
    "\t\t\tzip(\n",
    "\t\t\t\tcv_results[\"rank_test_score\"],\n",
    "\t\t\t\tcv_results[\"param_gamma\"],\n",
    "\t\t\t\tcv_results[\"param_nu\"],\n",
    "\t\t\t\tcv_results[\"param_tol\"],\n",
    "\t\t\t),\n",
    "\t\t\tcolumns=[\"rank_test_score\", \"gamma\", \"nu\", \"tol\"],\n",
    "\t\t)\n",
    "\t\t.sort_values(\"rank_test_score\")\n",
    "\t\t.head(NUM_TRIALS)\n",
    "\t)\n",
    "\t# Check if we're stuck with the same parameter space\n",
    "\tif len(top_entries) == NUM_TRIALS:\n",
    "\t\tprint(\"Detected potential parameter space stagnation, diversifying...\")\n",
    "\n",
    "\t\tcurrent_params = {col: set(top_entries[col]) for col in params}\n",
    "\t\tunused_params = {\n",
    "\t\t\tparam: list(set(og_param_grid[param]) - current_params[param])\n",
    "\t\t\tfor param in params\n",
    "\t\t}\n",
    "\t\t# Replace least effective values with unused ones\n",
    "\t\tfor param in params:\n",
    "\t\t\tif unused_params[param]:  # If there are unused values available\n",
    "\t\t\t\tcurrent_unique = list(dict.fromkeys(top_entries[param]))\n",
    "\t\t\t\t# Remove the least effective (last) value and add an unused one\n",
    "\t\t\t\tif len(current_unique) > 1 and unused_params[param]:\n",
    "\t\t\t\t\tcurrent_unique = current_unique[:-1] + [unused_params[param][0]]\n",
    "\t\t\t\telif unused_params[param]:\n",
    "\t\t\t\t\t# If only one value, replace it partially\n",
    "\t\t\t\t\tcurrent_unique.append(unused_params[param][0])\n",
    "\n",
    "\t\t\t\ttop_entries.loc[  # Update the parameter list\n",
    "\t\t\t\t\ttop_entries[param] == list(dict.fromkeys(top_entries[param]))[-1],\n",
    "\t\t\t\t\tparam,\n",
    "\t\t\t\t] = unused_params[param][0]\n",
    "\n",
    "\texmp = {col: list(dict.fromkeys(top_entries[col])) for col in params}\n",
    "\tcartesian_size = len(exmp[\"gamma\"]) * len(exmp[\"nu\"]) * len(exmp[\"tol\"])\n",
    "\n",
    "\tif cartesian_size > NUM_TRIALS:\n",
    "\t\twhile cartesian_size > NUM_TRIALS:\n",
    "\t\t\t# Find which parameter to reduce (try removing last value from each)\n",
    "\t\t\tbest_reduction = None\n",
    "\t\t\tbest_param = None\n",
    "\n",
    "\t\t\tfor param in params:\n",
    "\t\t\t\tif len(exmp[param]) > 1:  # Only reduce if more than 1 value remains\n",
    "\t\t\t\t\t# Calculate new cartesian size if we remove last value from this param\n",
    "\t\t\t\t\ttemp_sizes = [\n",
    "\t\t\t\t\t\tlen(exmp[p]) if p != param else len(exmp[p]) - 1 for p in params\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\t\tnew_size = temp_sizes[0] * temp_sizes[1] * temp_sizes[2]\n",
    "\t\t\t\t\t# Check if this gets us closer to NUM_TRIALS without going under\n",
    "\t\t\t\t\tif new_size >= NUM_TRIALS and (\n",
    "\t\t\t\t\t\tbest_reduction is None or new_size < best_reduction\n",
    "\t\t\t\t\t):\n",
    "\t\t\t\t\t\tbest_reduction = new_size\n",
    "\t\t\t\t\t\tbest_param = param\n",
    "\n",
    "\t\t\t# If no good reduction found, just remove from the param with most values\n",
    "\t\t\tif best_param is None:\n",
    "\t\t\t\tparam_lengths = [(param, len(exmp[param])) for param in params]\n",
    "\t\t\t\tparam_lengths.sort(key=lambda x: x[1], reverse=True)\n",
    "\t\t\t\tbest_param = param_lengths[0][0]\n",
    "\n",
    "\t\t\t# Remove the last (least effective) value from the chosen parameter\n",
    "\t\t\tif len(exmp[best_param]) > 1:\n",
    "\t\t\t\texmp[best_param] = exmp[best_param][:-1]\n",
    "\n",
    "\t\t\tcartesian_size = len(exmp[\"gamma\"]) * len(exmp[\"nu\"]) * len(exmp[\"tol\"])\n",
    "\t\t\t# Safety break to avoid infinite loop\n",
    "\t\t\tif all(len(exmp[param]) == 1 for param in params):\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\tassert cartesian_size == NUM_TRIALS, \"reducing the params space failed\"\n",
    "\n",
    "\tprint(f\"dict of len {cartesian_size} :\", exmp)\n",
    "\treturn exmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_search_method(\n",
    "\tactivities: ndarray,\n",
    "\tsearch_name: Literal[\n",
    "\t\t\"Grid\", \"Random\", \"SimulatedAnnealing\", \"GeneticAlgorithm\", \"Ensemble\"\n",
    "\t],\n",
    "\tuse_log_dist: bool = False,\n",
    ") -> SearchResult:\n",
    "\t\"\"\"\n",
    "\tEvaluate a hyperparameter search method across activities.\n",
    "\n",
    "\tArgs:\n",
    "\t\tactivities: Array of activity labels\n",
    "\t\tsearch_name: Name of search method\n",
    "\t\tuse_log_dist: Whether to use log-uniform distributions\n",
    "\n",
    "\tReturns:\n",
    "\t\tSearchResult with evaluation metrics\n",
    "\t\"\"\"\n",
    "\tdist = get_param_grid(search_name, use_log_dist)\n",
    "\tMAXIMAZED = False\n",
    "\tBEST_SCORES = None\n",
    "\n",
    "\tglobal testing_data, test_targets, logger\n",
    "\tstart_time = time()\n",
    "\n",
    "\t# Determine scoring function based on search type\n",
    "\tscoring_func = (\n",
    "\t\tscore_ensemble_function if search_name == \"Ensemble\" else score_function\n",
    "\t)\n",
    "\n",
    "\tfor i in range(1, len(activities)):\n",
    "\t\ttraining_data, train_targets, test_data, testing_targets = update_train_vars(\n",
    "\t\t\ti, activities\n",
    "\t\t)\n",
    "\t\ttesting_data = test_data\n",
    "\t\ttest_targets = testing_targets\n",
    "\t\tprint(f\"Training for activities {activities[:i]}\")\n",
    "\n",
    "\t\tif not MAXIMAZED:\n",
    "\t\t\tsearch_method = train_search_method(\n",
    "\t\t\t\ttraining_data=training_data,\n",
    "\t\t\t\ttrain_targets=train_targets,\n",
    "\t\t\t\tsearch_type=search_name,\n",
    "\t\t\t\tparams=dist,\n",
    "\t\t\t\tscoring=scoring_func,\n",
    "\t\t\t)\n",
    "\t\t\tBEST_SCORES = search_method\n",
    "\t\t\tMAXIMAZED = True\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"Already maximized, suggesting new {NUM_TRIALS} points\")\n",
    "\t\t\t# For metaheuristics and ensemble, we don't update param grid like GridSearch\n",
    "\t\t\tif search_name in [\"SimulatedAnnealing\", \"GeneticAlgorithm\", \"Ensemble\"]:\n",
    "\t\t\t\tsearch_method = train_search_method(\n",
    "\t\t\t\t\ttraining_data=training_data,\n",
    "\t\t\t\t\ttrain_targets=train_targets,\n",
    "\t\t\t\t\tsearch_type=search_name,\n",
    "\t\t\t\t\tparams=dist,\n",
    "\t\t\t\t\tscoring=scoring_func,\n",
    "\t\t\t\t\tn_iter=NUM_TRIALS,\n",
    "\t\t\t\t)\n",
    "\t\t\telse:\n",
    "\t\t\t\tsearch_method = train_search_method(\n",
    "\t\t\t\t\ttraining_data=training_data,\n",
    "\t\t\t\t\ttrain_targets=train_targets,\n",
    "\t\t\t\t\tsearch_type=search_name,\n",
    "\t\t\t\t\tparams=update_params_grid(search_method.cv_results_, dist)\n",
    "\t\t\t\t\tif search_name == \"Grid\"\n",
    "\t\t\t\t\telse dist,\n",
    "\t\t\t\t\tscoring=scoring_func,\n",
    "\t\t\t\t\tn_iter=NUM_TRIALS if search_name == \"Random\" else None,\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t\tif search_method.best_score_ > BEST_SCORES.best_score_:\n",
    "\t\t\t\tBEST_SCORES = search_method\n",
    "\n",
    "\t\tprint(f\"{search_name} Search Best Params:\", search_method.best_params_)\n",
    "\n",
    "\treturn SearchResult(\n",
    "\t\tmethod=search_name + \"_search\",\n",
    "\t\tbest_params=BEST_SCORES.best_params_,\n",
    "\t\tbest_score=BEST_SCORES.best_score_,\n",
    "\t\tcv_scores=BEST_SCORES.cv_results_[\"mean_test_score\"].tolist()\n",
    "\t\tif hasattr(BEST_SCORES.cv_results_[\"mean_test_score\"], \"tolist\")\n",
    "\t\telse BEST_SCORES.cv_results_[\"mean_test_score\"],\n",
    "\t\tfit_time=time() - start_time,\n",
    "\t\tn_evaluations=len(BEST_SCORES.cv_results_[\"mean_test_score\"]),\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = read_csv(\"../data/PAMAP2/x_train_data.csv\")\n",
    "X_test = read_csv(\"../data/PAMAP2/x_test_data.csv\")\n",
    "y_train = read_csv(\"../data/PAMAP2/y_train_data.csv\")\n",
    "y_test = read_csv(\"../data/PAMAP2/y_test_data.csv\")\n",
    "\n",
    "X_train[\"activity\"] = y_train\n",
    "X_test[\"activity\"] = y_test\n",
    "\n",
    "testing_data: DataFrame\n",
    "test_targets: Series\n",
    "\n",
    "MIN_SAMPLES = X_train[\"activity\"].value_counts().sort_values().iloc[0]\n",
    "MAXIMAZED = False\n",
    "\n",
    "activities = X_train[\"activity\"].unique()\n",
    "\n",
    "# Run original searches\n",
    "logger = configure_file_logger(\"../reports/logs_grid.log\")\n",
    "grid_result = eval_search_method(activities, \"Grid\")\n",
    "\n",
    "logger = configure_file_logger(\"../reports/logs_rand.log\")\n",
    "rand_result = eval_search_method(activities, \"Random\")\n",
    "\n",
    "logger = configure_file_logger(\"../reports/logs_rand_log.log\")\n",
    "rand_log_result = eval_search_method(activities, \"Random\", True)\n",
    "\n",
    "# New metaheuristic searches\n",
    "logger = configure_file_logger(\"../reports/logs_sian.log\")\n",
    "sa_result = eval_search_method(activities, \"SimulatedAnnealing\", True)\n",
    "\n",
    "logger = configure_file_logger(\"../reports/logs_geal.log\")\n",
    "ga_result = eval_search_method(activities, \"GeneticAlgorithm\", True)\n",
    "\n",
    "# New ensemble search\n",
    "logger = configure_file_logger(\"../reports/logs_ensemble.log\")\n",
    "ensemble_result = eval_search_method(activities, \"Ensemble\", True)\n",
    "\n",
    "# Compare all methods\n",
    "with open(\"../conf/test_results.json\", \"w\") as file:\n",
    "\tcomparisons = [\n",
    "\t\t{\n",
    "\t\t\t\"test\": \"Grid x Rand\",\n",
    "\t\t\t**compare_search_methods(grid_result.cv_scores, rand_result.cv_scores),\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"test\": \"Grid x SA\",\n",
    "\t\t\t**compare_search_methods(grid_result.cv_scores, sa_result.cv_scores),\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"test\": \"Grid x GA\",\n",
    "\t\t\t**compare_search_methods(grid_result.cv_scores, ga_result.cv_scores),\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"test\": \"Grid x Ensemble\",\n",
    "\t\t\t**compare_search_methods(grid_result.cv_scores, ensemble_result.cv_scores),\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"test\": \"Rand x SA\",\n",
    "\t\t\t**compare_search_methods(rand_result.cv_scores, sa_result.cv_scores),\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"test\": \"Rand x GA\",\n",
    "\t\t\t**compare_search_methods(rand_result.cv_scores, ga_result.cv_scores),\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"test\": \"Rand x Ensemble\",\n",
    "\t\t\t**compare_search_methods(rand_result.cv_scores, ensemble_result.cv_scores),\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"test\": \"SA x GA\",\n",
    "\t\t\t**compare_search_methods(sa_result.cv_scores, ga_result.cv_scores),\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"test\": \"SA x Ensemble\",\n",
    "\t\t\t**compare_search_methods(sa_result.cv_scores, ensemble_result.cv_scores),\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"test\": \"GA x Ensemble\",\n",
    "\t\t\t**compare_search_methods(ga_result.cv_scores, ensemble_result.cv_scores),\n",
    "\t\t},\n",
    "\t]\n",
    "\tfile.write(dumps(comparisons, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "for result in [\n",
    "\tgrid_result,\n",
    "\trand_result,\n",
    "\trand_log_result,\n",
    "\tsa_result,\n",
    "\tga_result,\n",
    "\tensemble_result,\n",
    "]:\n",
    "\tprint(f\"\\n{result.method}:\")\n",
    "\tprint(f\"  Best Score: {result.best_score:.4f}\")\n",
    "\tprint(f\"  Mean CV Score: {np.mean(result.cv_scores):.4f}\")\n",
    "\tprint(f\"  Fit Time: {result.fit_time:.2f}s\")\n",
    "\tprint(f\"  N Evaluations: {result.n_evaluations}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
